{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Homework 2 - Student No. 11371826</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 1: Data Understanding</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Opening the .csv files as a DataFrame\n",
    "# Importing pandas and numpy for usage throughout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing matplotlib for visualisations & plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Importing to show plots in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "dataFile = \"quality_issues_addressed_amazon_information.csv\"\n",
    "df = pd.read_csv(dataFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Previous statistics for the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>TimeOfOfferChange</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>IsFulfilledByAmazon</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>SellerId</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1207135739277432339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.35</td>\n",
       "      <td>95</td>\n",
       "      <td>4078</td>\n",
       "      <td>-1789487307643024748</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.46</td>\n",
       "      <td>98</td>\n",
       "      <td>478</td>\n",
       "      <td>5452082314297826053</td>\n",
       "      <td>6.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.24</td>\n",
       "      <td>95</td>\n",
       "      <td>4384</td>\n",
       "      <td>-2572277640783537773</td>\n",
       "      <td>11.67</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.48</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>-8704029307873847986</td>\n",
       "      <td>8.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116.70</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>1929046423112965216</td>\n",
       "      <td>6.98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124.69</td>\n",
       "      <td>100</td>\n",
       "      <td>4601</td>\n",
       "      <td>5657218934756058127</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.08</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125.73</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121.27</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.12</td>\n",
       "      <td>96</td>\n",
       "      <td>35264</td>\n",
       "      <td>6791568714796518563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123.77</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>-373508113925093038</td>\n",
       "      <td>12.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>139.58</td>\n",
       "      <td>94</td>\n",
       "      <td>178</td>\n",
       "      <td>-8070122054366980138</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136.71</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>750763505746428351</td>\n",
       "      <td>5.54</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>HK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131.25</td>\n",
       "      <td>94</td>\n",
       "      <td>337</td>\n",
       "      <td>2760162070632027753</td>\n",
       "      <td>14.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.26</td>\n",
       "      <td>96</td>\n",
       "      <td>41419</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>7.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145.93</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>5554217688069566383</td>\n",
       "      <td>1.34</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.27</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>9008330480532653624</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.79</td>\n",
       "      <td>100</td>\n",
       "      <td>26</td>\n",
       "      <td>5811974462741352839</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.64</td>\n",
       "      <td>98</td>\n",
       "      <td>3293</td>\n",
       "      <td>4143506568603310959</td>\n",
       "      <td>10.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89.64</td>\n",
       "      <td>96</td>\n",
       "      <td>35264</td>\n",
       "      <td>6791568714796518563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1207135739277432339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81.49</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.56</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74.07</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>-5016003493506265192</td>\n",
       "      <td>21.69</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.75</td>\n",
       "      <td>95</td>\n",
       "      <td>4384</td>\n",
       "      <td>-2572277640783537773</td>\n",
       "      <td>11.31</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.14</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97.45</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102.71</td>\n",
       "      <td>88</td>\n",
       "      <td>8452</td>\n",
       "      <td>-6639690782514669126</td>\n",
       "      <td>13.19</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109.13</td>\n",
       "      <td>96</td>\n",
       "      <td>41419</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>7.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>9970</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.84</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>4987276067789979672</td>\n",
       "      <td>13.24</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>9971</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.72</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>-373508113925093038</td>\n",
       "      <td>9.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>9972</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>9973</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.87</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>-5016003493506265192</td>\n",
       "      <td>21.25</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>9974</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>-9097393894851801879</td>\n",
       "      <td>6.89</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>9975</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.72</td>\n",
       "      <td>91</td>\n",
       "      <td>11930</td>\n",
       "      <td>-1888136325356517677</td>\n",
       "      <td>7.50</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>9976</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>88</td>\n",
       "      <td>8452</td>\n",
       "      <td>-6639690782514669126</td>\n",
       "      <td>11.84</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>9977</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.68</td>\n",
       "      <td>96</td>\n",
       "      <td>41420</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>6.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>9978</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3846853762521352076</td>\n",
       "      <td>15.26</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>9979</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.25</td>\n",
       "      <td>98</td>\n",
       "      <td>1446</td>\n",
       "      <td>1163115142515862290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>9980</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.57</td>\n",
       "      <td>96</td>\n",
       "      <td>184</td>\n",
       "      <td>-5514312832713552000</td>\n",
       "      <td>44.65</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>9981</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.07</td>\n",
       "      <td>95</td>\n",
       "      <td>4385</td>\n",
       "      <td>-2572277640783537773</td>\n",
       "      <td>11.22</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>9982</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.98</td>\n",
       "      <td>98</td>\n",
       "      <td>3293</td>\n",
       "      <td>4143506568603310959</td>\n",
       "      <td>7.99</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>9983</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.99</td>\n",
       "      <td>84</td>\n",
       "      <td>161</td>\n",
       "      <td>-3129154375621551414</td>\n",
       "      <td>8.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>9984</td>\n",
       "      <td>1</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1207135739277432339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>9985</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.71</td>\n",
       "      <td>96</td>\n",
       "      <td>35272</td>\n",
       "      <td>6791568714796518563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>9986</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.19</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>9987</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.06</td>\n",
       "      <td>94</td>\n",
       "      <td>178</td>\n",
       "      <td>-8070122054366980138</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>9988</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.31</td>\n",
       "      <td>100</td>\n",
       "      <td>4601</td>\n",
       "      <td>5657218934756058127</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>9989</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.62</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>9990</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.84</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>4987276067789979672</td>\n",
       "      <td>13.24</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>9991</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.72</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>-373508113925093038</td>\n",
       "      <td>9.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>9992</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>9993</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.87</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>-5016003493506265192</td>\n",
       "      <td>21.25</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>9994</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>-9097393894851801879</td>\n",
       "      <td>6.89</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>9995</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.72</td>\n",
       "      <td>91</td>\n",
       "      <td>11930</td>\n",
       "      <td>-1888136325356517677</td>\n",
       "      <td>7.50</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>88</td>\n",
       "      <td>8452</td>\n",
       "      <td>-6639690782514669126</td>\n",
       "      <td>11.84</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.68</td>\n",
       "      <td>96</td>\n",
       "      <td>41420</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>6.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3846853762521352076</td>\n",
       "      <td>15.26</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.25</td>\n",
       "      <td>98</td>\n",
       "      <td>1446</td>\n",
       "      <td>1163115142515862290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  IsWinner            ProductId         TimeOfOfferChange  \\\n",
       "0              0         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "1              1         1 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "2              2         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "3              3         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "4              4         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "5              5         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "6              6         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "7              7         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "8              8         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "9              9         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "10            10         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "11            11         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "12            12         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "13            13         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "14            14         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "15            15         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "16            16         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "17            17         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "18            19         0 -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "19            20         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "20            21         1 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "21            22         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "22            23         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "23            24         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "24            25         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "25            26         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "26            27         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "27            28         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "28            29         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "29            30         0 -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "...          ...       ...                  ...                       ...   \n",
       "9856        9970         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9857        9971         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9858        9972         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9859        9973         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9860        9974         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9861        9975         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9862        9976         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9863        9977         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9864        9978         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9865        9979         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9866        9980         0  8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9867        9981         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9868        9982         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9869        9983         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9870        9984         1  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9871        9985         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9872        9986         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9873        9987         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9874        9988         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9875        9989         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9876        9990         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9877        9991         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9878        9992         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9879        9993         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9880        9994         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9881        9995         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9882        9996         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9883        9997         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9884        9998         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9885        9999         0  8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "\n",
       "      IsFeaturedMerchant  IsFulfilledByAmazon  ListingPrice  \\\n",
       "0                      1                    1         94.00   \n",
       "1                      1                    0        107.35   \n",
       "2                      1                    0        100.46   \n",
       "3                      1                    0         99.24   \n",
       "4                      0                    0        109.48   \n",
       "5                      0                    0        116.70   \n",
       "6                      1                    0        124.69   \n",
       "7                      1                    0        120.08   \n",
       "8                      1                    0        125.73   \n",
       "9                      1                    0        121.27   \n",
       "10                     1                    0        133.12   \n",
       "11                     1                    0        123.77   \n",
       "12                     1                    0        139.58   \n",
       "13                     1                    0        136.71   \n",
       "14                     1                    0        131.25   \n",
       "15                     1                    0        140.26   \n",
       "16                     1                    0        145.93   \n",
       "17                     1                    0        150.27   \n",
       "18                     1                    0        150.79   \n",
       "19                     0                    0         78.64   \n",
       "20                     1                    0         89.64   \n",
       "21                     1                    1         90.86   \n",
       "22                     1                    0         81.49   \n",
       "23                     1                    0         82.56   \n",
       "24                     1                    0         74.07   \n",
       "25                     1                    0         85.75   \n",
       "26                     1                    0         94.14   \n",
       "27                     1                    0         97.45   \n",
       "28                     1                    0        102.71   \n",
       "29                     1                    0        109.13   \n",
       "...                  ...                  ...           ...   \n",
       "9856                   1                    0         60.84   \n",
       "9857                   1                    0         67.72   \n",
       "9858                   1                    0         75.99   \n",
       "9859                   1                    0         61.87   \n",
       "9860                   1                    0         88.00   \n",
       "9861                   1                    0         92.72   \n",
       "9862                   1                    0         96.77   \n",
       "9863                   1                    0        110.68   \n",
       "9864                   1                    0        105.73   \n",
       "9865                   1                    0        134.25   \n",
       "9866                   1                    0        110.57   \n",
       "9867                   1                    0         56.07   \n",
       "9868                   0                    0         59.98   \n",
       "9869                   0                    0         58.99   \n",
       "9870                   1                    1         68.62   \n",
       "9871                   1                    0         68.71   \n",
       "9872                   1                    0         59.19   \n",
       "9873                   1                    0         70.06   \n",
       "9874                   1                    0         70.31   \n",
       "9875                   1                    0         60.62   \n",
       "9876                   1                    0         60.84   \n",
       "9877                   1                    0         67.72   \n",
       "9878                   1                    0         75.99   \n",
       "9879                   1                    0         61.87   \n",
       "9880                   1                    0         88.00   \n",
       "9881                   1                    0         92.72   \n",
       "9882                   1                    0         96.77   \n",
       "9883                   1                    0        110.68   \n",
       "9884                   1                    0        105.73   \n",
       "9885                   1                    0        134.25   \n",
       "\n",
       "      SellerFeedbackRating  SellerFeedbackCount             SellerId  \\\n",
       "0                        0                    0  1207135739277432339   \n",
       "1                       95                 4078 -1789487307643024748   \n",
       "2                       98                  478  5452082314297826053   \n",
       "3                       95                 4384 -2572277640783537773   \n",
       "4                       94                  105 -8704029307873847986   \n",
       "5                       67                    9  1929046423112965216   \n",
       "6                      100                 4601  5657218934756058127   \n",
       "7                       96                 1790  1788801474825896666   \n",
       "8                       91                10606 -1177408302343430963   \n",
       "9                       96                 1790  1788801474825896666   \n",
       "10                      96                35264  6791568714796518563   \n",
       "11                      96                 7090  -373508113925093038   \n",
       "12                      94                  178 -8070122054366980138   \n",
       "13                     100                    3   750763505746428351   \n",
       "14                      94                  337  2760162070632027753   \n",
       "15                      96                41419  9012427554787096099   \n",
       "16                     100                   35  5554217688069566383   \n",
       "17                     100                   20  9008330480532653624   \n",
       "18                     100                   26  5811974462741352839   \n",
       "19                      98                 3293  4143506568603310959   \n",
       "20                      96                35264  6791568714796518563   \n",
       "21                       0                    0  1207135739277432339   \n",
       "22                      96                 1790  1788801474825896666   \n",
       "23                      96                 1790  1788801474825896666   \n",
       "24                      93                 2521 -5016003493506265192   \n",
       "25                      95                 4384 -2572277640783537773   \n",
       "26                      91                10606 -1177408302343430963   \n",
       "27                      91                10606 -1177408302343430963   \n",
       "28                      88                 8452 -6639690782514669126   \n",
       "29                      96                41419  9012427554787096099   \n",
       "...                    ...                  ...                  ...   \n",
       "9856                   100                  384  4987276067789979672   \n",
       "9857                    96                 7090  -373508113925093038   \n",
       "9858                    91                10606 -1177408302343430963   \n",
       "9859                    93                 2521 -5016003493506265192   \n",
       "9860                   100                    2 -9097393894851801879   \n",
       "9861                    91                11930 -1888136325356517677   \n",
       "9862                    88                 8452 -6639690782514669126   \n",
       "9863                    96                41420  9012427554787096099   \n",
       "9864                     0                    0  3846853762521352076   \n",
       "9865                    98                 1446  1163115142515862290   \n",
       "9866                    96                  184 -5514312832713552000   \n",
       "9867                    95                 4385 -2572277640783537773   \n",
       "9868                    98                 3293  4143506568603310959   \n",
       "9869                    84                  161 -3129154375621551414   \n",
       "9870                     0                    0  1207135739277432339   \n",
       "9871                    96                35272  6791568714796518563   \n",
       "9872                    96                 1790  1788801474825896666   \n",
       "9873                    94                  178 -8070122054366980138   \n",
       "9874                   100                 4601  5657218934756058127   \n",
       "9875                    96                 1790  1788801474825896666   \n",
       "9876                   100                  384  4987276067789979672   \n",
       "9877                    96                 7090  -373508113925093038   \n",
       "9878                    91                10606 -1177408302343430963   \n",
       "9879                    93                 2521 -5016003493506265192   \n",
       "9880                   100                    2 -9097393894851801879   \n",
       "9881                    91                11930 -1888136325356517677   \n",
       "9882                    88                 8452 -6639690782514669126   \n",
       "9883                    96                41420  9012427554787096099   \n",
       "9884                     0                    0  3846853762521352076   \n",
       "9885                    98                 1446  1163115142515862290   \n",
       "\n",
       "      ShippingPrice  ShippingTime_minHours  ShippingTime_maxHours  \\\n",
       "0              0.00                    672                   1008   \n",
       "1              0.00                     48                     72   \n",
       "2              6.99                     24                     48   \n",
       "3             11.67                     24                     48   \n",
       "4              8.99                     24                     48   \n",
       "5              6.98                     24                     48   \n",
       "6              0.00                     24                     48   \n",
       "7              9.98                     96                    120   \n",
       "8              5.00                     24                     48   \n",
       "9              9.98                     96                    120   \n",
       "10             0.00                     96                    120   \n",
       "11            12.95                     24                     48   \n",
       "12             0.00                     24                     48   \n",
       "13             5.54                     24                     48   \n",
       "14            14.99                     24                     48   \n",
       "15             7.00                     24                     48   \n",
       "16             1.34                     96                    120   \n",
       "17             0.00                     72                     96   \n",
       "18             0.00                     72                     96   \n",
       "19            10.99                     24                     48   \n",
       "20             0.00                     96                    120   \n",
       "21             0.00                    672                   1008   \n",
       "22             9.98                     96                    120   \n",
       "23             9.98                     96                    120   \n",
       "24            21.69                     24                     48   \n",
       "25            11.31                     24                     48   \n",
       "26             5.00                     24                     48   \n",
       "27             5.00                     24                     48   \n",
       "28            13.19                     96                    120   \n",
       "29             7.00                     24                     48   \n",
       "...             ...                    ...                    ...   \n",
       "9856          13.24                     24                     48   \n",
       "9857           9.95                     24                     48   \n",
       "9858           5.00                     24                     48   \n",
       "9859          21.25                     24                     48   \n",
       "9860           6.89                     24                     48   \n",
       "9861           7.50                     72                     96   \n",
       "9862          11.84                     96                    120   \n",
       "9863           6.00                     24                     48   \n",
       "9864          15.26                     24                     48   \n",
       "9865           0.00                     24                     48   \n",
       "9866          44.65                     96                    120   \n",
       "9867          11.22                     24                     48   \n",
       "9868           7.99                     48                     72   \n",
       "9869           8.99                     24                     48   \n",
       "9870           0.00                      0                      0   \n",
       "9871           0.00                     96                    120   \n",
       "9872           9.98                     96                    120   \n",
       "9873           0.00                     24                     48   \n",
       "9874           0.00                     24                     48   \n",
       "9875           9.98                     96                    120   \n",
       "9876          13.24                     24                     48   \n",
       "9877           9.95                     24                     48   \n",
       "9878           5.00                     24                     48   \n",
       "9879          21.25                     24                     48   \n",
       "9880           6.89                     24                     48   \n",
       "9881           7.50                     72                     96   \n",
       "9882          11.84                     96                    120   \n",
       "9883           6.00                     24                     48   \n",
       "9884          15.26                     24                     48   \n",
       "9885           0.00                     24                     48   \n",
       "\n",
       "     ShipsFromCountry ShipsFromState  \n",
       "0                 NaN            NaN  \n",
       "1                  CA             ON  \n",
       "2                  CA             ON  \n",
       "3                  CA             ON  \n",
       "4                  CA             ON  \n",
       "5                  CA             AB  \n",
       "6                  CA             ON  \n",
       "7                  US             NY  \n",
       "8                 NaN            NaN  \n",
       "9                  US             NY  \n",
       "10                 CA             QC  \n",
       "11                 CA             ON  \n",
       "12                 US             NV  \n",
       "13                 HK            NaN  \n",
       "14                 CA             QC  \n",
       "15                NaN            NaN  \n",
       "16                 JP            NaN  \n",
       "17                 JP            NaN  \n",
       "18                 JP            NaN  \n",
       "19                 US             NY  \n",
       "20                 CA             QC  \n",
       "21                NaN            NaN  \n",
       "22                 US             NY  \n",
       "23                 US             NY  \n",
       "24                 US             VA  \n",
       "25                 CA             ON  \n",
       "26                NaN            NaN  \n",
       "27                NaN            NaN  \n",
       "28                NaN            NaN  \n",
       "29                NaN            NaN  \n",
       "...               ...            ...  \n",
       "9856               CA             ON  \n",
       "9857               CA             ON  \n",
       "9858              NaN            NaN  \n",
       "9859               US             VA  \n",
       "9860               FR            NaN  \n",
       "9861              NaN            NaN  \n",
       "9862              NaN            NaN  \n",
       "9863              NaN            NaN  \n",
       "9864              NaN            NaN  \n",
       "9865               US             CA  \n",
       "9866               US             NY  \n",
       "9867               CA             ON  \n",
       "9868               US             NY  \n",
       "9869               CA             ON  \n",
       "9870              NaN            NaN  \n",
       "9871               CA             QC  \n",
       "9872               US             NY  \n",
       "9873               US             NV  \n",
       "9874               CA             ON  \n",
       "9875               US             NY  \n",
       "9876               CA             ON  \n",
       "9877               CA             ON  \n",
       "9878              NaN            NaN  \n",
       "9879               US             VA  \n",
       "9880               FR            NaN  \n",
       "9881              NaN            NaN  \n",
       "9882              NaN            NaN  \n",
       "9883              NaN            NaN  \n",
       "9884              NaN            NaN  \n",
       "9885               US             CA  \n",
       "\n",
       "[9886 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the cleaned df has been correctly read into the Notebook\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9886, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the cleaned df has been correctly read into the Notebook\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                 int64\n",
       "IsWinner                   int64\n",
       "ProductId                  int64\n",
       "TimeOfOfferChange         object\n",
       "IsFeaturedMerchant         int64\n",
       "IsFulfilledByAmazon        int64\n",
       "ListingPrice             float64\n",
       "SellerFeedbackRating       int64\n",
       "SellerFeedbackCount        int64\n",
       "SellerId                   int64\n",
       "ShippingPrice            float64\n",
       "ShippingTime_minHours      int64\n",
       "ShippingTime_maxHours      int64\n",
       "ShipsFromCountry          object\n",
       "ShipsFromState            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish Data Types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping unknown extra ID column added in error\n",
    "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsWinner                   int64\n",
       "ProductId                  int64\n",
       "TimeOfOfferChange         object\n",
       "IsFeaturedMerchant         int64\n",
       "IsFulfilledByAmazon        int64\n",
       "ListingPrice             float64\n",
       "SellerFeedbackRating       int64\n",
       "SellerFeedbackCount        int64\n",
       "SellerId                   int64\n",
       "ShippingPrice            float64\n",
       "ShippingTime_minHours      int64\n",
       "ShippingTime_maxHours      int64\n",
       "ShipsFromCountry          object\n",
       "ShipsFromState            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure that the column has been dropped\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsWinner                 category\n",
       "ProductId                  object\n",
       "TimeOfOfferChange          object\n",
       "IsFeaturedMerchant       category\n",
       "IsFulfilledByAmazon      category\n",
       "ListingPrice              float64\n",
       "SellerFeedbackRating        int64\n",
       "SellerFeedbackCount         int64\n",
       "SellerId                   object\n",
       "ShippingPrice             float64\n",
       "ShippingTime_minHours       int64\n",
       "ShippingTime_maxHours       int64\n",
       "ShipsFromCountry         category\n",
       "ShipsFromState           category\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the relevant types from 'object' or 'int' into type 'category'\n",
    "# Similarly, IsWinner, IsFeaturedMerchant, and IsFullfilledByAmazon, have been changed.\n",
    "# Although these are integer values within the cells, they represent Yes/No discreet, categorical information \n",
    "# rather than continuous numeric information. This make change in relation to the target feature when it comes to \n",
    "# Plotting Scatter Plots in later questions\n",
    "\n",
    "df['IsWinner'] = df['IsWinner'].astype('category')\n",
    "df['ProductId'] = df['ProductId'].astype('object')\n",
    "df['IsFeaturedMerchant'] = df['IsFeaturedMerchant'].astype('category')\n",
    "df['IsFulfilledByAmazon'] = df['IsFulfilledByAmazon'].astype('category')\n",
    "df['SellerId'] = df['SellerId'].astype('object')\n",
    "df['ShipsFromCountry'] = df['ShipsFromCountry'].astype('category')\n",
    "df['ShipsFromState'] = df['ShipsFromState'].astype('category')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ListingPrice</th>\n",
       "      <td>9886.0</td>\n",
       "      <td>216.480167</td>\n",
       "      <td>256.579400</td>\n",
       "      <td>3.24</td>\n",
       "      <td>63.63</td>\n",
       "      <td>125.99</td>\n",
       "      <td>257.8625</td>\n",
       "      <td>3194.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <td>9886.0</td>\n",
       "      <td>88.975926</td>\n",
       "      <td>21.559616</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <td>9886.0</td>\n",
       "      <td>6910.402488</td>\n",
       "      <td>10918.235681</td>\n",
       "      <td>0.00</td>\n",
       "      <td>338.00</td>\n",
       "      <td>3293.00</td>\n",
       "      <td>8452.0000</td>\n",
       "      <td>41420.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShippingPrice</th>\n",
       "      <td>9886.0</td>\n",
       "      <td>12.434700</td>\n",
       "      <td>26.476572</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>13.6800</td>\n",
       "      <td>705.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <td>9886.0</td>\n",
       "      <td>57.266437</td>\n",
       "      <td>82.801069</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>96.0000</td>\n",
       "      <td>672.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <td>9886.0</td>\n",
       "      <td>88.874772</td>\n",
       "      <td>120.397193</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>1008.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count         mean           std   min     25%  \\\n",
       "ListingPrice           9886.0   216.480167    256.579400  3.24   63.63   \n",
       "SellerFeedbackRating   9886.0    88.975926     21.559616  0.00   91.00   \n",
       "SellerFeedbackCount    9886.0  6910.402488  10918.235681  0.00  338.00   \n",
       "ShippingPrice          9886.0    12.434700     26.476572  0.00    0.00   \n",
       "ShippingTime_minHours  9886.0    57.266437     82.801069  0.00   24.00   \n",
       "ShippingTime_maxHours  9886.0    88.874772    120.397193  0.00   48.00   \n",
       "\n",
       "                           50%        75%       max  \n",
       "ListingPrice            125.99   257.8625   3194.32  \n",
       "SellerFeedbackRating     95.00    96.0000    100.00  \n",
       "SellerFeedbackCount    3293.00  8452.0000  41420.00  \n",
       "ShippingPrice             7.50    13.6800    705.27  \n",
       "ShippingTime_minHours    24.00    96.0000    672.00  \n",
       "ShippingTime_maxHours    48.00   120.0000   1008.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tables of Continuous Statistics for ease of access to Continuous Feature information\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IsWinner</th>\n",
       "      <td>9886</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <td>9886</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsFulfilledByAmazon</th>\n",
       "      <td>9886</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <td>6217</td>\n",
       "      <td>13</td>\n",
       "      <td>CA</td>\n",
       "      <td>3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShipsFromState</th>\n",
       "      <td>5851</td>\n",
       "      <td>24</td>\n",
       "      <td>ON</td>\n",
       "      <td>2211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count unique top  freq\n",
       "IsWinner             9886      2   0  9339\n",
       "IsFeaturedMerchant   9886      2   1  8090\n",
       "IsFulfilledByAmazon  9886      2   0  9519\n",
       "ShipsFromCountry     6217     13  CA  3655\n",
       "ShipsFromState       5851     24  ON  2211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tables of Categorical Statistics for ease of access to information on features\n",
    "category_columns = df.select_dtypes(['category']).columns\n",
    "df[category_columns].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1.1: Print the correlations between the continuous features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the packages that are required for this section\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5,  1.5,  2.5,  3.5,  4.5,  5.5]),\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArUAAAJUCAYAAAALuN5mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhHB6EmqFEEIIIYTT+wc5+wd6OtYsQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623d523668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix using code found on https://stanford.edu/~mwaskom/software/seaborn/examples/many_pairwise_correlations.html\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Select columns containing continuous data\n",
    "continuous_columns = df[['ListingPrice','SellerFeedbackRating','ShippingPrice','ShippingTime_minHours','SellerFeedbackCount', 'ShippingTime_maxHours']].columns\n",
    "\n",
    "# Calculate correlation of all pairs of continuous features\n",
    "corr = df[continuous_columns].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom colormap - blue and red\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, annot=True, mask=mask, cmap=cmap, vmax=1, vmin=-1,\n",
    "            square=True, xticklabels=True, yticklabels=True,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.xticks(rotation = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ListingPrice</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150274</td>\n",
       "      <td>0.034981</td>\n",
       "      <td>-0.033080</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShippingPrice</th>\n",
       "      <td>0.150274</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060349</td>\n",
       "      <td>-0.067493</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>0.019848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <td>0.034981</td>\n",
       "      <td>0.060349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167111</td>\n",
       "      <td>-0.375718</td>\n",
       "      <td>-0.381365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <td>-0.033080</td>\n",
       "      <td>-0.067493</td>\n",
       "      <td>0.167111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001627</td>\n",
       "      <td>-0.030522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>-0.375718</td>\n",
       "      <td>-0.001627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.019848</td>\n",
       "      <td>-0.381365</td>\n",
       "      <td>-0.030522</td>\n",
       "      <td>0.992427</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ListingPrice  ShippingPrice  SellerFeedbackRating  \\\n",
       "ListingPrice               1.000000       0.150274              0.034981   \n",
       "ShippingPrice              0.150274       1.000000              0.060349   \n",
       "SellerFeedbackRating       0.034981       0.060349              1.000000   \n",
       "SellerFeedbackCount       -0.033080      -0.067493              0.167111   \n",
       "ShippingTime_minHours      0.000290       0.019246             -0.375718   \n",
       "ShippingTime_maxHours     -0.000209       0.019848             -0.381365   \n",
       "\n",
       "                       SellerFeedbackCount  ShippingTime_minHours  \\\n",
       "ListingPrice                     -0.033080               0.000290   \n",
       "ShippingPrice                    -0.067493               0.019246   \n",
       "SellerFeedbackRating              0.167111              -0.375718   \n",
       "SellerFeedbackCount               1.000000              -0.001627   \n",
       "ShippingTime_minHours            -0.001627               1.000000   \n",
       "ShippingTime_maxHours            -0.030522               0.992427   \n",
       "\n",
       "                       ShippingTime_maxHours  \n",
       "ListingPrice                       -0.000209  \n",
       "ShippingPrice                       0.019848  \n",
       "SellerFeedbackRating               -0.381365  \n",
       "SellerFeedbackCount                -0.030522  \n",
       "ShippingTime_minHours               0.992427  \n",
       "ShippingTime_maxHours               1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another method for viewing the correlations of the Continuous Features\n",
    "\n",
    "df[['ListingPrice','ShippingPrice','SellerFeedbackRating','SellerFeedbackCount','ShippingTime_minHours','ShippingTime_maxHours']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1.2: Plot the scatter plots of each pair of continuous descriptive feature and target feature</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In order to plot scatter plots for each pair of Continuous Feature and Target Feature, the Target Feature, IsWinner\n",
    "# Must be converted to a Continuous Feature\n",
    "df['IsWinner'] = df['IsWinner'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2623d777588>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAHfCAYAAAAcIUqCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndgAAAHMBdRgf4ogpfUkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623dab2b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take the first 3 Continuous Features and the Target Feature and plot them on a Scatter Plot\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "df.plot(kind='scatter', x='ShippingTime_minHours', y='IsWinner', label=\"%.3f\" % df[['ShippingTime_minHours', 'IsWinner']].corr().as_matrix()[0,1], ax=axs[0], figsize=(15, 8))\n",
    "df.plot(kind='scatter', x='SellerFeedbackRating', y='IsWinner', label=\"%.3f\" % df[['SellerFeedbackRating', 'IsWinner']].corr().as_matrix()[0,1], ax=axs[1])\n",
    "df.plot(kind='scatter', x='SellerFeedbackCount', y='IsWinner', label=\"%.3f\" % df[['SellerFeedbackCount', 'IsWinner']].corr().as_matrix()[0,1], ax=axs[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2623ef45f98>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAHfCAYAAAAcIUqCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndgAAAHNiBwAAMCd2AAAAcwHKi+r4Negi1QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623d7c7748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take the second 3 Continuous Features and the Target Feature and plot them on a Scatter Plot\n",
    "fig, axs = plt.subplots(1, 3, sharey=True)\n",
    "df.plot(kind='scatter', x='ListingPrice', y='IsWinner', label=\"%.3f\" % df[['ListingPrice', 'IsWinner']].corr().as_matrix()[0,1], ax=axs[0], figsize=(15, 8))\n",
    "df.plot(kind='scatter', x='ShippingPrice', y='IsWinner', label=\"%.3f\" % df[['ShippingPrice', 'IsWinner']].corr().as_matrix()[0,1], ax=axs[1])\n",
    "df.plot(kind='scatter', x='ShippingTime_maxHours', y='IsWinner', label=\"%.3f\" % df[['ShippingTime_maxHours', 'IsWinner']].corr().as_matrix()[0,1], ax=axs[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1.3: Discuss what you observe from the scatter plots and correlations, e.g., which continuous features seem to be better at predicting the target feature. Choose a subset of continuous features you find promising. Justify your choices.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Discussion of Continuous Features and Subset of promising Features for Prediction</h3>\n",
    "<p>Six Continuous Features have been compared with the target feature; IsWinner. From the above Scatter Plots, there are some assumptions that can be derived from the data, .</p>\n",
    "\n",
    "<p>Firstly, in terms of the feature <u>ShippingTime_minHours</u>, the plot displays two points of interest. Firstly in relaton to 0, which indicates is not a winner, the plot indicates that as the min shipping time increases there is a correlation that that seller will not be a winner. It is also important to note that this is note a clear correlation as having a low minimum shipping time may also result in not being selected as a winner. With regard to 1, which represents positive IsWinner, there is a clear correlation with a low minimum and being selected as IsWinner. Within this data is should also be mentioned that there are outliers which have a high minimum shipping time that are also selected as IsWinner. These highlights that it is necessary to analyse more than one feature when deciding if a seller is IsWinner</p>\n",
    "\n",
    "<p>Secondly, in terms of the feature <u>SellerFeedbackRating</u>, the plot displays the same two points of interest, 1 and 0 on the Y-axis. Firstly in relaton to 1, the plot indicates that as the SellerFeedbackRating increases there is a correlation that that seller will not be a winner. It should also be noted that this is a reasonably clear correlation as there only two outliers which have a rating either at 50% or lower being selected as IsWinner. However, in relation to 0, it is clear that having a high SellerFeedbackRating does not guarantee being selected as IsWinner, as a large amount of sellers have a high rating without being selected. From the available data also, having a low SellerFeedbackRating does necessarily result in not being selected as IsWinner. Although there are a few cases of this, the correlation is not clear.</p>\n",
    "\n",
    "<p>Thirdly, in terms of the feature <u>SellerFeedbackCount</u>, it can be argued that by having a count of 0, there is a 50/50 chance of being selected or not as IsWinner. Given the type of feature, it could be argued that perhaps many customers might have left this field blank which may skew the data. It could therefore be argued that there is no clear correlation between this feature and the target feature.</p>\n",
    "\n",
    "<p>With regard to the feature <u>ListingPrice</u>, it can be argued that by having a low ListingPrice value, there is a correlation to being selected as IsWinner. As previously argued however, there are numerous features which must be considered in selecting IsWinner, as a large amount of sellers with low listing prices where not selected as IsWinner, and a large amount with high prices that have not been selected either.</p>\n",
    "\n",
    "<p>When considering the feature <u>ShippingPrice</u>, it can be argued similarly to the ListingPrice, that having a low ShippingPrice shows a correlation to being selected as IsWinner, while it is not a defining or unique feature in deciding if a seller IsWinner, as a significant majority of the seller have low ShippingPrice, but have not been selected.</p>\n",
    "\n",
    "<p>Finally, in considering the feature <u>ShippingTime_maxHours</u>, it can be argued that having a low value for ShippingTime_maxHours is correlated with being selected as IsWinner, with the exception of an outlier with a large maximum shipping time. This could be due to human error is it is unlikely that shipping of an object would cost 1000 dollars, however this information is not available from this data set. There is no clear correlation for not being selected as IsWinner and having a high value for ShippingTime_maximum, however there are more sellers not being selected as IsWinner with high max shipping values than those with high value and being selected</p>\n",
    "\n",
    "<p>From the above information, taking into account both Scatter Plots and Correlations; two continuous features which are strongly correlated are ShippingTime_minHours and ShippingTime_maxHours. To a lesser extent, there is correlation with the SellerFeedbackRating and both ShippingTime_minHours and _maxHours. These differ in that they should be negatively correlating, but it is not as strong as the positive correlation between ShippingTime_minHours and _maxHours. Therefore the expected result would be that as Shipping Hours decreases, an increase in customer satisfaction should be noted.</p> \n",
    "\n",
    "<p>With data from correlations and the Scatter Plots against Target Features, it can be argued that no continuous feature clearly or is outright in predicting the target feature. In terms of correlations the features that are closest are from the available data are: <u>ShippingTime_minHours</u>, <u>ShippingTime_maxhours</u>, and <u>SellerFeedbackRating</u>, and these should be included in a subset pf promising features. From the Scatter Plots, <u>ListingPrice and ShippingPrice</u> seem promising at predicting the Target Feature and these will be used as the subset.</p>\n",
    "\n",
    "<p>As argued above, these 5 features are best from the data set at predicting the target feature as they have the highest correlation to having IsWinner set with a value 1, rather than 0</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1.4: For each categorical feature, plot the pairwise interaction with the target feature (barplots or stacked barplots)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to plot scatter plots for each pair of Continuous Feature and Target Feature, the Target Feature, IsWinner\n",
    "# Must be converted to a Continuous Feature\n",
    "df['IsWinner'] = df['IsWinner'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAGzCAYAAACSHN4uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACAAhF5AAAABfL/AU48plBHFcK2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623ed51748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find unique values in Fulfilled by Amazon\n",
    "IsFulfilled = pd.unique(df.IsFulfilledByAmazon.ravel())\n",
    "\n",
    "# Insert a new column called 'percent' and fill it with 0s\n",
    "df['percent'] = 0\n",
    "\n",
    "# Iterate through the unique values in Fulfilled by Amazon and for each value count the amount of Winners\n",
    "# Find the indexes of each row and for each of these row insert count * 100 in the percent column\n",
    "for c in IsFulfilled:\n",
    "    count = 1 / df[df.IsFulfilledByAmazon == c].count()['IsWinner']\n",
    "    index_list = df[df['IsFulfilledByAmazon'] == c].index.tolist()\n",
    "    for i in index_list:\n",
    "        df.loc[i, 'percent'] = count * 100\n",
    "        \n",
    "# Group dataframe by Fulfilled by Amazon and IsWinner and sum percent\n",
    "group = df[['percent','IsFulfilledByAmazon','IsWinner']].groupby(['IsFulfilledByAmazon','IsWinner']).sum()\n",
    "\n",
    "# Plot values of group in a stacked bar chart\n",
    "my_plot = group.unstack().plot(kind='bar', stacked=True, title=\"IsWinner is or is not a IsFulfilledByAmazon\", figsize=(15,7))\n",
    "\n",
    "# Define label colours and text and add to the plot\n",
    "red_patch = mpatches.Patch(color='green', label='1')\n",
    "blue_patch = mpatches.Patch(color='blue', label='0')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "# Define x and y labels and min and max values for the y axis\n",
    "my_plot.set_xlabel(\"IsFulfilledByAmazon\")\n",
    "my_plot.set_ylabel(\"% IsWinner\")\n",
    "my_plot.set_ylim([0,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAGzCAYAAACSHN4uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKBARB4AAECB/H8QUOSy6CYnXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623edaff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find unique values in IsFeaturedMerchant\n",
    "IsMerchant = pd.unique(df.IsFeaturedMerchant.ravel())\n",
    "\n",
    "# Insert a new column called 'percent' and fill it with 0s\n",
    "df['percent'] = 0\n",
    "\n",
    "# Iterate through the unique values in IsFeaturedMerchant and for each value count the amount of Winners\n",
    "# Find the indexes of each row and for each of these row insert count * 100 in the percent column\n",
    "for c in IsMerchant:\n",
    "    count = 1 / df[df.IsFeaturedMerchant == c].count()['IsWinner']\n",
    "    index_list = df[df['IsFeaturedMerchant'] == c].index.tolist()\n",
    "    for i in index_list:\n",
    "        df.loc[i, 'percent'] = count * 100\n",
    "        \n",
    "# Group dataframe by IsFeaturedMerchant and IsWinner and sum percent\n",
    "group = df[['percent','IsFeaturedMerchant','IsWinner']].groupby(['IsFeaturedMerchant','IsWinner']).sum()\n",
    "\n",
    "# Plot values of group in a stacked bar chart\n",
    "my_plot = group.unstack().plot(kind='bar', stacked=True, title=\"IsWinner is or is not a IsFeaturedMerchant\", figsize=(15,7))\n",
    "\n",
    "# Define label colours and text and add to the plot\n",
    "red_patch = mpatches.Patch(color='green', label='1')\n",
    "blue_patch = mpatches.Patch(color='blue', label='0')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "# Define x and y labels and min and max values for the y axis\n",
    "my_plot.set_xlabel(\"IsFeaturedMerchant\")\n",
    "my_plot.set_ylabel(\"% IsWinner\")\n",
    "my_plot.set_ylim([0,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\ipykernel\\__main__.py:10: RuntimeWarning: divide by zero encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAG9CAYAAACoFr9eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnuYcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623ee751d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find unique values in ShipsFromCountry\n",
    "ShipsCountry = pd.unique(df.ShipsFromCountry.ravel())\n",
    "\n",
    "# Insert a new column called 'percent' and fill it with 0s\n",
    "df['percent'] = 0\n",
    "\n",
    "# Iterate through the unique values in ShipsFromCountry and for each value count the amount of Winners\n",
    "# Find the indexes of each row and for each of these row insert count * 100 in the percent column\n",
    "for c in ShipsCountry:\n",
    "    count = 1 / df[df.ShipsFromCountry == c].count()['IsWinner']\n",
    "    index_list = df[df['ShipsFromCountry'] == c].index.tolist()\n",
    "    for i in index_list:\n",
    "        df.loc[i, 'percent'] = count * 100\n",
    "        \n",
    "# Group dataframe by ShipsFromCountry and IsWinner and sum percent\n",
    "group = df[['percent','ShipsFromCountry','IsWinner']].groupby(['ShipsFromCountry','IsWinner']).sum()\n",
    "\n",
    "# Plot values of group in a stacked bar chart\n",
    "my_plot = group.unstack().plot(kind='bar', stacked=True, title=\"IsWinner is or is not from ShipsFromCountry\", figsize=(15,7))\n",
    "\n",
    "# Define label colours and text and add to the plot\n",
    "red_patch = mpatches.Patch(color='green', label='1')\n",
    "blue_patch = mpatches.Patch(color='blue', label='0')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "# Define x and y labels and min and max values for the y axis\n",
    "my_plot.set_xlabel(\"ShipsFromCountry\")\n",
    "my_plot.set_ylabel(\"% IsWinner\")\n",
    "my_plot.set_ylim([0,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\ipykernel\\__main__.py:10: RuntimeWarning: divide by zero encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAG+CAYAAAAugs3wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICryREREREREPMg/ANDff3bEekSlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623f745780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find unique values in ShipsFromState\n",
    "ShipsState = pd.unique(df.ShipsFromState.ravel())\n",
    "\n",
    "# Insert a new column called 'percent' and fill it with 0s\n",
    "df['percent'] = 0\n",
    "\n",
    "# Iterate through the unique values in ShipsFromState and for each value count the amount of Winners\n",
    "# Find the indexes of each row and for each of these row insert count * 100 in the percent column\n",
    "for c in ShipsState:\n",
    "    count = 1 / df[df.ShipsFromState == c].count()['IsWinner']\n",
    "    index_list = df[df['ShipsFromState'] == c].index.tolist()\n",
    "    for i in index_list:\n",
    "        df.loc[i, 'percent'] = count * 100\n",
    "        \n",
    "# Group dataframe by ShipsFromState and IsWinner and sum percent\n",
    "group = df[['percent','ShipsFromState','IsWinner']].groupby(['ShipsFromState','IsWinner']).sum()\n",
    "\n",
    "# Plot values of group in a stacked bar chart\n",
    "my_plot = group.unstack().plot(kind='bar', stacked=True, title=\"IsWinner is or is not from ShipsFromState\", figsize=(15,7))\n",
    "\n",
    "# Define label colours and text and add to the plot\n",
    "red_patch = mpatches.Patch(color='green', label='1')\n",
    "blue_patch = mpatches.Patch(color='blue', label='0')\n",
    "my_plot.legend(handles=[red_patch, blue_patch], frameon = True)\n",
    "\n",
    "# Define x and y labels and min and max values for the y axis\n",
    "my_plot.set_xlabel(\"ShipsFromState\")\n",
    "my_plot.set_ylabel(\"% IsWinner\")\n",
    "my_plot.set_ylim([0,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q1.5: Discuss what knowledge you gain from plotting the interaction of descriptive categorical features and the target feature, e.g., which categorical features seem to be better at predicting the target feature. Choose a subset of categorical features you find promising. Justify your choices.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Four Categorical Features have been compared with the target feature; IsWinner. From the above barcharts, there are some assumptions that can be derived from the data.</p>\n",
    "\n",
    "<p>Firstly, in terms of the featured <u>IsFulfilledByAmazon</u>, the plot displays the percentage of those who were marked as \"IsWinner\" and who were Fulfilled by Amazon, and those that were not. A significant margin of those who were winners, were also Fulfilled by Amazon. However, there is significant data that suggests that while it may be a factor that helps decide, it is not the sole deciding factor. This can be assumed from the small minority of the data set which are not Fulfilled by Amazon, but are also winners. It should be also noted that those who are Fulfilled by Amazon are not all Winners, from the data that is currently available.</p>\n",
    "\n",
    "<p>Secondly, in relation to <u>IsFeaturedMerchant</u>,  the plots indicates that a minority of those who were winners, were also featured Merchants. From the data however, it is clear that being a Featured Merchant is not required to be selected as a winner as the majority from this dataset that are winners, are not Featured Merchants.</p>\n",
    "\n",
    "<p>Thirdly, in relation to <u>ShipsFromCountry</u>, the above plots indicate that winners only come from three countries, Canada(CA), The United States(US) and Japan(JP). A minority from these countries have been selected as winners. However, as the majority from these countries are not winners being from these 3 countries does not guarantee you to a winner. However from the available data, being from these three countries that ships is a requirement to potentially be a winner.</p>\n",
    "\n",
    "<p>Finally, with regard to <u>ShipsFromState</u>, the above plots indicates that multiple states, or provinces, where orders are shipped, are winners. From the available data, in the US: CA, MI, NJ, NV, NY, and PA. From Canada: AB, BC, ON, QC and VA. Most significantly, a significant minority from BC in Canada, and PA in the US have the highest amount of winners. The above data suggests that winners must come from the listed states/provinces above, where IsWinner is true, or 1. However being from these states does not guarantee that a seller will be selected as a winner, as there is a majority that ship from these states that have not been selected as a winner. From this data, sellers of products from other states/provinces not selected as winning states/provinces cannot be selected as winners.</p>\n",
    "\n",
    "<p>The above analysis suggests that; the listed feature give different promising analysis. However, most significantly, IsFulfilledByAmazon is the most insightful statistic, where almost more than half who are Fulfilled by Amazon are winners. Concentration of winners is illustrated by ShipsFromCountry and ShipsFromState, where Canada, the US, and Japan are shipping countries that have sellers of a certain product as winners. More specifically, these winners come largely from British Columbia (BC) in Canada, and Philadelphia in the US. There is no data available for provinces in Japan. IsFeatured Merchant also has a number that have been selected as IsWinner.</p>\n",
    "\n",
    "<p>From this available information, it is suggested that the subset of promising features should contain: IsFulfilledByAmazon and IsFeaturedMerchant.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 2: Predictive Modeling: Linear Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Train a linear regression model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression is a prediction model that assumes numeric descriptive\n",
    "# and target features, and assumes linear relation between these to features\n",
    "# Therefore, target feature IsWinner must be changed to Continuous feature \n",
    "# for this section, as is considered Categorical feature in previous assignment\n",
    "df['IsWinner'] = df['IsWinner'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Train Linear Regression</u>:</h3>\n",
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ListingPrice, ShippingPrice, SellerFeedbackRating, ShippingTime_minHours, ShippingTime_maxHours</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import statsmodels package for training a linear regression model.\n",
    "import statsmodels.formula.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept       0.062730\n",
      "ListingPrice   -0.000034\n",
      "dtype: float64 \n",
      "\n",
      "Intercept        0.062492\n",
      "ShippingPrice   -0.000576\n",
      "dtype: float64 \n",
      "\n",
      "Intercept               0.384491\n",
      "SellerFeedbackRating   -0.003699\n",
      "dtype: float64 \n",
      "\n",
      "Intercept                0.063954\n",
      "ShippingTime_minHours   -0.000151\n",
      "dtype: float64 \n",
      "\n",
      "Intercept                0.066906\n",
      "ShippingTime_maxHours   -0.000130\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the linear regression model.\n",
    "# In this section, we train a simple linear regression with all descriptive features.\n",
    "# For training the model we call the method fit() on the given data stored in our df dataframe.\n",
    "lm1 = sm.ols(formula=\"IsWinner ~  ListingPrice\", data=df).fit()\n",
    "lm2 = sm.ols(formula=\"IsWinner ~  ShippingPrice\", data=df).fit()\n",
    "lm3 = sm.ols(formula=\"IsWinner ~  SellerFeedbackRating\", data=df).fit()\n",
    "lm4 = sm.ols(formula=\"IsWinner ~  ShippingTime_minHours\", data=df).fit()\n",
    "lm5 = sm.ols(formula=\"IsWinner ~  ShippingTime_maxHours\", data=df).fit()\n",
    "\n",
    "# Print the model weights/parameters\n",
    "print(lm1.params, \"\\n\")\n",
    "print(lm2.params, \"\\n\")\n",
    "print(lm3.params, \"\\n\")\n",
    "print(lm4.params, \"\\n\")\n",
    "print(lm5.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p><i><u>Single Linear Regressions using each Continuous Features</u></i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ListingPrice</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.059517\n",
       "1       0.059061\n",
       "2       0.059296\n",
       "3       0.059338\n",
       "4       0.058988\n",
       "5       0.058741\n",
       "6       0.058468\n",
       "7       0.058626\n",
       "8       0.058433\n",
       "9       0.058585\n",
       "10      0.058180\n",
       "11      0.058500\n",
       "12      0.057959\n",
       "13      0.058057\n",
       "14      0.058244\n",
       "15      0.057936\n",
       "16      0.057742\n",
       "17      0.057594\n",
       "18      0.057576\n",
       "19      0.060042\n",
       "20      0.059666\n",
       "21      0.059625\n",
       "22      0.059945\n",
       "23      0.059908\n",
       "24      0.060198\n",
       "25      0.059799\n",
       "26      0.059512\n",
       "27      0.059399\n",
       "28      0.059220\n",
       "29      0.059000\n",
       "          ...   \n",
       "9856    0.060651\n",
       "9857    0.060416\n",
       "9858    0.060133\n",
       "9859    0.060615\n",
       "9860    0.059722\n",
       "9861    0.059561\n",
       "9862    0.059423\n",
       "9863    0.058947\n",
       "9864    0.059116\n",
       "9865    0.058141\n",
       "9866    0.058951\n",
       "9867    0.060814\n",
       "9868    0.060680\n",
       "9869    0.060714\n",
       "9870    0.060385\n",
       "9871    0.060382\n",
       "9872    0.060707\n",
       "9873    0.060336\n",
       "9874    0.060327\n",
       "9875    0.060658\n",
       "9876    0.060651\n",
       "9877    0.060416\n",
       "9878    0.060133\n",
       "9879    0.060615\n",
       "9880    0.059722\n",
       "9881    0.059561\n",
       "9882    0.059423\n",
       "9883    0.058947\n",
       "9884    0.059116\n",
       "9885    0.058141\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the ListingPrice value from all 9886 rows\n",
    "lm1.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3194.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ListingPrice\n",
       "0          3.24\n",
       "1       3194.32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ListingPrice in our dataset.\n",
    "X_minmax1 = pd.DataFrame({'ListingPrice': [df.ListingPrice.min(), df.ListingPrice.max()]})\n",
    "X_minmax1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.062620\n",
       "1   -0.046455\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ListingPrice values and store them.\n",
    "predictions1 = lm1.predict(X_minmax1)\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623f5f2128>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wdHQ7C4KmB8IAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623f5b0d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ListingPrice', y='IsWinner')\n",
    "\n",
    "# Next, plot the regression line, in red.\n",
    "plt.plot(X_minmax1, predictions1, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ListingPrice</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                  0.001\n",
      "Method:                 Least Squares   F-statistic:                     14.56\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):           0.000136\n",
      "Time:                        08:53:05   Log-Likelihood:                 568.16\n",
      "No. Observations:                9886   AIC:                            -1132.\n",
      "Df Residuals:                    9884   BIC:                            -1118.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        0.0627      0.003     20.864      0.000       0.057       0.069\n",
      "ListingPrice -3.418e-05   8.96e-06     -3.816      0.000   -5.17e-05   -1.66e-05\n",
      "==============================================================================\n",
      "Omnibus:                     7633.594   Durbin-Watson:                   2.090\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            95396.972\n",
      "Skew:                           3.881   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.090   Cond. No.                         439.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.2: Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model)</h3>\n",
    "<p><u>Continuous Feature</u>: ListingPrice</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>As mentioned above, the model learned is: IsWinner = 0.062730 + (-0.000034) * ListingPrice. This means that for a increase in ListingPrice, we have a (-0.000034) decrease in chance of being IsWinner. This was used to predict the probability of being selected IsWinner, given a ListingPrice.\n",
    "</b></p>\n",
    "<p>This section will focus on the summary table for the feature ListingPrice. \n",
    "Focusing on the coeficient for weight this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "The Null Hypothesis states that there is no relationship between ListingPrice and IsWinner. It is rejected if the 95% confidence interval does not include zero. Similarly, for the feature weight to be statistically significant at 95% confidence level, the p-value has to be lower than 0.05. \n",
    "</p> \n",
    "<p>With this in mind, we can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ListingPrice is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "<p>The p-value can guide us in selecting reliable features, but we still need to evaluate the different choices we make (e.g., different sets of features or new features we may create to capture non-linear relationships).\n",
    "\n",
    "<p>R-squared is also used and is interpreted as the proportion of variance in the observed data that is explained by the model. R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model.</p> \n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ListingPrice</u> in this instance:</p>\n",
    "\n",
    "<p>For ListingPrice, the R-squared value is 0.001. This is quite a low value, indicating that less variance is explained by this model.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ShippingPrice</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.062492\n",
       "1       0.062492\n",
       "2       0.058466\n",
       "3       0.055771\n",
       "4       0.057315\n",
       "5       0.058472\n",
       "6       0.062492\n",
       "7       0.056744\n",
       "8       0.059612\n",
       "9       0.056744\n",
       "10      0.062492\n",
       "11      0.055034\n",
       "12      0.062492\n",
       "13      0.059301\n",
       "14      0.053859\n",
       "15      0.058461\n",
       "16      0.061720\n",
       "17      0.062492\n",
       "18      0.062492\n",
       "19      0.056163\n",
       "20      0.062492\n",
       "21      0.062492\n",
       "22      0.056744\n",
       "23      0.056744\n",
       "24      0.050001\n",
       "25      0.055978\n",
       "26      0.059612\n",
       "27      0.059612\n",
       "28      0.054896\n",
       "29      0.058461\n",
       "          ...   \n",
       "9856    0.054867\n",
       "9857    0.056762\n",
       "9858    0.059612\n",
       "9859    0.050254\n",
       "9860    0.058524\n",
       "9861    0.058173\n",
       "9862    0.055673\n",
       "9863    0.059036\n",
       "9864    0.053704\n",
       "9865    0.062492\n",
       "9866    0.036778\n",
       "9867    0.056030\n",
       "9868    0.057890\n",
       "9869    0.057315\n",
       "9870    0.062492\n",
       "9871    0.062492\n",
       "9872    0.056744\n",
       "9873    0.062492\n",
       "9874    0.062492\n",
       "9875    0.056744\n",
       "9876    0.054867\n",
       "9877    0.056762\n",
       "9878    0.059612\n",
       "9879    0.050254\n",
       "9880    0.058524\n",
       "9881    0.058173\n",
       "9882    0.055673\n",
       "9883    0.059036\n",
       "9884    0.053704\n",
       "9885    0.062492\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the ShippingPrice value from all 9886 rows\n",
    "lm2.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShippingPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>705.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShippingPrice\n",
       "0           0.00\n",
       "1         705.27"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ShippingPrice in our dataset.\n",
    "X_minmax2 = pd.DataFrame({'ShippingPrice': [df.ShippingPrice.min(), df.ShippingPrice.max()]})\n",
    "X_minmax2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.062492\n",
       "1   -0.343668\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ShippingPrice values and store them.\n",
    "predictions2 = lm2.predict(X_minmax2)\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623f6c1710>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFXCAYAAAC7nNf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623dca8358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ShippingPrice', y='IsWinner')\n",
    "\n",
    "# Next, plot the regression line, in red.\n",
    "plt.plot(X_minmax2, predictions2, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingPrice</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.004\n",
      "Method:                 Least Squares   F-statistic:                     44.16\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):           3.19e-11\n",
      "Time:                        08:53:11   Log-Likelihood:                 582.91\n",
      "No. Observations:                9886   AIC:                            -1162.\n",
      "Df Residuals:                    9884   BIC:                            -1147.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         0.0625      0.003     24.652      0.000       0.058       0.067\n",
      "ShippingPrice    -0.0006   8.67e-05     -6.645      0.000      -0.001      -0.000\n",
      "==============================================================================\n",
      "Omnibus:                     7605.975   Durbin-Watson:                   2.087\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            94196.872\n",
      "Skew:                           3.865   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.997   Cond. No.                         32.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.2: Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model)</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingPrice</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>The model learned is: IsWinner = 0.062492 + (-0.000576) * ShippingPrice. This means that for a increase in ShippingPrice, we have a (-0.000576) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a ShippingPrice\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ShippingPrice. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ShippingPrice is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ShippingPrice</u> in this instance:</p>\n",
    "\n",
    "<p>For ShippingPrice, the R-squared value is 0.004. This is quite a low value, indicating that less variance is explained by this model.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: SellerFeedbackRating</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.384491\n",
       "1       0.033045\n",
       "2       0.021947\n",
       "3       0.033045\n",
       "4       0.036745\n",
       "5       0.136629\n",
       "6       0.014548\n",
       "7       0.029346\n",
       "8       0.047843\n",
       "9       0.029346\n",
       "10      0.029346\n",
       "11      0.029346\n",
       "12      0.036745\n",
       "13      0.014548\n",
       "14      0.036745\n",
       "15      0.029346\n",
       "16      0.014548\n",
       "17      0.014548\n",
       "18      0.014548\n",
       "19      0.021947\n",
       "20      0.029346\n",
       "21      0.384491\n",
       "22      0.029346\n",
       "23      0.029346\n",
       "24      0.040444\n",
       "25      0.033045\n",
       "26      0.047843\n",
       "27      0.047843\n",
       "28      0.058941\n",
       "29      0.029346\n",
       "          ...   \n",
       "9856    0.014548\n",
       "9857    0.029346\n",
       "9858    0.047843\n",
       "9859    0.040444\n",
       "9860    0.014548\n",
       "9861    0.047843\n",
       "9862    0.058941\n",
       "9863    0.029346\n",
       "9864    0.384491\n",
       "9865    0.021947\n",
       "9866    0.029346\n",
       "9867    0.033045\n",
       "9868    0.021947\n",
       "9869    0.073739\n",
       "9870    0.384491\n",
       "9871    0.029346\n",
       "9872    0.029346\n",
       "9873    0.036745\n",
       "9874    0.014548\n",
       "9875    0.029346\n",
       "9876    0.014548\n",
       "9877    0.029346\n",
       "9878    0.047843\n",
       "9879    0.040444\n",
       "9880    0.014548\n",
       "9881    0.047843\n",
       "9882    0.058941\n",
       "9883    0.029346\n",
       "9884    0.384491\n",
       "9885    0.021947\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the SellerFeedbackRating value from all 9886 rows\n",
    "lm3.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SellerFeedbackRating\n",
       "0                     0\n",
       "1                   100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max SellerFeedbackRatings in our dataset.\n",
    "X_minmax3 = pd.DataFrame({'SellerFeedbackRating': [df.SellerFeedbackRating.min(), df.SellerFeedbackRating.max()]})\n",
    "X_minmax3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.384491\n",
       "1    0.014548\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max SellerFeedbackRating values and store them.\n",
    "predictions3 = lm3.predict(X_minmax3)\n",
    "predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623eec8668>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623f78c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='SellerFeedbackRating', y='IsWinner')\n",
    "\n",
    "# Next, plot the regression line, in red.\n",
    "plt.plot(X_minmax3, predictions3, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: SellerFeedbackRating</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.122\n",
      "Model:                            OLS   Adj. R-squared:                  0.122\n",
      "Method:                 Least Squares   F-statistic:                     1369.\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):          7.32e-281\n",
      "Time:                        08:53:15   Log-Likelihood:                 1202.3\n",
      "No. Observations:                9886   AIC:                            -2401.\n",
      "Df Residuals:                    9884   BIC:                            -2386.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept                0.3845      0.009     42.011      0.000       0.367       0.402\n",
      "SellerFeedbackRating    -0.0037     0.0001    -37.006      0.000      -0.004      -0.004\n",
      "==============================================================================\n",
      "Omnibus:                     7022.782   Durbin-Watson:                   2.173\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            86820.267\n",
      "Skew:                           3.428   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.797   Cond. No.                         389.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.2: Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model)</h3>\n",
    "<p><u>Continuous Feature</u>: SellerFeedbackRating</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>The model learned is: IsWinner = 0.384494 + (-0.003699) * SellerFeedbackRating. This means that for a increase in SellerFeedbackrating, we have a (-0.003699) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a SellerFeedbackRating\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ListingPrice. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis. \n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature SellerFeedbackRating is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>SellerFeedbackRating</u> in this instance:</p>\n",
    "\n",
    "<p>For SellerFeedbackRating, the R-squared value is 0.0122. This is quite a low value, indicating that less variance is explained by this model.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ShippingTime_minHours</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.037233\n",
       "1       0.056726\n",
       "2       0.060340\n",
       "3       0.060340\n",
       "4       0.060340\n",
       "5       0.060340\n",
       "6       0.060340\n",
       "7       0.049498\n",
       "8       0.060340\n",
       "9       0.049498\n",
       "10      0.049498\n",
       "11      0.060340\n",
       "12      0.060340\n",
       "13      0.060340\n",
       "14      0.060340\n",
       "15      0.060340\n",
       "16      0.049498\n",
       "17      0.053112\n",
       "18      0.053112\n",
       "19      0.060340\n",
       "20      0.049498\n",
       "21     -0.037233\n",
       "22      0.049498\n",
       "23      0.049498\n",
       "24      0.060340\n",
       "25      0.060340\n",
       "26      0.060340\n",
       "27      0.060340\n",
       "28      0.049498\n",
       "29      0.060340\n",
       "          ...   \n",
       "9856    0.060340\n",
       "9857    0.060340\n",
       "9858    0.060340\n",
       "9859    0.060340\n",
       "9860    0.060340\n",
       "9861    0.053112\n",
       "9862    0.049498\n",
       "9863    0.060340\n",
       "9864    0.060340\n",
       "9865    0.060340\n",
       "9866    0.049498\n",
       "9867    0.060340\n",
       "9868    0.056726\n",
       "9869    0.060340\n",
       "9870    0.063954\n",
       "9871    0.049498\n",
       "9872    0.049498\n",
       "9873    0.060340\n",
       "9874    0.060340\n",
       "9875    0.049498\n",
       "9876    0.060340\n",
       "9877    0.060340\n",
       "9878    0.060340\n",
       "9879    0.060340\n",
       "9880    0.060340\n",
       "9881    0.053112\n",
       "9882    0.049498\n",
       "9883    0.060340\n",
       "9884    0.060340\n",
       "9885    0.060340\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the ShippingTime_minHours value from all 9886 rows\n",
    "lm4.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShippingTime_minHours\n",
       "0                      0\n",
       "1                    672"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ShippingTime_minHours in our dataset\n",
    "X_minmax4 = pd.DataFrame({'ShippingTime_minHours': [df.ShippingTime_minHours.min(), df.ShippingTime_minHours.max()]})\n",
    "X_minmax4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.063954\n",
       "1   -0.037233\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ShippingTime_minHours values and store them.\n",
    "predictions4 = lm4.predict(X_minmax4)\n",
    "predictions4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623ff8ea90>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAFXCAYAAABUXrzKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26240022eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ShippingTime_minHours', y='IsWinner')\n",
    "\n",
    "# Next, plot the regression line, in red.\n",
    "plt.plot(X_minmax4, predictions4, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingTime_minHours</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.003\n",
      "Model:                            OLS   Adj. R-squared:                  0.003\n",
      "Method:                 Least Squares   F-statistic:                     29.48\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):           5.79e-08\n",
      "Time:                        08:53:19   Log-Likelihood:                 575.60\n",
      "No. Observations:                9886   AIC:                            -1147.\n",
      "Df Residuals:                    9884   BIC:                            -1133.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.0640      0.003     22.907      0.000       0.058       0.069\n",
      "ShippingTime_minHours    -0.0002   2.77e-05     -5.429      0.000      -0.000   -9.62e-05\n",
      "==============================================================================\n",
      "Omnibus:                     7619.453   Durbin-Watson:                   2.070\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            94815.084\n",
      "Skew:                           3.873   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.046   Cond. No.                         122.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.2: Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model)</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingTime_minHours</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>The model learned is: IsWinner = 0.063954 + (-0.000151) * ShippingTime_minHours. This means that for a increase in ShippingTime_minHours, we have a (-0.000151) decrease in chance of being IsWinner.\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ListingPrice. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis. \n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ShippingTime_minHours is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ShippingTime_minHours</u> in this instance:</p>\n",
    "\n",
    "<p>For ShippingTime_minHours, the R-squared value is 0.003. This is quite a low value, indicating that less variance is explained by this model.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ShippingTime_maxHours</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.064381\n",
       "1       0.057529\n",
       "2       0.060654\n",
       "3       0.060654\n",
       "4       0.060654\n",
       "5       0.060654\n",
       "6       0.060654\n",
       "7       0.051277\n",
       "8       0.060654\n",
       "9       0.051277\n",
       "10      0.051277\n",
       "11      0.060654\n",
       "12      0.060654\n",
       "13      0.060654\n",
       "14      0.060654\n",
       "15      0.060654\n",
       "16      0.051277\n",
       "17      0.054403\n",
       "18      0.054403\n",
       "19      0.060654\n",
       "20      0.051277\n",
       "21     -0.064381\n",
       "22      0.051277\n",
       "23      0.051277\n",
       "24      0.060654\n",
       "25      0.060654\n",
       "26      0.060654\n",
       "27      0.060654\n",
       "28      0.051277\n",
       "29      0.060654\n",
       "          ...   \n",
       "9856    0.060654\n",
       "9857    0.060654\n",
       "9858    0.060654\n",
       "9859    0.060654\n",
       "9860    0.060654\n",
       "9861    0.054403\n",
       "9862    0.051277\n",
       "9863    0.060654\n",
       "9864    0.060654\n",
       "9865    0.060654\n",
       "9866    0.051277\n",
       "9867    0.060654\n",
       "9868    0.057529\n",
       "9869    0.060654\n",
       "9870    0.066906\n",
       "9871    0.051277\n",
       "9872    0.051277\n",
       "9873    0.060654\n",
       "9874    0.060654\n",
       "9875    0.051277\n",
       "9876    0.060654\n",
       "9877    0.060654\n",
       "9878    0.060654\n",
       "9879    0.060654\n",
       "9880    0.060654\n",
       "9881    0.054403\n",
       "9882    0.051277\n",
       "9883    0.060654\n",
       "9884    0.060654\n",
       "9885    0.060654\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the ShippingTime_maxHours value from all 9886 rows\n",
    "lm5.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShippingTime_maxHours\n",
       "0                      0\n",
       "1                   1008"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ShippingTime_maxHours in our dataset\n",
    "X_minmax5 = pd.DataFrame({'ShippingTime_maxHours': [df.ShippingTime_maxHours.min(), df.ShippingTime_maxHours.max()]})\n",
    "X_minmax5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.066906\n",
       "1   -0.064381\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ShippingTime_maxHours values and store them.\n",
    "predictions6 = lm5.predict(X_minmax5)\n",
    "predictions6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x262400afc18>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623f6957f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ShippingTime_maxHours', y='IsWinner')\n",
    "\n",
    "# Next, plot the regression line, in red.\n",
    "plt.plot(X_minmax5, predictions6, c='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingTime_maxHours</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     46.71\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):           8.70e-12\n",
      "Time:                        08:53:23   Log-Likelihood:                 584.19\n",
      "No. Observations:                9886   AIC:                            -1164.\n",
      "Df Residuals:                    9884   BIC:                            -1150.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.0669      0.003     23.463      0.000       0.061       0.072\n",
      "ShippingTime_maxHours    -0.0001   1.91e-05     -6.835      0.000      -0.000   -9.29e-05\n",
      "==============================================================================\n",
      "Omnibus:                     7603.369   Durbin-Watson:                   2.065\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            94148.869\n",
      "Skew:                           3.863   Prob(JB):                         0.00\n",
      "Kurtosis:                      15.995   Cond. No.                         186.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.2: Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model)</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingTime_maxHours</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>The model learned is: IsWinner = 0.066906 + (-0.000130) * ShippingTime_maxHours This means that for a increase in ShippingTime_maxHours, we have a (-0.000130) decrease in chance of being IsWinner.\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ListingPrice. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ShippingTime_maxHours is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ShippingTime_maxHours</u> in this instance:</p>\n",
    "\n",
    "<p>For ShippingTime_maxHours, the R-squared value is 0.005. This is quite a low value, indicating that less variance is explained by this model.</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p><i><u>Multiple Linear Regressions using subset of Continuous Features</u></i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: All of subset Continuous Features</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                0.525153\n",
      "ListingPrice            -0.000017\n",
      "ShippingPrice           -0.000279\n",
      "SellerFeedbackRating    -0.004652\n",
      "ShippingTime_minHours    0.002697\n",
      "ShippingTime_maxHours   -0.002288\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the linear regression model.\n",
    "# In this section, we train a simple linear regression with all descriptive features.\n",
    "# For training the model we call the method fit() on the given data stored in our df dataframe.\n",
    "lm7 = sm.ols(formula=\"IsWinner ~  ListingPrice + ShippingPrice + SellerFeedbackRating + ShippingTime_minHours + ShippingTime_maxHours\", data=df).fit()\n",
    "\n",
    "# Print the model weights/parameters\n",
    "# This gives different weights for the model than doing the weights separately\n",
    "print(lm7.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.030187\n",
       "1       0.046204\n",
       "2       0.020583\n",
       "3       0.033253\n",
       "4       0.038482\n",
       "5       0.164520\n",
       "6       0.012825\n",
       "7       0.058220\n",
       "8       0.053279\n",
       "9       0.058200\n",
       "10      0.060786\n",
       "11      0.027836\n",
       "12      0.040488\n",
       "13      0.011080\n",
       "14      0.036446\n",
       "15      0.029221\n",
       "16      0.041592\n",
       "17      0.032062\n",
       "18      0.032053\n",
       "19      0.019831\n",
       "20      0.061511\n",
       "21      0.030240\n",
       "22      0.058863\n",
       "23      0.058845\n",
       "24      0.040181\n",
       "25      0.033578\n",
       "26      0.053806\n",
       "27      0.053750\n",
       "28      0.094828\n",
       "29      0.029739\n",
       "          ...   \n",
       "9856    0.010196\n",
       "9857    0.029606\n",
       "9858    0.054108\n",
       "9859    0.040507\n",
       "9860    0.011515\n",
       "9861    0.072795\n",
       "9862    0.095304\n",
       "9863    0.029992\n",
       "9864    0.474061\n",
       "9865    0.021970\n",
       "9866    0.048708\n",
       "9867    0.034098\n",
       "9868    0.030810\n",
       "9869    0.085841\n",
       "9870    0.524010\n",
       "9871    0.061859\n",
       "9872    0.059234\n",
       "9873    0.041646\n",
       "9874    0.013731\n",
       "9875    0.059211\n",
       "9876    0.010196\n",
       "9877    0.029606\n",
       "9878    0.054108\n",
       "9879    0.040507\n",
       "9880    0.011515\n",
       "9881    0.072795\n",
       "9882    0.095304\n",
       "9883    0.029992\n",
       "9884    0.474061\n",
       "9885    0.021970\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the subset of all promising Continuous Feature values from all 9886 rows\n",
    "lm7.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: All Continuous Features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.185\n",
      "Model:                            OLS   Adj. R-squared:                  0.185\n",
      "Method:                 Least Squares   F-statistic:                     449.3\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):               0.00\n",
      "Time:                        08:53:28   Log-Likelihood:                 1573.5\n",
      "No. Observations:                9886   AIC:                            -3135.\n",
      "Df Residuals:                    9880   BIC:                            -3092.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.5252      0.010     50.655      0.000       0.505       0.545\n",
      "ListingPrice          -1.666e-05   8.19e-06     -2.035      0.042   -3.27e-05   -6.09e-07\n",
      "ShippingPrice            -0.0003   7.95e-05     -3.507      0.000      -0.000      -0.000\n",
      "SellerFeedbackRating     -0.0047      0.000    -44.502      0.000      -0.005      -0.004\n",
      "ShippingTime_minHours     0.0027      0.000     13.210      0.000       0.002       0.003\n",
      "ShippingTime_maxHours    -0.0023      0.000    -16.249      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     7039.427   Durbin-Watson:                   2.070\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            95612.855\n",
      "Skew:                           3.393   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.641   Cond. No.                     1.75e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.75e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(lm7.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.2: Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model)</h3>\n",
    "<p><u>Continuous Feature</u>: All Continuous Features</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>This section will focus on the summary table for <b><u>all Continuous Features from the subset</u></b>.\n",
    "<p>This section was added to focus on how the R-squared value is shaped when taking Single Regressions firstly from the individual Continuous Features, and then with Multiple Regressions, as is the case here with all of the selected subset of Continuous Features.</p>\n",
    "Focusing on the coeficient weights of these features, column 'coef' in the table, on the p-values, column 'P>|t|' and confidence intervals, column '[95.0% Conf. Int.]', which describes the features' statistical significances via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weights is statistically significant (p-value = 0.000).\n",
    "The weight for the feature ListingPrice has questionable statistical significance (p-value less than 0.05, ListingPrice: p-value = 0.040. For the purpose of retraining, it will be removed from the following section.\n",
    "</p>\n",
    "\n",
    "<p>R-squared is also used and is interpreted as the proportion of variance in the observed data that is explained by the model. R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model.</p>\n",
    "\n",
    "<p>Multiple Regression model with <b><u>all Continuous Features</u></b> in this instance:</p>\n",
    "\n",
    "<p><u>Previously, the R-squared values for each individual Continuous Feature were as follows:</u></p>\n",
    "<p>For <u>ListingPrice</u>, the R-squared value is 0.001.</p>\n",
    "<p>For <u>ShippingPrice</u>, the R-squared value is 0.004.</p>\n",
    "<p>For <u>SellerFeedbackRating</u>, the R-squared value is 0.0122.</p>\n",
    "<p>For <u>ShippingTime_minHours</u>, the R-squared value is 0.003.</p>\n",
    "<p>For <u>ShippingTime_maxHours</u>, the R-squared value is 0.005.</p>\n",
    "\n",
    "<p>These were all quite low values, indicating that less variance is explained by this model.</p>\n",
    "\n",
    "<p>By including all selected Continuous Features in a Multiple Regression, the result is a model with higher R-squared of 0.185.\n",
    "While this is still a low value between 0 and 1, it presents a better model looking at the R-squared measure. It should be noted however that this could be due to over-fitting of training data, which refers to capturing insignifcant details in sample training data. Out-of-sample, or test data predictions should also be performed</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(2.3) Retrain the model using only the subset of features found to be statistically significant. Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As this section is taking the full 9886 rows as training set, re-training here takes all the same rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                0.522374\n",
      "ShippingPrice           -0.000303\n",
      "SellerFeedbackRating    -0.004657\n",
      "ShippingTime_minHours    0.002696\n",
      "ShippingTime_maxHours   -0.002287\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the linear regression model.\n",
    "# In this section, we train a simple linear regression with all descriptive features.\n",
    "# For training the model we call the method fit() on the given data stored in our df dataframe.\n",
    "lm8 = sm.ols(formula=\"IsWinner ~  ShippingPrice + SellerFeedbackRating + ShippingTime_minHours + ShippingTime_maxHours\", data=df).fit()\n",
    "\n",
    "# Print the model weights/parameters\n",
    "# This gives different weights for the model than doing the weights separately\n",
    "print(lm8.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q2.3: Re-evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: All Statistically Significant Features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.185\n",
      "Model:                            OLS   Adj. R-squared:                  0.185\n",
      "Method:                 Least Squares   F-statistic:                     560.4\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):               0.00\n",
      "Time:                        08:53:34   Log-Likelihood:                 1571.5\n",
      "No. Observations:                9886   AIC:                            -3133.\n",
      "Df Residuals:                    9881   BIC:                            -3097.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.5224      0.010     50.822      0.000       0.502       0.543\n",
      "ShippingPrice            -0.0003   7.87e-05     -3.850      0.000      -0.000      -0.000\n",
      "SellerFeedbackRating     -0.0047      0.000    -44.566      0.000      -0.005      -0.004\n",
      "ShippingTime_minHours     0.0027      0.000     13.200      0.000       0.002       0.003\n",
      "ShippingTime_maxHours    -0.0023      0.000    -16.241      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     7039.524   Durbin-Watson:                   2.073\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            95570.157\n",
      "Skew:                           3.393   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.637   Cond. No.                         927.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm8.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(2.3) Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><b><u>Conclusion:</u></b></p>\n",
    "<p>The above data represents a trained model on the 9886 rows of the data set. It was used to predict a selection of values, as seen for example; min and max values. There was a difference in R-squared values between the single and multiple regression models. From the results, a multiple regression model is favoured for higher variance. In relation to the provided graphs for each Continuous Feature, they were a visual aid to see if a model is good at predicting the Target Feature. In all cases, the graphs do not indicate that is outright good at predicting the Target Feature. With regard to both the first model and the retrained model, althought p-values are below the required threshold, the model does not clearly and outrightly predict the Target Feature</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(2.4) Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Threshold the predicted target feature value at 0.5 to get the predicted class for each example</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.028719\n",
       "1       0.044651\n",
       "2       0.018749\n",
       "3       0.031304\n",
       "4       0.036773\n",
       "5       0.163135\n",
       "6       0.011551\n",
       "7       0.056595\n",
       "8       0.051954\n",
       "9       0.056595\n",
       "10      0.059617\n",
       "11      0.026259\n",
       "12      0.039496\n",
       "13      0.009873\n",
       "14      0.034956\n",
       "15      0.028061\n",
       "16      0.040582\n",
       "17      0.031175\n",
       "18      0.031175\n",
       "19      0.017538\n",
       "20      0.059617\n",
       "21      0.028719\n",
       "22      0.056595\n",
       "23      0.056595\n",
       "24      0.037584\n",
       "25      0.031413\n",
       "26      0.051954\n",
       "27      0.051954\n",
       "28      0.092883\n",
       "29      0.028061\n",
       "          ...   \n",
       "9856    0.007541\n",
       "9857    0.027168\n",
       "9858    0.051954\n",
       "9859    0.037718\n",
       "9860    0.009464\n",
       "9861    0.070821\n",
       "9862    0.093291\n",
       "9863    0.028364\n",
       "9864    0.472679\n",
       "9865    0.020866\n",
       "9866    0.046094\n",
       "9867    0.031440\n",
       "9868    0.028258\n",
       "9869    0.083348\n",
       "9870    0.522374\n",
       "9871    0.059617\n",
       "9872    0.056595\n",
       "9873    0.039496\n",
       "9874    0.011551\n",
       "9875    0.056595\n",
       "9876    0.007541\n",
       "9877    0.027168\n",
       "9878    0.051954\n",
       "9879    0.037718\n",
       "9880    0.009464\n",
       "9881    0.070821\n",
       "9882    0.093291\n",
       "9883    0.028364\n",
       "9884    0.472679\n",
       "9885    0.020866\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the predicted target feature value for all the examples in the training set (9886 rows)\n",
    "predictionsThreshold = lm8.predict(df)\n",
    "predictionsThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.163135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.059617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.026259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.039496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.034956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.028061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.040582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.031175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.031175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.017538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.059617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.028719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.037584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.031413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.092883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.028061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>0.007541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>0.027168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>0.037718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>0.009464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>0.070821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>0.093291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>0.028364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>0.472679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>0.020866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>0.046094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>0.031440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>0.028258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>0.083348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>0.522374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>0.059617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0.039496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>0.011551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>0.007541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>0.027168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>0.037718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>0.009464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>0.070821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>0.093291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>0.028364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>0.472679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>0.020866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Threshold\n",
       "0      0.028719\n",
       "1      0.044651\n",
       "2      0.018749\n",
       "3      0.031304\n",
       "4      0.036773\n",
       "5      0.163135\n",
       "6      0.011551\n",
       "7      0.056595\n",
       "8      0.051954\n",
       "9      0.056595\n",
       "10     0.059617\n",
       "11     0.026259\n",
       "12     0.039496\n",
       "13     0.009873\n",
       "14     0.034956\n",
       "15     0.028061\n",
       "16     0.040582\n",
       "17     0.031175\n",
       "18     0.031175\n",
       "19     0.017538\n",
       "20     0.059617\n",
       "21     0.028719\n",
       "22     0.056595\n",
       "23     0.056595\n",
       "24     0.037584\n",
       "25     0.031413\n",
       "26     0.051954\n",
       "27     0.051954\n",
       "28     0.092883\n",
       "29     0.028061\n",
       "...         ...\n",
       "9856   0.007541\n",
       "9857   0.027168\n",
       "9858   0.051954\n",
       "9859   0.037718\n",
       "9860   0.009464\n",
       "9861   0.070821\n",
       "9862   0.093291\n",
       "9863   0.028364\n",
       "9864   0.472679\n",
       "9865   0.020866\n",
       "9866   0.046094\n",
       "9867   0.031440\n",
       "9868   0.028258\n",
       "9869   0.083348\n",
       "9870   0.522374\n",
       "9871   0.059617\n",
       "9872   0.056595\n",
       "9873   0.039496\n",
       "9874   0.011551\n",
       "9875   0.056595\n",
       "9876   0.007541\n",
       "9877   0.027168\n",
       "9878   0.051954\n",
       "9879   0.037718\n",
       "9880   0.009464\n",
       "9881   0.070821\n",
       "9882   0.093291\n",
       "9883   0.028364\n",
       "9884   0.472679\n",
       "9885   0.020866\n",
       "\n",
       "[9886 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = pd.DataFrame({\"Threshold\" : predictionsThreshold})\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Values:\n",
      "\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Threshold the predicted target feature value at 0.5 to get the predicted class for each example\n",
    "# The left column refers to the Target Feature, while the right is the assigned predicted value\n",
    "# After the threshold has been applied\n",
    "print(\"Predicted Values:\\n\")       \n",
    "for i in predictionsThreshold:\n",
    "    if i < 0.5:\n",
    "        print(0.0) \n",
    "    else: \n",
    "        print(1.0)\n",
    "        \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 3: Predictive Modeling: Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(3.1) Train a logistic regression model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u>Train Logistic Regression</u>:</h3>\n",
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ListingPrice, ShippingPrice, SellerFeedbackRating, ShippingTime_minHours, ShippingTime_maxHours</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.213041\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.206328\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.182660\n",
      "         Iterations 7\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.210992\n",
      "         Iterations 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.206045\n",
      "         Iterations 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159468\n",
      "         Iterations 9\n",
      "Intercept      -2.669442\n",
      "ListingPrice   -0.000861\n",
      "dtype: float64 \n",
      "\n",
      "Intercept       -2.370408\n",
      "ShippingPrice   -0.062909\n",
      "dtype: float64 \n",
      "\n",
      "Intercept              -0.403409\n",
      "SellerFeedbackRating   -0.030774\n",
      "dtype: float64 \n",
      "\n",
      "Intercept               -2.456450\n",
      "ShippingTime_minHours   -0.008433\n",
      "dtype: float64 \n",
      "\n",
      "Intercept               -1.850240\n",
      "ShippingTime_maxHours   -0.015303\n",
      "dtype: float64 \n",
      "\n",
      "Intercept                1.349425\n",
      "ListingPrice            -0.000272\n",
      "ShippingPrice           -0.020707\n",
      "SellerFeedbackRating    -0.021702\n",
      "ShippingTime_minHours    0.139083\n",
      "ShippingTime_maxHours   -0.125136\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the \n",
    "# logistic regression model.\n",
    "# Firstly, simple logistic regression is calculated for all individual Continuous Features.\n",
    "# After, a multiple logistic regression is calucated for all Continuous Features together.\n",
    "\n",
    "# For training the model we call the method fit() on the given data stored in our dataframe.\n",
    "logreg1 = sm.logit(formula=\"IsWinner ~  ListingPrice\", data=df).fit()\n",
    "logreg2 = sm.logit(formula=\"IsWinner ~  ShippingPrice\", data=df).fit()\n",
    "logreg3 = sm.logit(formula=\"IsWinner ~  SellerFeedbackRating\", data=df).fit()\n",
    "logreg4 = sm.logit(formula=\"IsWinner ~  ShippingTime_minHours\", data=df).fit()\n",
    "logreg5 = sm.logit(formula=\"IsWinner ~  ShippingTime_maxHours\", data=df).fit()\n",
    "logreg6 = sm.logit(formula=\"IsWinner ~  ListingPrice + ShippingPrice + SellerFeedbackRating + ShippingTime_minHours + ShippingTime_maxHours\", data=df).fit()\n",
    "\n",
    "# Print the model weights/parameters\n",
    "print(logreg1.params, \"\\n\")\n",
    "print(logreg2.params, \"\\n\")\n",
    "print(logreg3.params, \"\\n\")\n",
    "print(logreg4.params, \"\\n\")\n",
    "print(logreg5.params, \"\\n\")\n",
    "print(logreg6.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p><i><u>Single Logistic Regressions using each Continuous Feature</u></i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ListingPrice</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.060067\n",
       "1       0.059421\n",
       "2       0.059753\n",
       "3       0.059812\n",
       "4       0.059319\n",
       "5       0.058973\n",
       "6       0.058592\n",
       "7       0.058812\n",
       "8       0.058543\n",
       "9       0.058755\n",
       "10      0.058193\n",
       "11      0.058636\n",
       "12      0.057889\n",
       "13      0.058024\n",
       "14      0.058282\n",
       "15      0.057857\n",
       "16      0.057592\n",
       "17      0.057390\n",
       "18      0.057365\n",
       "19      0.060817\n",
       "20      0.060279\n",
       "21      0.060219\n",
       "22      0.060677\n",
       "23      0.060625\n",
       "24      0.061043\n",
       "25      0.060469\n",
       "26      0.060060\n",
       "27      0.059899\n",
       "28      0.059645\n",
       "29      0.059336\n",
       "          ...   \n",
       "9856    0.061699\n",
       "9857    0.061357\n",
       "9858    0.060948\n",
       "9859    0.061647\n",
       "9860    0.060359\n",
       "9861    0.060129\n",
       "9862    0.059932\n",
       "9863    0.059261\n",
       "9864    0.059499\n",
       "9865    0.058140\n",
       "9866    0.059266\n",
       "9867    0.061937\n",
       "9868    0.061741\n",
       "9869    0.061791\n",
       "9870    0.061312\n",
       "9871    0.061307\n",
       "9872    0.061781\n",
       "9873    0.061241\n",
       "9874    0.061228\n",
       "9875    0.061709\n",
       "9876    0.061699\n",
       "9877    0.061357\n",
       "9878    0.060948\n",
       "9879    0.061647\n",
       "9880    0.060359\n",
       "9881    0.060129\n",
       "9882    0.059932\n",
       "9883    0.059261\n",
       "9884    0.059499\n",
       "9885    0.058140\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of ListingPrice\n",
    "predictionsLP = logreg1.predict(df)\n",
    "predictionsLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3194.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ListingPrice\n",
       "0          3.24\n",
       "1       3194.32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ListingPrice in our dataset\n",
    "X_minmax9 = pd.DataFrame({'ListingPrice': [df.ListingPrice.min(), df.ListingPrice.max()]})\n",
    "X_minmax9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.064632\n",
       "1    0.004412\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ListingPrice values and store them.\n",
    "predictions7 = logreg1.predict(X_minmax9)\n",
    "predictions7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623f745080>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262400d9a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ListingPrice', y='IsWinner')\n",
    "\n",
    "# Next, plot the logistic regression estimation, in red.\n",
    "plt.plot(df.ListingPrice, predictionsLP, c='yellow', linewidth=2)\n",
    "\n",
    "# Plot the linear decision surface estimated by logistic regression\n",
    "plt.plot(X_minmax9, logreg1.predict(X_minmax9), c='red', linewidth=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q3.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ListingPrice</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9884\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                0.004116\n",
      "Time:                        08:54:37   Log-Likelihood:                -2106.1\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                 3.011e-05\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       -2.6694      0.059    -44.914      0.000      -2.786      -2.553\n",
      "ListingPrice    -0.0009      0.000     -3.823      0.000      -0.001      -0.000\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(3.2) Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><b>The model learned is: IsWinner = -2.6694 + (-0.0009) * ListingPrice. This means that for a decrease in ListingPrice, we have a (-0.0009) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a ListingPrice\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ListingPrice. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ListingPrice is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ListingPrice</u> in this instance:</p>\n",
    "\n",
    "<p>For ListingPrice, the R-squared value is 0.004. This is quite a low value, indicating that less variance is explained by this model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ShippingPrice</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.085457\n",
       "1       0.085457\n",
       "2       0.056779\n",
       "3       0.042920\n",
       "4       0.050404\n",
       "5       0.056812\n",
       "6       0.085457\n",
       "7       0.047506\n",
       "8       0.063867\n",
       "9       0.047506\n",
       "10      0.085457\n",
       "11      0.039731\n",
       "12      0.085457\n",
       "13      0.061866\n",
       "14      0.035114\n",
       "15      0.056745\n",
       "16      0.079095\n",
       "17      0.085457\n",
       "18      0.085457\n",
       "19      0.044712\n",
       "20      0.085457\n",
       "21      0.085457\n",
       "22      0.047506\n",
       "23      0.047506\n",
       "24      0.023319\n",
       "25      0.043860\n",
       "26      0.063867\n",
       "27      0.063867\n",
       "28      0.039159\n",
       "29      0.056745\n",
       "          ...   \n",
       "9856    0.039041\n",
       "9857    0.047591\n",
       "9858    0.063867\n",
       "9859    0.023958\n",
       "9860    0.057117\n",
       "9861    0.055085\n",
       "9862    0.042483\n",
       "9863    0.060208\n",
       "9864    0.034543\n",
       "9865    0.085457\n",
       "9866    0.005601\n",
       "9867    0.044098\n",
       "9868    0.053502\n",
       "9869    0.050404\n",
       "9870    0.085457\n",
       "9871    0.085457\n",
       "9872    0.047506\n",
       "9873    0.085457\n",
       "9874    0.085457\n",
       "9875    0.047506\n",
       "9876    0.039041\n",
       "9877    0.047591\n",
       "9878    0.063867\n",
       "9879    0.023958\n",
       "9880    0.057117\n",
       "9881    0.055085\n",
       "9882    0.042483\n",
       "9883    0.060208\n",
       "9884    0.034543\n",
       "9885    0.085457\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of ShippingPrice\n",
    "predictionsSP = logreg2.predict(df)\n",
    "predictionsSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShippingPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>705.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShippingPrice\n",
       "0           0.00\n",
       "1         705.27"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ShippingPrice in our dataset\n",
    "X_minmax10 = pd.DataFrame({'ShippingPrice': [df.ShippingPrice.min(), df.ShippingPrice.max()]})\n",
    "X_minmax10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.545722e-02\n",
       "1    5.034368e-21\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ShippingPrice values and store them.\n",
    "predictions8 = logreg2.predict(X_minmax10)\n",
    "predictions8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623fe98b70>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262400d1c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ShippingPrice', y='IsWinner')\n",
    "\n",
    "# Next, plot the logistic regression estimation, in red.\n",
    "plt.plot(df.ShippingPrice, predictionsSP, c='yellow', linewidth=2)\n",
    "\n",
    "# Plot the linear decision surface estimated by logistic regression\n",
    "plt.plot(X_minmax10, logreg2.predict(X_minmax10), c='red', linewidth=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q3.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingPrice</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9884\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                 0.03550\n",
      "Time:                        08:54:42   Log-Likelihood:                -2039.8\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                 1.613e-34\n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        -2.3704      0.056    -42.009      0.000      -2.481      -2.260\n",
      "ShippingPrice    -0.0629      0.007     -9.483      0.000      -0.076      -0.050\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(3.2) Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><b>The model learned is: IsWinner = -2.3704 + (-0.0629) * ShippingPrice. This means that for a decrease in ShippingPrice, we have a (-0.000576) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a ShippingPrice\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ShippingPrice. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ShippingPrice is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ShippingPrice</u> in this instance:</p>\n",
    "\n",
    "<p>For ShippingPrice, the Pseudo R-squared value is 0.0355. This is quite a low value, indicating that less variance is explained by this model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: SellerFeedbackRating</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.400494\n",
       "1       0.034658\n",
       "2       0.031699\n",
       "3       0.034658\n",
       "4       0.035703\n",
       "5       0.078329\n",
       "6       0.029863\n",
       "7       0.033643\n",
       "8       0.039021\n",
       "9       0.033643\n",
       "10      0.033643\n",
       "11      0.033643\n",
       "12      0.035703\n",
       "13      0.029863\n",
       "14      0.035703\n",
       "15      0.033643\n",
       "16      0.029863\n",
       "17      0.029863\n",
       "18      0.029863\n",
       "19      0.031699\n",
       "20      0.033643\n",
       "21      0.400494\n",
       "22      0.033643\n",
       "23      0.033643\n",
       "24      0.036778\n",
       "25      0.034658\n",
       "26      0.039021\n",
       "27      0.039021\n",
       "28      0.042634\n",
       "29      0.033643\n",
       "          ...   \n",
       "9856    0.029863\n",
       "9857    0.033643\n",
       "9858    0.039021\n",
       "9859    0.036778\n",
       "9860    0.029863\n",
       "9861    0.039021\n",
       "9862    0.042634\n",
       "9863    0.033643\n",
       "9864    0.400494\n",
       "9865    0.031699\n",
       "9866    0.033643\n",
       "9867    0.034658\n",
       "9868    0.031699\n",
       "9869    0.047951\n",
       "9870    0.400494\n",
       "9871    0.033643\n",
       "9872    0.033643\n",
       "9873    0.035703\n",
       "9874    0.029863\n",
       "9875    0.033643\n",
       "9876    0.029863\n",
       "9877    0.033643\n",
       "9878    0.039021\n",
       "9879    0.036778\n",
       "9880    0.029863\n",
       "9881    0.039021\n",
       "9882    0.042634\n",
       "9883    0.033643\n",
       "9884    0.400494\n",
       "9885    0.031699\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of SellerFeedbackRating\n",
    "predictionsSFR = logreg3.predict(df)\n",
    "predictionsSFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SellerFeedbackRating\n",
       "0                     0\n",
       "1                   100"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max SellerFeedbackRating in our dataset\n",
    "X_minmax11 = pd.DataFrame({'SellerFeedbackRating': [df.SellerFeedbackRating.min(), df.SellerFeedbackRating.max()]})\n",
    "X_minmax11.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.400494\n",
       "1    0.029863\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max SellerFeedbackRating values and store them.\n",
    "predictions9 = logreg3.predict(X_minmax11)\n",
    "predictions9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623fefa390>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623ed7ac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='SellerFeedbackRating', y='IsWinner')\n",
    "\n",
    "# Next, plot the logistic regression estimation, in red.\n",
    "plt.plot(df.SellerFeedbackRating, predictionsSFR, c='yellow', linewidth=2)\n",
    "\n",
    "# Plot the linear decision surface estimated by logistic regression\n",
    "plt.plot(X_minmax11, logreg3.predict(X_minmax11), c='red', linewidth=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Q3.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: SellerFeedbackRating</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9884\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.1461\n",
      "Time:                        08:54:49   Log-Likelihood:                -1805.8\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                1.921e-136\n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept               -0.4034      0.090     -4.507      0.000      -0.579      -0.228\n",
      "SellerFeedbackRating    -0.0308      0.001    -27.248      0.000      -0.033      -0.029\n",
      "========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(3.2) Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><b>The model learned is: IsWinner = -0.4034 + (-0.0308) * SellerFeedbackRating. This means that for a decrease in SellerFeedbackRating, we have a (-0.00308) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a SellerFeedbackRating\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature SellerFeedbackRating. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature SellerFeedbackRating is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>SellerFeedbackRating</u> in this instance:</p>\n",
    "\n",
    "<p>For SellerFeedbackRating, the Pseudo R-squared value is 0.01461. This is quite a low value, indicating that less variance is explained by this model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ShippingTime_minHours</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000296\n",
       "1       0.054102\n",
       "2       0.065445\n",
       "3       0.065445\n",
       "4       0.065445\n",
       "5       0.065445\n",
       "6       0.065445\n",
       "7       0.036754\n",
       "8       0.065445\n",
       "9       0.036754\n",
       "10      0.036754\n",
       "11      0.065445\n",
       "12      0.065445\n",
       "13      0.065445\n",
       "14      0.065445\n",
       "15      0.065445\n",
       "16      0.036754\n",
       "17      0.044631\n",
       "18      0.044631\n",
       "19      0.065445\n",
       "20      0.036754\n",
       "21      0.000296\n",
       "22      0.036754\n",
       "23      0.036754\n",
       "24      0.065445\n",
       "25      0.065445\n",
       "26      0.065445\n",
       "27      0.065445\n",
       "28      0.036754\n",
       "29      0.065445\n",
       "          ...   \n",
       "9856    0.065445\n",
       "9857    0.065445\n",
       "9858    0.065445\n",
       "9859    0.065445\n",
       "9860    0.065445\n",
       "9861    0.044631\n",
       "9862    0.036754\n",
       "9863    0.065445\n",
       "9864    0.065445\n",
       "9865    0.065445\n",
       "9866    0.036754\n",
       "9867    0.065445\n",
       "9868    0.054102\n",
       "9869    0.065445\n",
       "9870    0.078968\n",
       "9871    0.036754\n",
       "9872    0.036754\n",
       "9873    0.065445\n",
       "9874    0.065445\n",
       "9875    0.036754\n",
       "9876    0.065445\n",
       "9877    0.065445\n",
       "9878    0.065445\n",
       "9879    0.065445\n",
       "9880    0.065445\n",
       "9881    0.044631\n",
       "9882    0.036754\n",
       "9883    0.065445\n",
       "9884    0.065445\n",
       "9885    0.065445\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of ShippingTime_minHours\n",
    "predictionsSTmin = logreg4.predict(df)\n",
    "predictionsSTmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShippingTime_minHours\n",
       "0                      0\n",
       "1                    672"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ShippingTime_minHours in our dataset\n",
    "X_minmax12 = pd.DataFrame({'ShippingTime_minHours': [df.ShippingTime_minHours.min(), df.ShippingTime_minHours.max()]})\n",
    "X_minmax12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.078968\n",
       "1    0.000296\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ShippingTime_minHours values and store them.\n",
    "predictions10 = logreg4.predict(X_minmax12)\n",
    "predictions10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623fa20ba8>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAFXCAYAAABUXrzKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623fa20048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ShippingTime_minHours', y='IsWinner')\n",
    "\n",
    "# Next, plot the logistic regression estimation, in red.\n",
    "plt.plot(df.ShippingTime_minHours, predictionsSTmin, c='yellow', linewidth=2)\n",
    "\n",
    "# Plot the linear decision surface estimated by logistic regression\n",
    "plt.plot(X_minmax12, logreg4.predict(X_minmax12), c='red', linewidth=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q3.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingTime_minHours</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9884\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                 0.01370\n",
      "Time:                        08:54:55   Log-Likelihood:                -2085.9\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                 2.706e-14\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -2.4564      0.070    -35.302      0.000      -2.593      -2.320\n",
      "ShippingTime_minHours    -0.0084      0.001     -6.112      0.000      -0.011      -0.006\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(3.2) Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><b>The model learned is: IsWinner = -2.4564 + (-0.0084) * ShippingTime_minHours. This means that for a decrease in ShippingTime_minHours, we have a (-0.0084) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a ShippingTime_minHours\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ShippingTime_minHours. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ShippingTime_minHours is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ShippingTime_minHours</u> in this instance:</p>\n",
    "\n",
    "<p>For ShippingTime_minHours, the R-squared value is 0.01370. This is quite a low value, indicating that less variance is explained by this model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: ShippingTime_maxHours</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3.141636e-08\n",
       "1       4.963850e-02\n",
       "2       7.012327e-02\n",
       "3       7.012327e-02\n",
       "4       7.012327e-02\n",
       "5       7.012327e-02\n",
       "6       7.012327e-02\n",
       "7       2.444376e-02\n",
       "8       7.012327e-02\n",
       "9       2.444376e-02\n",
       "10      2.444376e-02\n",
       "11      7.012327e-02\n",
       "12      7.012327e-02\n",
       "13      7.012327e-02\n",
       "14      7.012327e-02\n",
       "15      7.012327e-02\n",
       "16      2.444376e-02\n",
       "17      3.491316e-02\n",
       "18      3.491316e-02\n",
       "19      7.012327e-02\n",
       "20      2.444376e-02\n",
       "21      3.141636e-08\n",
       "22      2.444376e-02\n",
       "23      2.444376e-02\n",
       "24      7.012327e-02\n",
       "25      7.012327e-02\n",
       "26      7.012327e-02\n",
       "27      7.012327e-02\n",
       "28      2.444376e-02\n",
       "29      7.012327e-02\n",
       "            ...     \n",
       "9856    7.012327e-02\n",
       "9857    7.012327e-02\n",
       "9858    7.012327e-02\n",
       "9859    7.012327e-02\n",
       "9860    7.012327e-02\n",
       "9861    3.491316e-02\n",
       "9862    2.444376e-02\n",
       "9863    7.012327e-02\n",
       "9864    7.012327e-02\n",
       "9865    7.012327e-02\n",
       "9866    2.444376e-02\n",
       "9867    7.012327e-02\n",
       "9868    4.963850e-02\n",
       "9869    7.012327e-02\n",
       "9870    1.358447e-01\n",
       "9871    2.444376e-02\n",
       "9872    2.444376e-02\n",
       "9873    7.012327e-02\n",
       "9874    7.012327e-02\n",
       "9875    2.444376e-02\n",
       "9876    7.012327e-02\n",
       "9877    7.012327e-02\n",
       "9878    7.012327e-02\n",
       "9879    7.012327e-02\n",
       "9880    7.012327e-02\n",
       "9881    3.491316e-02\n",
       "9882    2.444376e-02\n",
       "9883    7.012327e-02\n",
       "9884    7.012327e-02\n",
       "9885    7.012327e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of ShippingTime_maxHours\n",
    "predictionsSTmax = logreg5.predict(df)\n",
    "predictionsSTmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ShippingTime_maxHours\n",
       "0                      0\n",
       "1                   1008"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can plot the regression line that was estimated from our training set.\n",
    "# First we use the trained model to predict IsWinner for the min and max ShippingTime_maxHours in our dataset\n",
    "X_minmax13 = pd.DataFrame({'ShippingTime_maxHours': [df.ShippingTime_maxHours.min(), df.ShippingTime_maxHours.max()]})\n",
    "X_minmax13.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.358447e-01\n",
       "1    3.141636e-08\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions for the min and max ShippingTime_maxHours values and store them.\n",
    "predictions11 = logreg5.predict(X_minmax13)\n",
    "predictions11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2623fa8e898>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFXCAYAAACLEMbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2623fa95780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='ShippingTime_maxHours', y='IsWinner')\n",
    "\n",
    "# Next, plot the logistic regression estimation, in red.\n",
    "plt.plot(df.ShippingTime_maxHours, predictionsSTmax, c='yellow', linewidth=2)\n",
    "\n",
    "# Plot the linear decision surface estimated by logistic regression\n",
    "plt.plot(X_minmax13, logreg5.predict(X_minmax13), c='red', linewidth=1, linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Q3.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: ShippingTime_maxHours</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9884\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                 0.03682\n",
      "Time:                        08:55:01   Log-Likelihood:                -2037.0\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                 9.607e-36\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                -1.8502      0.098    -18.936      0.000      -2.042      -1.659\n",
      "ShippingTime_maxHours    -0.0153      0.002     -9.730      0.000      -0.018      -0.012\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(3.2) Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p><b>The model learned is: IsWinner = -1.8502 + (-0.0153) * ShippingTime_maxHours. This means that for a decrease in ShippingTime_maxHours, we have a (-0.00153) decrease in chance of being IsWinner. This model has been used to predict the probability of being selected given a ShippingTime_maxHours\n",
    "</b>\n",
    "</p>\n",
    "<p>This section will focus on the summary table for the feature ShippingTime_maxHours. \n",
    "Focusing on the coeficient weight for this feature, column 'coef' in the table, on the p-value, column 'P>|t|' and confidence interval, column '[95.0% Conf. Int.]', which describes the features statistical significance via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weight is statistically significant (p-value = 0.000).\n",
    "The weight for feature ShippingTime_maxHours is found to be statistically significant (p-value less than 0.05, p-value = 0.000).\n",
    "</p>\n",
    "\n",
    "<p>We can use R-squared to compare different models. In this case, we will focus on the simple regression model with only one feature, <u>ShippingTime_maxHours</u> in this instance:</p>\n",
    "\n",
    "<p>For ShippingTime_maxHours, the Pseudo R-squared value is 0.03682. This is quite a low value, indicating that less variance is explained by this model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><p><i><u>Multiple Regressions using subset of Continuous Features</u></i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4><p><i><u>Target Feature</u></i>: IsWinner</p>\n",
    "<p><i><u>Continuous Features</u></i>: Subset of all Continuous Features</p></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.426241e-14\n",
       "1       4.413834e-02\n",
       "2       2.613559e-02\n",
       "3       2.534643e-02\n",
       "4       2.725112e-02\n",
       "5       4.976401e-02\n",
       "6       2.865860e-02\n",
       "7       6.675328e-02\n",
       "8       3.131864e-02\n",
       "9       6.673313e-02\n",
       "10      8.057519e-02\n",
       "11      2.402556e-02\n",
       "12      3.238749e-02\n",
       "13      2.555073e-02\n",
       "14      2.400515e-02\n",
       "15      2.697248e-02\n",
       "16      7.225238e-02\n",
       "17      5.412860e-02\n",
       "18      5.412137e-02\n",
       "19      2.424810e-02\n",
       "20      8.145507e-02\n",
       "21      2.428313e-14\n",
       "22      6.740970e-02\n",
       "23      6.739142e-02\n",
       "24      2.173876e-02\n",
       "25      2.562263e-02\n",
       "26      3.158018e-02\n",
       "27      3.155268e-02\n",
       "28      7.406937e-02\n",
       "29      2.719544e-02\n",
       "            ...     \n",
       "9856    2.231287e-02\n",
       "9857    2.590777e-02\n",
       "9858    3.173141e-02\n",
       "9859    2.200461e-02\n",
       "9860    2.518692e-02\n",
       "9861    5.705010e-02\n",
       "9862    7.612300e-02\n",
       "9863    2.773729e-02\n",
       "9864    1.592456e-01\n",
       "9865    2.981663e-02\n",
       "9866    3.379761e-02\n",
       "9867    2.587173e-02\n",
       "9868    3.581344e-02\n",
       "9869    3.408273e-02\n",
       "9870    7.909686e-01\n",
       "9871    8.188173e-02\n",
       "9872    6.779175e-02\n",
       "9873    3.298493e-02\n",
       "9874    2.907294e-02\n",
       "9875    6.776719e-02\n",
       "9876    2.231287e-02\n",
       "9877    2.590777e-02\n",
       "9878    3.173141e-02\n",
       "9879    2.200461e-02\n",
       "9880    2.518692e-02\n",
       "9881    5.705010e-02\n",
       "9882    7.612300e-02\n",
       "9883    2.773729e-02\n",
       "9884    1.592456e-01\n",
       "9885    2.981663e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of ShippingPrice\n",
    "predictionsCFeats = logreg6.predict(df)\n",
    "predictionsCFeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>Q3.1: Evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: Subset of All Continuous Features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9880\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.2545\n",
      "Time:                        08:55:05   Log-Likelihood:                -1576.5\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                1.516e-230\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 1.3494      0.161      8.356      0.000       1.033       1.666\n",
      "ListingPrice             -0.0003      0.000     -1.201      0.230      -0.001       0.000\n",
      "ShippingPrice            -0.0207      0.005     -3.929      0.000      -0.031      -0.010\n",
      "SellerFeedbackRating     -0.0217      0.002    -10.510      0.000      -0.026      -0.018\n",
      "ShippingTime_minHours     0.1391      0.011     12.445      0.000       0.117       0.161\n",
      "ShippingTime_maxHours    -0.1251      0.011    -11.880      0.000      -0.146      -0.104\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(3.2) Print the coefficients learned by the model and discuss their statistical significance as well as their role in the model (e.g., interpret the model).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>This section will focus on the summary table for <b><u>all Continuous Features from the subset</u></b>.\n",
    "<p>This section was added to focus on how the R-squared value is shaped when taking Single Regressions firstly from the individual Continuous Features, and then with Multiple Regressions, as is the case here with all of the selected subset of Continuous Features.</p>\n",
    "Focusing on the coeficient weights of these features, column 'coef' in the table, on the p-values, column 'P>|t|' and confidence intervals, column '[95.0% Conf. Int.]', which describes the features' statistical significances via a t-test.The t-test is a hypothesis test that checks if there is enough evidence in the data to support or reject the null hypothesis.\n",
    "</p> \n",
    "<p>We can see that the Intercept weights is statistically significant (p-value = 0.000).\n",
    "The weight for the feature ListingPrice has questionable statistical significance (p-value less than 0.05, ListingPrice: p-value = 0.230. For the purpose of retraining, it will be removed from the following section.\n",
    "</p>\n",
    "\n",
    "<p>R-squared is also used and is interpreted as the proportion of variance in the observed data that is explained by the model. R-squared is between 0 and 1, and higher is better because it means that more variance is explained by the model.</p>\n",
    "\n",
    "<p>Multiple Regression model with <b><u>all Continuous Features</u></b> in this instance:</p>\n",
    "\n",
    "<p><u>Previously, the R-squared values for each individual Continuous Feature were as follows:</u></p>\n",
    "<p>For <u>ListingPrice</u>, the R-squared value is 0.004.</p>\n",
    "<p>For <u>ShippingPrice</u>, the R-squared value is 0.0355.</p>\n",
    "<p>For <u>SellerFeedbackRating</u>, the R-squared value is 0.1461.</p>\n",
    "<p>For <u>ShippingTime_minHours</u>, the R-squared value is 0.01370.</p>\n",
    "<p>For <u>ShippingTime_maxHours</u>, the R-squared value is 0.03682.</p>\n",
    "\n",
    "<p>While these values are an increase on the Single Linear Regression R-squared values, they are all quite low values, indicating that less variance is explained by this model.</p>\n",
    "\n",
    "<p>By including all selected Continuous Features in a Multiple Regression, the result is a model with higher R-squared of 0.2545. While this is still a low value between 0 and 1, it presents a better model looking at the R-squared measure. It should be noted however that this could be due to over-fitting of training data, which refers to capturing insignifcant details in sample training data. Out-of-sample, or test data predictions should also be performed. This figure, 0.2545, is an increase on the 0.185 from the Multiple Linear Regression R-squared value, indicating higher variance</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3>(3.3) Retrain the model using only the subset of features found to be statistically significant. Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As we are not using 70/30 train/test model, this training model will include all 9886 rows from the subset of columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.159545\n",
      "         Iterations 9\n",
      "Intercept                1.312716\n",
      "ShippingPrice           -0.020882\n",
      "SellerFeedbackRating    -0.021736\n",
      "ShippingTime_minHours    0.139579\n",
      "ShippingTime_maxHours   -0.125667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the \n",
    "# logistic regression model.\n",
    "\n",
    "# Here, the multiple logistic regression is re-calucated for all Statistically significant Continuous Features together.\n",
    "\n",
    "# For training the model we call the method fit() on the given data stored in our dataframe.\n",
    "logreg7 = sm.logit(formula=\"IsWinner ~  ShippingPrice + SellerFeedbackRating + ShippingTime_minHours + ShippingTime_maxHours\", data=df).fit()\n",
    "\n",
    "# Print the model weights/parameters\n",
    "print(logreg7.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Q3.3: Re-evaluate the quality of the model on the training set</h3>\n",
    "<p><u>Continuous Feature</u>: All Statistically Significant Features</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 9886\n",
      "Model:                          Logit   Df Residuals:                     9881\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.2542\n",
      "Time:                        08:55:26   Log-Likelihood:                -1577.3\n",
      "converged:                       True   LL-Null:                       -2114.8\n",
      "                                        LLR p-value:                1.858e-231\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 1.3127      0.158      8.285      0.000       1.002       1.623\n",
      "ShippingPrice            -0.0209      0.005     -3.996      0.000      -0.031      -0.011\n",
      "SellerFeedbackRating     -0.0217      0.002    -10.508      0.000      -0.026      -0.018\n",
      "ShippingTime_minHours     0.1396      0.011     12.478      0.000       0.118       0.162\n",
      "ShippingTime_maxHours    -0.1257      0.011    -11.921      0.000      -0.146      -0.105\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg7.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(3.4) Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Print the predicted class for each example.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Stephen\\Anaconda3\\envs\\comp47350\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Intercept\n",
       "0           1.0\n",
       "1           1.0\n",
       "2           1.0\n",
       "3           1.0\n",
       "4           1.0\n",
       "5           1.0\n",
       "6           1.0\n",
       "7           1.0\n",
       "8           1.0\n",
       "9           1.0\n",
       "10          1.0\n",
       "11          1.0\n",
       "12          1.0\n",
       "13          1.0\n",
       "14          1.0\n",
       "15          1.0\n",
       "16          1.0\n",
       "17          1.0\n",
       "18          1.0\n",
       "19          1.0\n",
       "20          1.0\n",
       "21          1.0\n",
       "22          1.0\n",
       "23          1.0\n",
       "24          1.0\n",
       "25          1.0\n",
       "26          1.0\n",
       "27          1.0\n",
       "28          1.0\n",
       "29          1.0\n",
       "...         ...\n",
       "9856        1.0\n",
       "9857        1.0\n",
       "9858        1.0\n",
       "9859        1.0\n",
       "9860        1.0\n",
       "9861        1.0\n",
       "9862        1.0\n",
       "9863        1.0\n",
       "9864        1.0\n",
       "9865        1.0\n",
       "9866        1.0\n",
       "9867        1.0\n",
       "9868        1.0\n",
       "9869        1.0\n",
       "9870        1.0\n",
       "9871        1.0\n",
       "9872        1.0\n",
       "9873        1.0\n",
       "9874        1.0\n",
       "9875        1.0\n",
       "9876        1.0\n",
       "9877        1.0\n",
       "9878        1.0\n",
       "9879        1.0\n",
       "9880        1.0\n",
       "9881        1.0\n",
       "9882        1.0\n",
       "9883        1.0\n",
       "9884        1.0\n",
       "9885        1.0\n",
       "\n",
       "[9886 rows x 1 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare an intercept term that adds a 1 to each example.\n",
    "# Scikit-learn does not use an intercept by default.\n",
    "intercept = pd.DataFrame({'Intercept': np.ones(9886)})\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      "       Intercept  ShippingPrice  SellerFeedbackRating  ShippingTime_minHours  \\\n",
      "0           1.0           0.00                     0                    672   \n",
      "1           1.0           0.00                    95                     48   \n",
      "2           1.0           6.99                    98                     24   \n",
      "3           1.0          11.67                    95                     24   \n",
      "4           1.0           8.99                    94                     24   \n",
      "5           1.0           6.98                    67                     24   \n",
      "6           1.0           0.00                   100                     24   \n",
      "7           1.0           9.98                    96                     96   \n",
      "8           1.0           5.00                    91                     24   \n",
      "9           1.0           9.98                    96                     96   \n",
      "10          1.0           0.00                    96                     96   \n",
      "11          1.0          12.95                    96                     24   \n",
      "12          1.0           0.00                    94                     24   \n",
      "13          1.0           5.54                   100                     24   \n",
      "14          1.0          14.99                    94                     24   \n",
      "15          1.0           7.00                    96                     24   \n",
      "16          1.0           1.34                   100                     96   \n",
      "17          1.0           0.00                   100                     72   \n",
      "18          1.0           0.00                   100                     72   \n",
      "19          1.0          10.99                    98                     24   \n",
      "20          1.0           0.00                    96                     96   \n",
      "21          1.0           0.00                     0                    672   \n",
      "22          1.0           9.98                    96                     96   \n",
      "23          1.0           9.98                    96                     96   \n",
      "24          1.0          21.69                    93                     24   \n",
      "25          1.0          11.31                    95                     24   \n",
      "26          1.0           5.00                    91                     24   \n",
      "27          1.0           5.00                    91                     24   \n",
      "28          1.0          13.19                    88                     96   \n",
      "29          1.0           7.00                    96                     24   \n",
      "...         ...            ...                   ...                    ...   \n",
      "9856        1.0          13.24                   100                     24   \n",
      "9857        1.0           9.95                    96                     24   \n",
      "9858        1.0           5.00                    91                     24   \n",
      "9859        1.0          21.25                    93                     24   \n",
      "9860        1.0           6.89                   100                     24   \n",
      "9861        1.0           7.50                    91                     72   \n",
      "9862        1.0          11.84                    88                     96   \n",
      "9863        1.0           6.00                    96                     24   \n",
      "9864        1.0          15.26                     0                     24   \n",
      "9865        1.0           0.00                    98                     24   \n",
      "9866        1.0          44.65                    96                     96   \n",
      "9867        1.0          11.22                    95                     24   \n",
      "9868        1.0           7.99                    98                     48   \n",
      "9869        1.0           8.99                    84                     24   \n",
      "9870        1.0           0.00                     0                      0   \n",
      "9871        1.0           0.00                    96                     96   \n",
      "9872        1.0           9.98                    96                     96   \n",
      "9873        1.0           0.00                    94                     24   \n",
      "9874        1.0           0.00                   100                     24   \n",
      "9875        1.0           9.98                    96                     96   \n",
      "9876        1.0          13.24                   100                     24   \n",
      "9877        1.0           9.95                    96                     24   \n",
      "9878        1.0           5.00                    91                     24   \n",
      "9879        1.0          21.25                    93                     24   \n",
      "9880        1.0           6.89                   100                     24   \n",
      "9881        1.0           7.50                    91                     72   \n",
      "9882        1.0          11.84                    88                     96   \n",
      "9883        1.0           6.00                    96                     24   \n",
      "9884        1.0          15.26                     0                     24   \n",
      "9885        1.0           0.00                    98                     24   \n",
      "\n",
      "      ShippingTime_maxHours  \n",
      "0                      1008  \n",
      "1                        72  \n",
      "2                        48  \n",
      "3                        48  \n",
      "4                        48  \n",
      "5                        48  \n",
      "6                        48  \n",
      "7                       120  \n",
      "8                        48  \n",
      "9                       120  \n",
      "10                      120  \n",
      "11                       48  \n",
      "12                       48  \n",
      "13                       48  \n",
      "14                       48  \n",
      "15                       48  \n",
      "16                      120  \n",
      "17                       96  \n",
      "18                       96  \n",
      "19                       48  \n",
      "20                      120  \n",
      "21                     1008  \n",
      "22                      120  \n",
      "23                      120  \n",
      "24                       48  \n",
      "25                       48  \n",
      "26                       48  \n",
      "27                       48  \n",
      "28                      120  \n",
      "29                       48  \n",
      "...                     ...  \n",
      "9856                     48  \n",
      "9857                     48  \n",
      "9858                     48  \n",
      "9859                     48  \n",
      "9860                     48  \n",
      "9861                     96  \n",
      "9862                    120  \n",
      "9863                     48  \n",
      "9864                     48  \n",
      "9865                     48  \n",
      "9866                    120  \n",
      "9867                     48  \n",
      "9868                     72  \n",
      "9869                     48  \n",
      "9870                      0  \n",
      "9871                    120  \n",
      "9872                    120  \n",
      "9873                     48  \n",
      "9874                     48  \n",
      "9875                    120  \n",
      "9876                     48  \n",
      "9877                     48  \n",
      "9878                     48  \n",
      "9879                     48  \n",
      "9880                     48  \n",
      "9881                     96  \n",
      "9882                    120  \n",
      "9883                     48  \n",
      "9884                     48  \n",
      "9885                     48  \n",
      "\n",
      "[9886 rows x 5 columns]\n",
      "\n",
      "Target feature:\n",
      " 0       0\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "5       0\n",
      "6       0\n",
      "7       0\n",
      "8       0\n",
      "9       0\n",
      "10      0\n",
      "11      0\n",
      "12      0\n",
      "13      0\n",
      "14      0\n",
      "15      0\n",
      "16      0\n",
      "17      0\n",
      "18      0\n",
      "19      0\n",
      "20      1\n",
      "21      0\n",
      "22      0\n",
      "23      0\n",
      "24      0\n",
      "25      0\n",
      "26      0\n",
      "27      0\n",
      "28      0\n",
      "29      0\n",
      "       ..\n",
      "9856    0\n",
      "9857    0\n",
      "9858    0\n",
      "9859    0\n",
      "9860    0\n",
      "9861    0\n",
      "9862    0\n",
      "9863    0\n",
      "9864    0\n",
      "9865    0\n",
      "9866    0\n",
      "9867    0\n",
      "9868    0\n",
      "9869    0\n",
      "9870    1\n",
      "9871    0\n",
      "9872    0\n",
      "9873    0\n",
      "9874    0\n",
      "9875    0\n",
      "9876    0\n",
      "9877    0\n",
      "9878    0\n",
      "9879    0\n",
      "9880    0\n",
      "9881    0\n",
      "9882    0\n",
      "9883    0\n",
      "9884    0\n",
      "9885    0\n",
      "Name: IsWinner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features   \n",
    "X_log = pd.concat([intercept, df[['ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']]], axis=1)\n",
    "y_log = df.IsWinner\n",
    "print(\"Descriptive features:\\n\", X_log)\n",
    "print(\"\\nTarget feature:\\n\", y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a model using logistic regression from scikit-learn.\n",
    "# Use all descriptive features that are promising, as before.\n",
    "logreg_retrain = LogisticRegression().fit(X_log[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']], y_log)\n",
    "logreg_retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(3.3) Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   2.38038483e-14],\n",
       "       [  9.56903442e-01,   4.30965584e-02],\n",
       "       [  9.74545572e-01,   2.54544279e-02],\n",
       "       ..., \n",
       "       [  9.72906082e-01,   2.70939177e-02],\n",
       "       [  8.44157033e-01,   1.55842967e-01],\n",
       "       [  9.70663358e-01,   2.93366424e-02]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for all examples. \n",
    "# The output is a pair for each example, \n",
    "# The first component is the probability of the negative class (class 0).\n",
    "# The second component is the probability of the positive class (class 1).\n",
    "logreg_retrain.predict_proba(X_log[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicted class labels for all examples, \n",
    "# using the trained model, on in-sample data (same sample used for training and test)\n",
    "predictions = logreg_retrain.predict(X_log[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']])\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               0               0\n",
       "1               1               0\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              0               0\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              1               0\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              0               0\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "9856            0               0\n",
       "9857            0               0\n",
       "9858            0               0\n",
       "9859            0               0\n",
       "9860            0               0\n",
       "9861            0               0\n",
       "9862            0               0\n",
       "9863            0               0\n",
       "9864            0               0\n",
       "9865            0               0\n",
       "9866            0               0\n",
       "9867            0               0\n",
       "9868            0               0\n",
       "9869            0               0\n",
       "9870            1               1\n",
       "9871            0               0\n",
       "9872            0               0\n",
       "9873            0               0\n",
       "9874            0               0\n",
       "9875            0               0\n",
       "9876            0               0\n",
       "9877            0               0\n",
       "9878            0               0\n",
       "9879            0               0\n",
       "9880            0               0\n",
       "9881            0               0\n",
       "9882            0               0\n",
       "9883            0               0\n",
       "9884            0               0\n",
       "9885            0               0\n",
       "\n",
       "[9886 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a clearer representation of the above cells code showing actual an predicted classes\n",
    "df_true_vs_predicted_log = pd.DataFrame({'ActualClass': df.IsWinner, 'PredictedClass': predictions})\n",
    "df_true_vs_predicted_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96469755209387009"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy on the training set. \n",
    "# For this we use the predicted class labels, and compare them to the true class labels.\n",
    "# The accuracy is the ratio of correct predictions to total examples.\n",
    "# In our case we have 9886 examples.\n",
    "# Total accuracy for this shuffled sample is 0.96, or 96% accuracy\n",
    "# As this is testing on the entire trainining model, high accuracy is expected\n",
    "logreg_retrain.score(X_log[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']], y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.964697552094\n",
      "Confusion matrix: \n",
      " [[9326   13]\n",
      " [ 336  211]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      9339\n",
      "          1       0.94      0.39      0.55       547\n",
      "\n",
      "avg / total       0.96      0.96      0.96      9886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Below are some further evaluation metrics\n",
    "# Confusion matrix: \n",
    "# [true_positives false_positives\n",
    "# false_negatives true_negatives]\n",
    "# We have 9326 true_positives, where the model predicted 1 and the actual class is 1.\n",
    "# We have 13 false_positives, where the model predicted 1 and the actual class is 0.\n",
    "# We have 336 false_negative, where the model predicted 0 and the actual class is 1.\n",
    "# We have 211 true_negatives, where the model predicted 0 and the actual class is 0.\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_log, predictions))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_log, predictions))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_log, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b><u>Conclusion:</u></b></p>\n",
    "<p>The above data represents a trained model on the 9886 rows of the data set. It was used to predict a selection of values, as seen for example; min and max values. There was a difference in R-squared values between the single and multiple regression models. From the results, a multiple regression model is favoured for higher variance. In relation to the provided graphs for each Continuous Feature, they were a visual aid to see if a model is good at predicting the Target Feature. In all cases, the graphs, while they improve on the Linear Regression model, do not indicate that is outright good at predicting the Target Feature. With regard to both the first model and the retrained model, althought p-values are below the required threshold, the model does not clearly and outrightly predict the Target Feature</p>\n",
    "\n",
    "<p>With regard to retraining the model, the Scikit-learning tools were used in conjunction with the Statsmodel tools to give a more holistic conclusion to the predictions. The better model with features removed appears to give a result with 0.96 accuracy in a scale from 0 to 1. What is important to note here however is that there is no divide between the training set and test prediction set as all 9886 rows were used. Therefore this result should be used with caution. The confusion matrix represents this outcome with high number of true positives and true negatives and lower false positive and negatives</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Question 4: Predictive Modeling: Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Before Assignment Questions: Preparation for Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsFeaturedMerchant_0</th>\n",
       "      <th>IsFeaturedMerchant_1</th>\n",
       "      <th>IsFulfilledByAmazon_0</th>\n",
       "      <th>IsFulfilledByAmazon_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsFeaturedMerchant_0  IsFeaturedMerchant_1  IsFulfilledByAmazon_0  \\\n",
       "0                     0                     1                      0   \n",
       "1                     0                     1                      1   \n",
       "2                     0                     1                      1   \n",
       "3                     0                     1                      1   \n",
       "4                     1                     0                      1   \n",
       "\n",
       "   IsFulfilledByAmazon_1  \n",
       "0                      1  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data by turning categorical features IsFullfilledByAmazon and IsFeaturedMerchant\n",
    "# into dummies represented by 0 and 1 \n",
    "\n",
    "df_cont_feat = df[['ListingPrice', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours', 'IsFeaturedMerchant', 'IsFulfilledByAmazon']]\n",
    "df_dummies = pd.get_dummies(df[['IsFeaturedMerchant', 'IsFulfilledByAmazon']])\n",
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      "       ListingPrice  ShippingPrice  SellerFeedbackRating  \\\n",
      "0            94.00           0.00                     0   \n",
      "1           107.35           0.00                    95   \n",
      "2           100.46           6.99                    98   \n",
      "3            99.24          11.67                    95   \n",
      "4           109.48           8.99                    94   \n",
      "5           116.70           6.98                    67   \n",
      "6           124.69           0.00                   100   \n",
      "7           120.08           9.98                    96   \n",
      "8           125.73           5.00                    91   \n",
      "9           121.27           9.98                    96   \n",
      "10          133.12           0.00                    96   \n",
      "11          123.77          12.95                    96   \n",
      "12          139.58           0.00                    94   \n",
      "13          136.71           5.54                   100   \n",
      "14          131.25          14.99                    94   \n",
      "15          140.26           7.00                    96   \n",
      "16          145.93           1.34                   100   \n",
      "17          150.27           0.00                   100   \n",
      "18          150.79           0.00                   100   \n",
      "19           78.64          10.99                    98   \n",
      "20           89.64           0.00                    96   \n",
      "21           90.86           0.00                     0   \n",
      "22           81.49           9.98                    96   \n",
      "23           82.56           9.98                    96   \n",
      "24           74.07          21.69                    93   \n",
      "25           85.75          11.31                    95   \n",
      "26           94.14           5.00                    91   \n",
      "27           97.45           5.00                    91   \n",
      "28          102.71          13.19                    88   \n",
      "29          109.13           7.00                    96   \n",
      "...            ...            ...                   ...   \n",
      "9856         60.84          13.24                   100   \n",
      "9857         67.72           9.95                    96   \n",
      "9858         75.99           5.00                    91   \n",
      "9859         61.87          21.25                    93   \n",
      "9860         88.00           6.89                   100   \n",
      "9861         92.72           7.50                    91   \n",
      "9862         96.77          11.84                    88   \n",
      "9863        110.68           6.00                    96   \n",
      "9864        105.73          15.26                     0   \n",
      "9865        134.25           0.00                    98   \n",
      "9866        110.57          44.65                    96   \n",
      "9867         56.07          11.22                    95   \n",
      "9868         59.98           7.99                    98   \n",
      "9869         58.99           8.99                    84   \n",
      "9870         68.62           0.00                     0   \n",
      "9871         68.71           0.00                    96   \n",
      "9872         59.19           9.98                    96   \n",
      "9873         70.06           0.00                    94   \n",
      "9874         70.31           0.00                   100   \n",
      "9875         60.62           9.98                    96   \n",
      "9876         60.84          13.24                   100   \n",
      "9877         67.72           9.95                    96   \n",
      "9878         75.99           5.00                    91   \n",
      "9879         61.87          21.25                    93   \n",
      "9880         88.00           6.89                   100   \n",
      "9881         92.72           7.50                    91   \n",
      "9882         96.77          11.84                    88   \n",
      "9883        110.68           6.00                    96   \n",
      "9884        105.73          15.26                     0   \n",
      "9885        134.25           0.00                    98   \n",
      "\n",
      "      ShippingTime_minHours  ShippingTime_maxHours IsFeaturedMerchant  \\\n",
      "0                       672                   1008                  1   \n",
      "1                        48                     72                  1   \n",
      "2                        24                     48                  1   \n",
      "3                        24                     48                  1   \n",
      "4                        24                     48                  0   \n",
      "5                        24                     48                  0   \n",
      "6                        24                     48                  1   \n",
      "7                        96                    120                  1   \n",
      "8                        24                     48                  1   \n",
      "9                        96                    120                  1   \n",
      "10                       96                    120                  1   \n",
      "11                       24                     48                  1   \n",
      "12                       24                     48                  1   \n",
      "13                       24                     48                  1   \n",
      "14                       24                     48                  1   \n",
      "15                       24                     48                  1   \n",
      "16                       96                    120                  1   \n",
      "17                       72                     96                  1   \n",
      "18                       72                     96                  1   \n",
      "19                       24                     48                  0   \n",
      "20                       96                    120                  1   \n",
      "21                      672                   1008                  1   \n",
      "22                       96                    120                  1   \n",
      "23                       96                    120                  1   \n",
      "24                       24                     48                  1   \n",
      "25                       24                     48                  1   \n",
      "26                       24                     48                  1   \n",
      "27                       24                     48                  1   \n",
      "28                       96                    120                  1   \n",
      "29                       24                     48                  1   \n",
      "...                     ...                    ...                ...   \n",
      "9856                     24                     48                  1   \n",
      "9857                     24                     48                  1   \n",
      "9858                     24                     48                  1   \n",
      "9859                     24                     48                  1   \n",
      "9860                     24                     48                  1   \n",
      "9861                     72                     96                  1   \n",
      "9862                     96                    120                  1   \n",
      "9863                     24                     48                  1   \n",
      "9864                     24                     48                  1   \n",
      "9865                     24                     48                  1   \n",
      "9866                     96                    120                  1   \n",
      "9867                     24                     48                  1   \n",
      "9868                     48                     72                  0   \n",
      "9869                     24                     48                  0   \n",
      "9870                      0                      0                  1   \n",
      "9871                     96                    120                  1   \n",
      "9872                     96                    120                  1   \n",
      "9873                     24                     48                  1   \n",
      "9874                     24                     48                  1   \n",
      "9875                     96                    120                  1   \n",
      "9876                     24                     48                  1   \n",
      "9877                     24                     48                  1   \n",
      "9878                     24                     48                  1   \n",
      "9879                     24                     48                  1   \n",
      "9880                     24                     48                  1   \n",
      "9881                     72                     96                  1   \n",
      "9882                     96                    120                  1   \n",
      "9883                     24                     48                  1   \n",
      "9884                     24                     48                  1   \n",
      "9885                     24                     48                  1   \n",
      "\n",
      "     IsFulfilledByAmazon  IsFeaturedMerchant_0  IsFeaturedMerchant_1  \\\n",
      "0                      1                     0                     1   \n",
      "1                      0                     0                     1   \n",
      "2                      0                     0                     1   \n",
      "3                      0                     0                     1   \n",
      "4                      0                     1                     0   \n",
      "5                      0                     1                     0   \n",
      "6                      0                     0                     1   \n",
      "7                      0                     0                     1   \n",
      "8                      0                     0                     1   \n",
      "9                      0                     0                     1   \n",
      "10                     0                     0                     1   \n",
      "11                     0                     0                     1   \n",
      "12                     0                     0                     1   \n",
      "13                     0                     0                     1   \n",
      "14                     0                     0                     1   \n",
      "15                     0                     0                     1   \n",
      "16                     0                     0                     1   \n",
      "17                     0                     0                     1   \n",
      "18                     0                     0                     1   \n",
      "19                     0                     1                     0   \n",
      "20                     0                     0                     1   \n",
      "21                     1                     0                     1   \n",
      "22                     0                     0                     1   \n",
      "23                     0                     0                     1   \n",
      "24                     0                     0                     1   \n",
      "25                     0                     0                     1   \n",
      "26                     0                     0                     1   \n",
      "27                     0                     0                     1   \n",
      "28                     0                     0                     1   \n",
      "29                     0                     0                     1   \n",
      "...                  ...                   ...                   ...   \n",
      "9856                   0                     0                     1   \n",
      "9857                   0                     0                     1   \n",
      "9858                   0                     0                     1   \n",
      "9859                   0                     0                     1   \n",
      "9860                   0                     0                     1   \n",
      "9861                   0                     0                     1   \n",
      "9862                   0                     0                     1   \n",
      "9863                   0                     0                     1   \n",
      "9864                   0                     0                     1   \n",
      "9865                   0                     0                     1   \n",
      "9866                   0                     0                     1   \n",
      "9867                   0                     0                     1   \n",
      "9868                   0                     1                     0   \n",
      "9869                   0                     1                     0   \n",
      "9870                   1                     0                     1   \n",
      "9871                   0                     0                     1   \n",
      "9872                   0                     0                     1   \n",
      "9873                   0                     0                     1   \n",
      "9874                   0                     0                     1   \n",
      "9875                   0                     0                     1   \n",
      "9876                   0                     0                     1   \n",
      "9877                   0                     0                     1   \n",
      "9878                   0                     0                     1   \n",
      "9879                   0                     0                     1   \n",
      "9880                   0                     0                     1   \n",
      "9881                   0                     0                     1   \n",
      "9882                   0                     0                     1   \n",
      "9883                   0                     0                     1   \n",
      "9884                   0                     0                     1   \n",
      "9885                   0                     0                     1   \n",
      "\n",
      "      IsFulfilledByAmazon_0  IsFulfilledByAmazon_1  \n",
      "0                         0                      1  \n",
      "1                         1                      0  \n",
      "2                         1                      0  \n",
      "3                         1                      0  \n",
      "4                         1                      0  \n",
      "5                         1                      0  \n",
      "6                         1                      0  \n",
      "7                         1                      0  \n",
      "8                         1                      0  \n",
      "9                         1                      0  \n",
      "10                        1                      0  \n",
      "11                        1                      0  \n",
      "12                        1                      0  \n",
      "13                        1                      0  \n",
      "14                        1                      0  \n",
      "15                        1                      0  \n",
      "16                        1                      0  \n",
      "17                        1                      0  \n",
      "18                        1                      0  \n",
      "19                        1                      0  \n",
      "20                        1                      0  \n",
      "21                        0                      1  \n",
      "22                        1                      0  \n",
      "23                        1                      0  \n",
      "24                        1                      0  \n",
      "25                        1                      0  \n",
      "26                        1                      0  \n",
      "27                        1                      0  \n",
      "28                        1                      0  \n",
      "29                        1                      0  \n",
      "...                     ...                    ...  \n",
      "9856                      1                      0  \n",
      "9857                      1                      0  \n",
      "9858                      1                      0  \n",
      "9859                      1                      0  \n",
      "9860                      1                      0  \n",
      "9861                      1                      0  \n",
      "9862                      1                      0  \n",
      "9863                      1                      0  \n",
      "9864                      1                      0  \n",
      "9865                      1                      0  \n",
      "9866                      1                      0  \n",
      "9867                      1                      0  \n",
      "9868                      1                      0  \n",
      "9869                      1                      0  \n",
      "9870                      0                      1  \n",
      "9871                      1                      0  \n",
      "9872                      1                      0  \n",
      "9873                      1                      0  \n",
      "9874                      1                      0  \n",
      "9875                      1                      0  \n",
      "9876                      1                      0  \n",
      "9877                      1                      0  \n",
      "9878                      1                      0  \n",
      "9879                      1                      0  \n",
      "9880                      1                      0  \n",
      "9881                      1                      0  \n",
      "9882                      1                      0  \n",
      "9883                      1                      0  \n",
      "9884                      1                      0  \n",
      "9885                      1                      0  \n",
      "\n",
      "[9886 rows x 11 columns]\n",
      "\n",
      "Target feature:\n",
      " 0       0\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "5       0\n",
      "6       0\n",
      "7       0\n",
      "8       0\n",
      "9       0\n",
      "10      0\n",
      "11      0\n",
      "12      0\n",
      "13      0\n",
      "14      0\n",
      "15      0\n",
      "16      0\n",
      "17      0\n",
      "18      0\n",
      "19      0\n",
      "20      1\n",
      "21      0\n",
      "22      0\n",
      "23      0\n",
      "24      0\n",
      "25      0\n",
      "26      0\n",
      "27      0\n",
      "28      0\n",
      "29      0\n",
      "       ..\n",
      "9856    0\n",
      "9857    0\n",
      "9858    0\n",
      "9859    0\n",
      "9860    0\n",
      "9861    0\n",
      "9862    0\n",
      "9863    0\n",
      "9864    0\n",
      "9865    0\n",
      "9866    0\n",
      "9867    0\n",
      "9868    0\n",
      "9869    0\n",
      "9870    1\n",
      "9871    0\n",
      "9872    0\n",
      "9873    0\n",
      "9874    0\n",
      "9875    0\n",
      "9876    0\n",
      "9877    0\n",
      "9878    0\n",
      "9879    0\n",
      "9880    0\n",
      "9881    0\n",
      "9882    0\n",
      "9883    0\n",
      "9884    0\n",
      "9885    0\n",
      "Name: IsWinner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Add dummies to the other continuous features\n",
    "X = pd.concat([df_cont_feat, df_dummies[['IsFeaturedMerchant_0', 'IsFeaturedMerchant_1', 'IsFulfilledByAmazon_0', 'IsFulfilledByAmazon_1']]], axis =1)\n",
    "y = df.IsWinner\n",
    "print(\"Descriptive features:\\n\", X)\n",
    "print(\"\\nTarget feature:\\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(4.1) Train a random forest model to predict the target feature IsWinner, using the descriptive features selected in exercise (1). Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train RF with 100 trees\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=True, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model on full dataset\n",
    "rfc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ],\n",
       "       [ 0.04,  0.96],\n",
       "       [ 1.  ,  0.  ],\n",
       "       ..., \n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 1.  ,  0.  ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for all examples. \n",
    "# The output is a pair for each example, \n",
    "# The first component is the probability of the negative class (class 0).\n",
    "# The second component is the probability of the positive class (class 1).\n",
    "rfc.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               0               0\n",
       "1               1               1\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              0               0\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              1               1\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              0               0\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "9856            0               0\n",
       "9857            0               0\n",
       "9858            0               0\n",
       "9859            0               0\n",
       "9860            0               0\n",
       "9861            0               0\n",
       "9862            0               0\n",
       "9863            0               0\n",
       "9864            0               0\n",
       "9865            0               0\n",
       "9866            0               0\n",
       "9867            0               0\n",
       "9868            0               0\n",
       "9869            0               0\n",
       "9870            1               1\n",
       "9871            0               0\n",
       "9872            0               0\n",
       "9873            0               0\n",
       "9874            0               0\n",
       "9875            0               0\n",
       "9876            0               0\n",
       "9877            0               0\n",
       "9878            0               0\n",
       "9879            0               0\n",
       "9880            0               0\n",
       "9881            0               0\n",
       "9882            0               0\n",
       "9883            0               0\n",
       "9884            0               0\n",
       "9885            0               0\n",
       "\n",
       "[9886 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted class labels for all examples, using the trained model\n",
    "rfc_predictions = rfc.predict(X)\n",
    "df_true_vs_rfc_predicted = pd.DataFrame({'ActualClass': y, 'PredictedClass': rfc_predictions})\n",
    "df_true_vs_rfc_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4.1 Evaluate the quality of the model on the training set. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.995144648999\n",
      "\n",
      "Confusion matrix: \n",
      " [[9320   19]\n",
      " [  29  518]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9339\n",
      "          1       0.96      0.95      0.96       547\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing some metrics which will be used to evaluate the quality of the model\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y, rfc_predictions))\n",
    "print(\"\\nConfusion matrix: \\n\", metrics.confusion_matrix(y, rfc_predictions))\n",
    "print(\"\\nClassification report:\\n \", metrics.classification_report(y, rfc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>(4.2) Print the features ranked by random forest importance. Discuss your findings and choose a subset of features you find promising.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ListingPrice</td>\n",
       "      <td>0.392544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ShippingPrice</td>\n",
       "      <td>0.151840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SellerFeedbackRating</td>\n",
       "      <td>0.067758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ShippingTime_minHours</td>\n",
       "      <td>0.137832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ShippingTime_maxHours</td>\n",
       "      <td>0.144848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IsFeaturedMerchant</td>\n",
       "      <td>0.002222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IsFulfilledByAmazon</td>\n",
       "      <td>0.043602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IsFeaturedMerchant_0</td>\n",
       "      <td>0.002438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IsFeaturedMerchant_1</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IsFulfilledByAmazon_0</td>\n",
       "      <td>0.028489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IsFulfilledByAmazon_1</td>\n",
       "      <td>0.025936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  Importance\n",
       "0            ListingPrice    0.392544\n",
       "1           ShippingPrice    0.151840\n",
       "2    SellerFeedbackRating    0.067758\n",
       "3   ShippingTime_minHours    0.137832\n",
       "4   ShippingTime_maxHours    0.144848\n",
       "5      IsFeaturedMerchant    0.002222\n",
       "6     IsFulfilledByAmazon    0.043602\n",
       "7    IsFeaturedMerchant_0    0.002438\n",
       "8    IsFeaturedMerchant_1    0.002489\n",
       "9   IsFulfilledByAmazon_0    0.028489\n",
       "10  IsFulfilledByAmazon_1    0.025936"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the importance of each feature based on the trained random forest classifier\n",
    "# RF finds different feature importance than the single decision tree\n",
    "# It finds ListingPrice to be the most important, and ShippingPrice, SHippingTime_minHours and _maxHours to be equally important\n",
    "# It should be noted that we cannot interpret the RF with 100 tress as we could by looking at a single decision tree\n",
    "# This table is therefore used to interpret the trained model\n",
    "pd.DataFrame({'Feature': X.columns, 'Importance':rfc.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>(4.3) Retrain the model using only the subset of features found to be promising. Evaluate the quality of the model on the training set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      "       ListingPrice  ShippingPrice  ShippingTime_minHours  \\\n",
      "0            94.00           0.00                    672   \n",
      "1           107.35           0.00                     48   \n",
      "2           100.46           6.99                     24   \n",
      "3            99.24          11.67                     24   \n",
      "4           109.48           8.99                     24   \n",
      "5           116.70           6.98                     24   \n",
      "6           124.69           0.00                     24   \n",
      "7           120.08           9.98                     96   \n",
      "8           125.73           5.00                     24   \n",
      "9           121.27           9.98                     96   \n",
      "10          133.12           0.00                     96   \n",
      "11          123.77          12.95                     24   \n",
      "12          139.58           0.00                     24   \n",
      "13          136.71           5.54                     24   \n",
      "14          131.25          14.99                     24   \n",
      "15          140.26           7.00                     24   \n",
      "16          145.93           1.34                     96   \n",
      "17          150.27           0.00                     72   \n",
      "18          150.79           0.00                     72   \n",
      "19           78.64          10.99                     24   \n",
      "20           89.64           0.00                     96   \n",
      "21           90.86           0.00                    672   \n",
      "22           81.49           9.98                     96   \n",
      "23           82.56           9.98                     96   \n",
      "24           74.07          21.69                     24   \n",
      "25           85.75          11.31                     24   \n",
      "26           94.14           5.00                     24   \n",
      "27           97.45           5.00                     24   \n",
      "28          102.71          13.19                     96   \n",
      "29          109.13           7.00                     24   \n",
      "...            ...            ...                    ...   \n",
      "9856         60.84          13.24                     24   \n",
      "9857         67.72           9.95                     24   \n",
      "9858         75.99           5.00                     24   \n",
      "9859         61.87          21.25                     24   \n",
      "9860         88.00           6.89                     24   \n",
      "9861         92.72           7.50                     72   \n",
      "9862         96.77          11.84                     96   \n",
      "9863        110.68           6.00                     24   \n",
      "9864        105.73          15.26                     24   \n",
      "9865        134.25           0.00                     24   \n",
      "9866        110.57          44.65                     96   \n",
      "9867         56.07          11.22                     24   \n",
      "9868         59.98           7.99                     48   \n",
      "9869         58.99           8.99                     24   \n",
      "9870         68.62           0.00                      0   \n",
      "9871         68.71           0.00                     96   \n",
      "9872         59.19           9.98                     96   \n",
      "9873         70.06           0.00                     24   \n",
      "9874         70.31           0.00                     24   \n",
      "9875         60.62           9.98                     96   \n",
      "9876         60.84          13.24                     24   \n",
      "9877         67.72           9.95                     24   \n",
      "9878         75.99           5.00                     24   \n",
      "9879         61.87          21.25                     24   \n",
      "9880         88.00           6.89                     24   \n",
      "9881         92.72           7.50                     72   \n",
      "9882         96.77          11.84                     96   \n",
      "9883        110.68           6.00                     24   \n",
      "9884        105.73          15.26                     24   \n",
      "9885        134.25           0.00                     24   \n",
      "\n",
      "      ShippingTime_maxHours  \n",
      "0                      1008  \n",
      "1                        72  \n",
      "2                        48  \n",
      "3                        48  \n",
      "4                        48  \n",
      "5                        48  \n",
      "6                        48  \n",
      "7                       120  \n",
      "8                        48  \n",
      "9                       120  \n",
      "10                      120  \n",
      "11                       48  \n",
      "12                       48  \n",
      "13                       48  \n",
      "14                       48  \n",
      "15                       48  \n",
      "16                      120  \n",
      "17                       96  \n",
      "18                       96  \n",
      "19                       48  \n",
      "20                      120  \n",
      "21                     1008  \n",
      "22                      120  \n",
      "23                      120  \n",
      "24                       48  \n",
      "25                       48  \n",
      "26                       48  \n",
      "27                       48  \n",
      "28                      120  \n",
      "29                       48  \n",
      "...                     ...  \n",
      "9856                     48  \n",
      "9857                     48  \n",
      "9858                     48  \n",
      "9859                     48  \n",
      "9860                     48  \n",
      "9861                     96  \n",
      "9862                    120  \n",
      "9863                     48  \n",
      "9864                     48  \n",
      "9865                     48  \n",
      "9866                    120  \n",
      "9867                     48  \n",
      "9868                     72  \n",
      "9869                     48  \n",
      "9870                      0  \n",
      "9871                    120  \n",
      "9872                    120  \n",
      "9873                     48  \n",
      "9874                     48  \n",
      "9875                    120  \n",
      "9876                     48  \n",
      "9877                     48  \n",
      "9878                     48  \n",
      "9879                     48  \n",
      "9880                     48  \n",
      "9881                     96  \n",
      "9882                    120  \n",
      "9883                     48  \n",
      "9884                     48  \n",
      "9885                     48  \n",
      "\n",
      "[9886 rows x 4 columns]\n",
      "\n",
      "Target feature:\n",
      " 0       0\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "5       0\n",
      "6       0\n",
      "7       0\n",
      "8       0\n",
      "9       0\n",
      "10      0\n",
      "11      0\n",
      "12      0\n",
      "13      0\n",
      "14      0\n",
      "15      0\n",
      "16      0\n",
      "17      0\n",
      "18      0\n",
      "19      0\n",
      "20      1\n",
      "21      0\n",
      "22      0\n",
      "23      0\n",
      "24      0\n",
      "25      0\n",
      "26      0\n",
      "27      0\n",
      "28      0\n",
      "29      0\n",
      "       ..\n",
      "9856    0\n",
      "9857    0\n",
      "9858    0\n",
      "9859    0\n",
      "9860    0\n",
      "9861    0\n",
      "9862    0\n",
      "9863    0\n",
      "9864    0\n",
      "9865    0\n",
      "9866    0\n",
      "9867    0\n",
      "9868    0\n",
      "9869    0\n",
      "9870    1\n",
      "9871    0\n",
      "9872    0\n",
      "9873    0\n",
      "9874    0\n",
      "9875    0\n",
      "9876    0\n",
      "9877    0\n",
      "9878    0\n",
      "9879    0\n",
      "9880    0\n",
      "9881    0\n",
      "9882    0\n",
      "9883    0\n",
      "9884    0\n",
      "9885    0\n",
      "Name: IsWinner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Taking the 4 most important features from above, the models is retrained\n",
    "X_train = df[['ListingPrice', 'ShippingPrice', 'ShippingTime_minHours', 'ShippingTime_maxHours']]\n",
    "y_train = df.IsWinner\n",
    "print(\"Descriptive features:\\n\", X_train)\n",
    "print(\"\\nTarget feature:\\n\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=True, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4.3 Evaluate the quality of the model on the training set. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.995144648999\n",
      "\n",
      "Confusion matrix: \n",
      " [[9320   19]\n",
      " [  29  518]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      9339\n",
      "          1       0.96      0.95      0.96       547\n",
      "\n",
      "avg / total       1.00      1.00      1.00      9886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing some metrics which will be used to evaluate the quality of the retrained model\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_train, rfc_predictions))\n",
    "print(\"\\nConfusion matrix: \\n\", metrics.confusion_matrix(y_train, rfc_predictions))\n",
    "print(\"\\nClassification report:\\n \", metrics.classification_report(y_train, rfc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b><u>Conclusion:</u></b></p>\n",
    "<p>With regard to training the model, the Scikit-learning tools were used to give a more holistic conclusion to the predictions. The model appears to give a result with 0.99 accuracy in a scale from 0 to 1. What is important to note here however is that there is no divide between the training set and test prediction set as all 9886 rows were used. Therefore this result should be used with caution. The confusion matrix represents this outcome with high number of true positives and true negatives and lower false positive and negatives. Similiarly, it is represented by precision, with a slightly higher precision in predicting the probability of IsWinner being 0 than 1</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>(4.4) Using the better model (as per evaluation on training set), print the predicted target feature value for all the examples in the training set. Print the predicted class for each example.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ],\n",
       "       [ 0.04,  0.96],\n",
       "       [ 1.  ,  0.  ],\n",
       "       ..., \n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 1.  ,  0.  ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for all examples. \n",
    "# The output is a pair for each example, \n",
    "# The first component is the probability of the negative class (class 0).\n",
    "# The second component is the probability of the positive class (class 1).\n",
    "rfc.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "0               0               0\n",
       "1               1               1\n",
       "2               0               0\n",
       "3               0               0\n",
       "4               0               0\n",
       "5               0               0\n",
       "6               0               0\n",
       "7               0               0\n",
       "8               0               0\n",
       "9               0               0\n",
       "10              0               0\n",
       "11              0               0\n",
       "12              0               0\n",
       "13              0               0\n",
       "14              0               0\n",
       "15              0               0\n",
       "16              0               0\n",
       "17              0               0\n",
       "18              0               0\n",
       "19              0               0\n",
       "20              1               1\n",
       "21              0               0\n",
       "22              0               0\n",
       "23              0               0\n",
       "24              0               0\n",
       "25              0               0\n",
       "26              0               0\n",
       "27              0               0\n",
       "28              0               0\n",
       "29              0               0\n",
       "...           ...             ...\n",
       "9856            0               0\n",
       "9857            0               0\n",
       "9858            0               0\n",
       "9859            0               0\n",
       "9860            0               0\n",
       "9861            0               0\n",
       "9862            0               0\n",
       "9863            0               0\n",
       "9864            0               0\n",
       "9865            0               0\n",
       "9866            0               0\n",
       "9867            0               0\n",
       "9868            0               0\n",
       "9869            0               0\n",
       "9870            1               1\n",
       "9871            0               0\n",
       "9872            0               0\n",
       "9873            0               0\n",
       "9874            0               0\n",
       "9875            0               0\n",
       "9876            0               0\n",
       "9877            0               0\n",
       "9878            0               0\n",
       "9879            0               0\n",
       "9880            0               0\n",
       "9881            0               0\n",
       "9882            0               0\n",
       "9883            0               0\n",
       "9884            0               0\n",
       "9885            0               0\n",
       "\n",
       "[9886 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted class labels for all examples, \n",
    "# using the trained model, on in-sample data (same sample used for training and test)\n",
    "rfc_predictions = rfc.predict(X_train)\n",
    "df_true_vs_rfc_predicted = pd.DataFrame({'ActualClass': y, 'PredictedClass': rfc_predictions})\n",
    "df_true_vs_rfc_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Question 5: Evaluating Predictive Models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> (5.1) Split the dataset into 70% training and remaining 30% test.</h3>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Intercept\n",
       "0           1.0\n",
       "1           1.0\n",
       "2           1.0\n",
       "3           1.0\n",
       "4           1.0\n",
       "5           1.0\n",
       "6           1.0\n",
       "7           1.0\n",
       "8           1.0\n",
       "9           1.0\n",
       "10          1.0\n",
       "11          1.0\n",
       "12          1.0\n",
       "13          1.0\n",
       "14          1.0\n",
       "15          1.0\n",
       "16          1.0\n",
       "17          1.0\n",
       "18          1.0\n",
       "19          1.0\n",
       "20          1.0\n",
       "21          1.0\n",
       "22          1.0\n",
       "23          1.0\n",
       "24          1.0\n",
       "25          1.0\n",
       "26          1.0\n",
       "27          1.0\n",
       "28          1.0\n",
       "29          1.0\n",
       "...         ...\n",
       "9856        1.0\n",
       "9857        1.0\n",
       "9858        1.0\n",
       "9859        1.0\n",
       "9860        1.0\n",
       "9861        1.0\n",
       "9862        1.0\n",
       "9863        1.0\n",
       "9864        1.0\n",
       "9865        1.0\n",
       "9866        1.0\n",
       "9867        1.0\n",
       "9868        1.0\n",
       "9869        1.0\n",
       "9870        1.0\n",
       "9871        1.0\n",
       "9872        1.0\n",
       "9873        1.0\n",
       "9874        1.0\n",
       "9875        1.0\n",
       "9876        1.0\n",
       "9877        1.0\n",
       "9878        1.0\n",
       "9879        1.0\n",
       "9880        1.0\n",
       "9881        1.0\n",
       "9882        1.0\n",
       "9883        1.0\n",
       "9884        1.0\n",
       "9885        1.0\n",
       "\n",
       "[9886 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare an intercept term that adds a 1 to each example.\n",
    "# Scikit-learn does not use an intercept by default.\n",
    "intercept = pd.DataFrame({'Intercept': np.ones(9886)})\n",
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>TimeOfOfferChange</th>\n",
       "      <th>IsFeaturedMerchant</th>\n",
       "      <th>IsFulfilledByAmazon</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>SellerFeedbackCount</th>\n",
       "      <th>SellerId</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "      <th>ShipsFromCountry</th>\n",
       "      <th>ShipsFromState</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1207135739277432339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.35</td>\n",
       "      <td>95</td>\n",
       "      <td>4078</td>\n",
       "      <td>-1789487307643024748</td>\n",
       "      <td>0.00</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.46</td>\n",
       "      <td>98</td>\n",
       "      <td>478</td>\n",
       "      <td>5452082314297826053</td>\n",
       "      <td>6.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.24</td>\n",
       "      <td>95</td>\n",
       "      <td>4384</td>\n",
       "      <td>-2572277640783537773</td>\n",
       "      <td>11.67</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109.48</td>\n",
       "      <td>94</td>\n",
       "      <td>105</td>\n",
       "      <td>-8704029307873847986</td>\n",
       "      <td>8.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116.70</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>1929046423112965216</td>\n",
       "      <td>6.98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>AB</td>\n",
       "      <td>2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>124.69</td>\n",
       "      <td>100</td>\n",
       "      <td>4601</td>\n",
       "      <td>5657218934756058127</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120.08</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125.73</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121.27</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.12</td>\n",
       "      <td>96</td>\n",
       "      <td>35264</td>\n",
       "      <td>6791568714796518563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "      <td>0.090416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123.77</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>-373508113925093038</td>\n",
       "      <td>12.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>139.58</td>\n",
       "      <td>94</td>\n",
       "      <td>178</td>\n",
       "      <td>-8070122054366980138</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NV</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136.71</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>750763505746428351</td>\n",
       "      <td>5.54</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>HK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131.25</td>\n",
       "      <td>94</td>\n",
       "      <td>337</td>\n",
       "      <td>2760162070632027753</td>\n",
       "      <td>14.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "      <td>0.090416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.26</td>\n",
       "      <td>96</td>\n",
       "      <td>41419</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>7.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145.93</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>5554217688069566383</td>\n",
       "      <td>1.34</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.27</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>9008330480532653624</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4885255916155087854</td>\n",
       "      <td>2016-02-04T04:26:52.136Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.79</td>\n",
       "      <td>100</td>\n",
       "      <td>26</td>\n",
       "      <td>5811974462741352839</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>JP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.64</td>\n",
       "      <td>98</td>\n",
       "      <td>3293</td>\n",
       "      <td>4143506568603310959</td>\n",
       "      <td>10.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89.64</td>\n",
       "      <td>96</td>\n",
       "      <td>35264</td>\n",
       "      <td>6791568714796518563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "      <td>0.090416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1207135739277432339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>81.49</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82.56</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74.07</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>-5016003493506265192</td>\n",
       "      <td>21.69</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85.75</td>\n",
       "      <td>95</td>\n",
       "      <td>4384</td>\n",
       "      <td>-2572277640783537773</td>\n",
       "      <td>11.31</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94.14</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97.45</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102.71</td>\n",
       "      <td>88</td>\n",
       "      <td>8452</td>\n",
       "      <td>-6639690782514669126</td>\n",
       "      <td>13.19</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6219878023547990916</td>\n",
       "      <td>2016-02-04T04:27:21.627Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109.13</td>\n",
       "      <td>96</td>\n",
       "      <td>41419</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>7.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.84</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>4987276067789979672</td>\n",
       "      <td>13.24</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.72</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>-373508113925093038</td>\n",
       "      <td>9.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.87</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>-5016003493506265192</td>\n",
       "      <td>21.25</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>-9097393894851801879</td>\n",
       "      <td>6.89</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>FR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.72</td>\n",
       "      <td>91</td>\n",
       "      <td>11930</td>\n",
       "      <td>-1888136325356517677</td>\n",
       "      <td>7.50</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>88</td>\n",
       "      <td>8452</td>\n",
       "      <td>-6639690782514669126</td>\n",
       "      <td>11.84</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.68</td>\n",
       "      <td>96</td>\n",
       "      <td>41420</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>6.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3846853762521352076</td>\n",
       "      <td>15.26</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.25</td>\n",
       "      <td>98</td>\n",
       "      <td>1446</td>\n",
       "      <td>1163115142515862290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.298507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:45:50.216Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.57</td>\n",
       "      <td>96</td>\n",
       "      <td>184</td>\n",
       "      <td>-5514312832713552000</td>\n",
       "      <td>44.65</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.07</td>\n",
       "      <td>95</td>\n",
       "      <td>4385</td>\n",
       "      <td>-2572277640783537773</td>\n",
       "      <td>11.22</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.98</td>\n",
       "      <td>98</td>\n",
       "      <td>3293</td>\n",
       "      <td>4143506568603310959</td>\n",
       "      <td>7.99</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.99</td>\n",
       "      <td>84</td>\n",
       "      <td>161</td>\n",
       "      <td>-3129154375621551414</td>\n",
       "      <td>8.99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1207135739277432339</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68.71</td>\n",
       "      <td>96</td>\n",
       "      <td>35272</td>\n",
       "      <td>6791568714796518563</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>CA</td>\n",
       "      <td>QC</td>\n",
       "      <td>0.090416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.19</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.06</td>\n",
       "      <td>94</td>\n",
       "      <td>178</td>\n",
       "      <td>-8070122054366980138</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>NV</td>\n",
       "      <td>1.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70.31</td>\n",
       "      <td>100</td>\n",
       "      <td>4601</td>\n",
       "      <td>5657218934756058127</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.62</td>\n",
       "      <td>96</td>\n",
       "      <td>1790</td>\n",
       "      <td>1788801474825896666</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>0.085763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60.84</td>\n",
       "      <td>100</td>\n",
       "      <td>384</td>\n",
       "      <td>4987276067789979672</td>\n",
       "      <td>13.24</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67.72</td>\n",
       "      <td>96</td>\n",
       "      <td>7090</td>\n",
       "      <td>-373508113925093038</td>\n",
       "      <td>9.95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>CA</td>\n",
       "      <td>ON</td>\n",
       "      <td>0.045228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>91</td>\n",
       "      <td>10606</td>\n",
       "      <td>-1177408302343430963</td>\n",
       "      <td>5.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61.87</td>\n",
       "      <td>93</td>\n",
       "      <td>2521</td>\n",
       "      <td>-5016003493506265192</td>\n",
       "      <td>21.25</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>VA</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>-9097393894851801879</td>\n",
       "      <td>6.89</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>FR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.72</td>\n",
       "      <td>91</td>\n",
       "      <td>11930</td>\n",
       "      <td>-1888136325356517677</td>\n",
       "      <td>7.50</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>88</td>\n",
       "      <td>8452</td>\n",
       "      <td>-6639690782514669126</td>\n",
       "      <td>11.84</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.68</td>\n",
       "      <td>96</td>\n",
       "      <td>41420</td>\n",
       "      <td>9012427554787096099</td>\n",
       "      <td>6.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3846853762521352076</td>\n",
       "      <td>15.26</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8414836866689867420</td>\n",
       "      <td>2016-02-04T05:46:57.316Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.25</td>\n",
       "      <td>98</td>\n",
       "      <td>1446</td>\n",
       "      <td>1163115142515862290</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>0.298507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Intercept  IsWinner             ProductId         TimeOfOfferChange  \\\n",
       "0           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "1           1.0         1  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "2           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "3           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "4           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "5           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "6           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "7           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "8           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "9           1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "10          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "11          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "12          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "13          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "14          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "15          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "16          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "17          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "18          1.0         0  -4885255916155087854  2016-02-04T04:26:52.136Z   \n",
       "19          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "20          1.0         1  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "21          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "22          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "23          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "24          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "25          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "26          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "27          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "28          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "29          1.0         0  -6219878023547990916  2016-02-04T04:27:21.627Z   \n",
       "...         ...       ...                   ...                       ...   \n",
       "9856        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9857        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9858        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9859        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9860        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9861        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9862        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9863        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9864        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9865        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9866        1.0         0   8414836866689867420  2016-02-04T05:45:50.216Z   \n",
       "9867        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9868        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9869        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9870        1.0         1   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9871        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9872        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9873        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9874        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9875        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9876        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9877        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9878        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9879        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9880        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9881        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9882        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9883        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9884        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "9885        1.0         0   8414836866689867420  2016-02-04T05:46:57.316Z   \n",
       "\n",
       "     IsFeaturedMerchant IsFulfilledByAmazon  ListingPrice  \\\n",
       "0                     1                   1         94.00   \n",
       "1                     1                   0        107.35   \n",
       "2                     1                   0        100.46   \n",
       "3                     1                   0         99.24   \n",
       "4                     0                   0        109.48   \n",
       "5                     0                   0        116.70   \n",
       "6                     1                   0        124.69   \n",
       "7                     1                   0        120.08   \n",
       "8                     1                   0        125.73   \n",
       "9                     1                   0        121.27   \n",
       "10                    1                   0        133.12   \n",
       "11                    1                   0        123.77   \n",
       "12                    1                   0        139.58   \n",
       "13                    1                   0        136.71   \n",
       "14                    1                   0        131.25   \n",
       "15                    1                   0        140.26   \n",
       "16                    1                   0        145.93   \n",
       "17                    1                   0        150.27   \n",
       "18                    1                   0        150.79   \n",
       "19                    0                   0         78.64   \n",
       "20                    1                   0         89.64   \n",
       "21                    1                   1         90.86   \n",
       "22                    1                   0         81.49   \n",
       "23                    1                   0         82.56   \n",
       "24                    1                   0         74.07   \n",
       "25                    1                   0         85.75   \n",
       "26                    1                   0         94.14   \n",
       "27                    1                   0         97.45   \n",
       "28                    1                   0        102.71   \n",
       "29                    1                   0        109.13   \n",
       "...                 ...                 ...           ...   \n",
       "9856                  1                   0         60.84   \n",
       "9857                  1                   0         67.72   \n",
       "9858                  1                   0         75.99   \n",
       "9859                  1                   0         61.87   \n",
       "9860                  1                   0         88.00   \n",
       "9861                  1                   0         92.72   \n",
       "9862                  1                   0         96.77   \n",
       "9863                  1                   0        110.68   \n",
       "9864                  1                   0        105.73   \n",
       "9865                  1                   0        134.25   \n",
       "9866                  1                   0        110.57   \n",
       "9867                  1                   0         56.07   \n",
       "9868                  0                   0         59.98   \n",
       "9869                  0                   0         58.99   \n",
       "9870                  1                   1         68.62   \n",
       "9871                  1                   0         68.71   \n",
       "9872                  1                   0         59.19   \n",
       "9873                  1                   0         70.06   \n",
       "9874                  1                   0         70.31   \n",
       "9875                  1                   0         60.62   \n",
       "9876                  1                   0         60.84   \n",
       "9877                  1                   0         67.72   \n",
       "9878                  1                   0         75.99   \n",
       "9879                  1                   0         61.87   \n",
       "9880                  1                   0         88.00   \n",
       "9881                  1                   0         92.72   \n",
       "9882                  1                   0         96.77   \n",
       "9883                  1                   0        110.68   \n",
       "9884                  1                   0        105.73   \n",
       "9885                  1                   0        134.25   \n",
       "\n",
       "      SellerFeedbackRating  SellerFeedbackCount              SellerId  \\\n",
       "0                        0                    0   1207135739277432339   \n",
       "1                       95                 4078  -1789487307643024748   \n",
       "2                       98                  478   5452082314297826053   \n",
       "3                       95                 4384  -2572277640783537773   \n",
       "4                       94                  105  -8704029307873847986   \n",
       "5                       67                    9   1929046423112965216   \n",
       "6                      100                 4601   5657218934756058127   \n",
       "7                       96                 1790   1788801474825896666   \n",
       "8                       91                10606  -1177408302343430963   \n",
       "9                       96                 1790   1788801474825896666   \n",
       "10                      96                35264   6791568714796518563   \n",
       "11                      96                 7090   -373508113925093038   \n",
       "12                      94                  178  -8070122054366980138   \n",
       "13                     100                    3    750763505746428351   \n",
       "14                      94                  337   2760162070632027753   \n",
       "15                      96                41419   9012427554787096099   \n",
       "16                     100                   35   5554217688069566383   \n",
       "17                     100                   20   9008330480532653624   \n",
       "18                     100                   26   5811974462741352839   \n",
       "19                      98                 3293   4143506568603310959   \n",
       "20                      96                35264   6791568714796518563   \n",
       "21                       0                    0   1207135739277432339   \n",
       "22                      96                 1790   1788801474825896666   \n",
       "23                      96                 1790   1788801474825896666   \n",
       "24                      93                 2521  -5016003493506265192   \n",
       "25                      95                 4384  -2572277640783537773   \n",
       "26                      91                10606  -1177408302343430963   \n",
       "27                      91                10606  -1177408302343430963   \n",
       "28                      88                 8452  -6639690782514669126   \n",
       "29                      96                41419   9012427554787096099   \n",
       "...                    ...                  ...                   ...   \n",
       "9856                   100                  384   4987276067789979672   \n",
       "9857                    96                 7090   -373508113925093038   \n",
       "9858                    91                10606  -1177408302343430963   \n",
       "9859                    93                 2521  -5016003493506265192   \n",
       "9860                   100                    2  -9097393894851801879   \n",
       "9861                    91                11930  -1888136325356517677   \n",
       "9862                    88                 8452  -6639690782514669126   \n",
       "9863                    96                41420   9012427554787096099   \n",
       "9864                     0                    0   3846853762521352076   \n",
       "9865                    98                 1446   1163115142515862290   \n",
       "9866                    96                  184  -5514312832713552000   \n",
       "9867                    95                 4385  -2572277640783537773   \n",
       "9868                    98                 3293   4143506568603310959   \n",
       "9869                    84                  161  -3129154375621551414   \n",
       "9870                     0                    0   1207135739277432339   \n",
       "9871                    96                35272   6791568714796518563   \n",
       "9872                    96                 1790   1788801474825896666   \n",
       "9873                    94                  178  -8070122054366980138   \n",
       "9874                   100                 4601   5657218934756058127   \n",
       "9875                    96                 1790   1788801474825896666   \n",
       "9876                   100                  384   4987276067789979672   \n",
       "9877                    96                 7090   -373508113925093038   \n",
       "9878                    91                10606  -1177408302343430963   \n",
       "9879                    93                 2521  -5016003493506265192   \n",
       "9880                   100                    2  -9097393894851801879   \n",
       "9881                    91                11930  -1888136325356517677   \n",
       "9882                    88                 8452  -6639690782514669126   \n",
       "9883                    96                41420   9012427554787096099   \n",
       "9884                     0                    0   3846853762521352076   \n",
       "9885                    98                 1446   1163115142515862290   \n",
       "\n",
       "      ShippingPrice  ShippingTime_minHours  ShippingTime_maxHours  \\\n",
       "0              0.00                    672                   1008   \n",
       "1              0.00                     48                     72   \n",
       "2              6.99                     24                     48   \n",
       "3             11.67                     24                     48   \n",
       "4              8.99                     24                     48   \n",
       "5              6.98                     24                     48   \n",
       "6              0.00                     24                     48   \n",
       "7              9.98                     96                    120   \n",
       "8              5.00                     24                     48   \n",
       "9              9.98                     96                    120   \n",
       "10             0.00                     96                    120   \n",
       "11            12.95                     24                     48   \n",
       "12             0.00                     24                     48   \n",
       "13             5.54                     24                     48   \n",
       "14            14.99                     24                     48   \n",
       "15             7.00                     24                     48   \n",
       "16             1.34                     96                    120   \n",
       "17             0.00                     72                     96   \n",
       "18             0.00                     72                     96   \n",
       "19            10.99                     24                     48   \n",
       "20             0.00                     96                    120   \n",
       "21             0.00                    672                   1008   \n",
       "22             9.98                     96                    120   \n",
       "23             9.98                     96                    120   \n",
       "24            21.69                     24                     48   \n",
       "25            11.31                     24                     48   \n",
       "26             5.00                     24                     48   \n",
       "27             5.00                     24                     48   \n",
       "28            13.19                     96                    120   \n",
       "29             7.00                     24                     48   \n",
       "...             ...                    ...                    ...   \n",
       "9856          13.24                     24                     48   \n",
       "9857           9.95                     24                     48   \n",
       "9858           5.00                     24                     48   \n",
       "9859          21.25                     24                     48   \n",
       "9860           6.89                     24                     48   \n",
       "9861           7.50                     72                     96   \n",
       "9862          11.84                     96                    120   \n",
       "9863           6.00                     24                     48   \n",
       "9864          15.26                     24                     48   \n",
       "9865           0.00                     24                     48   \n",
       "9866          44.65                     96                    120   \n",
       "9867          11.22                     24                     48   \n",
       "9868           7.99                     48                     72   \n",
       "9869           8.99                     24                     48   \n",
       "9870           0.00                      0                      0   \n",
       "9871           0.00                     96                    120   \n",
       "9872           9.98                     96                    120   \n",
       "9873           0.00                     24                     48   \n",
       "9874           0.00                     24                     48   \n",
       "9875           9.98                     96                    120   \n",
       "9876          13.24                     24                     48   \n",
       "9877           9.95                     24                     48   \n",
       "9878           5.00                     24                     48   \n",
       "9879          21.25                     24                     48   \n",
       "9880           6.89                     24                     48   \n",
       "9881           7.50                     72                     96   \n",
       "9882          11.84                     96                    120   \n",
       "9883           6.00                     24                     48   \n",
       "9884          15.26                     24                     48   \n",
       "9885           0.00                     24                     48   \n",
       "\n",
       "     ShipsFromCountry ShipsFromState   percent  \n",
       "0                 NaN            NaN  0.000000  \n",
       "1                  CA             ON  0.045228  \n",
       "2                  CA             ON  0.045228  \n",
       "3                  CA             ON  0.045228  \n",
       "4                  CA             ON  0.045228  \n",
       "5                  CA             AB  2.777778  \n",
       "6                  CA             ON  0.045228  \n",
       "7                  US             NY  0.085763  \n",
       "8                 NaN            NaN  0.000000  \n",
       "9                  US             NY  0.085763  \n",
       "10                 CA             QC  0.090416  \n",
       "11                 CA             ON  0.045228  \n",
       "12                 US             NV  1.470588  \n",
       "13                 HK            NaN  0.000000  \n",
       "14                 CA             QC  0.090416  \n",
       "15                NaN            NaN  0.000000  \n",
       "16                 JP            NaN  0.000000  \n",
       "17                 JP            NaN  0.000000  \n",
       "18                 JP            NaN  0.000000  \n",
       "19                 US             NY  0.085763  \n",
       "20                 CA             QC  0.090416  \n",
       "21                NaN            NaN  0.000000  \n",
       "22                 US             NY  0.085763  \n",
       "23                 US             NY  0.085763  \n",
       "24                 US             VA  0.312500  \n",
       "25                 CA             ON  0.045228  \n",
       "26                NaN            NaN  0.000000  \n",
       "27                NaN            NaN  0.000000  \n",
       "28                NaN            NaN  0.000000  \n",
       "29                NaN            NaN  0.000000  \n",
       "...               ...            ...       ...  \n",
       "9856               CA             ON  0.045228  \n",
       "9857               CA             ON  0.045228  \n",
       "9858              NaN            NaN  0.000000  \n",
       "9859               US             VA  0.312500  \n",
       "9860               FR            NaN  0.000000  \n",
       "9861              NaN            NaN  0.000000  \n",
       "9862              NaN            NaN  0.000000  \n",
       "9863              NaN            NaN  0.000000  \n",
       "9864              NaN            NaN  0.000000  \n",
       "9865               US             CA  0.298507  \n",
       "9866               US             NY  0.085763  \n",
       "9867               CA             ON  0.045228  \n",
       "9868               US             NY  0.085763  \n",
       "9869               CA             ON  0.045228  \n",
       "9870              NaN            NaN  0.000000  \n",
       "9871               CA             QC  0.090416  \n",
       "9872               US             NY  0.085763  \n",
       "9873               US             NV  1.470588  \n",
       "9874               CA             ON  0.045228  \n",
       "9875               US             NY  0.085763  \n",
       "9876               CA             ON  0.045228  \n",
       "9877               CA             ON  0.045228  \n",
       "9878              NaN            NaN  0.000000  \n",
       "9879               US             VA  0.312500  \n",
       "9880               FR            NaN  0.000000  \n",
       "9881              NaN            NaN  0.000000  \n",
       "9882              NaN            NaN  0.000000  \n",
       "9883              NaN            NaN  0.000000  \n",
       "9884              NaN            NaN  0.000000  \n",
       "9885               US             CA  0.298507  \n",
       "\n",
       "[9886 rows x 16 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([intercept, df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.46</td>\n",
       "      <td>6.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.24</td>\n",
       "      <td>11.67</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.48</td>\n",
       "      <td>8.99</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.70</td>\n",
       "      <td>6.98</td>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.08</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.73</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.27</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.77</td>\n",
       "      <td>12.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.71</td>\n",
       "      <td>5.54</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131.25</td>\n",
       "      <td>14.99</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.26</td>\n",
       "      <td>7.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.93</td>\n",
       "      <td>1.34</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.64</td>\n",
       "      <td>10.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.49</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.56</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.07</td>\n",
       "      <td>21.69</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.75</td>\n",
       "      <td>11.31</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.14</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.45</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.71</td>\n",
       "      <td>13.19</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.13</td>\n",
       "      <td>7.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.84</td>\n",
       "      <td>13.24</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9857</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.72</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.87</td>\n",
       "      <td>21.25</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>6.89</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9861</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.72</td>\n",
       "      <td>7.50</td>\n",
       "      <td>91</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9862</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>11.84</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9863</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.68</td>\n",
       "      <td>6.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.73</td>\n",
       "      <td>15.26</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.57</td>\n",
       "      <td>44.65</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.07</td>\n",
       "      <td>11.22</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.98</td>\n",
       "      <td>7.99</td>\n",
       "      <td>98</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9869</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>84</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9872</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.19</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9873</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.62</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.84</td>\n",
       "      <td>13.24</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.72</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9879</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.87</td>\n",
       "      <td>21.25</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.00</td>\n",
       "      <td>6.89</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.72</td>\n",
       "      <td>7.50</td>\n",
       "      <td>91</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9882</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.77</td>\n",
       "      <td>11.84</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9883</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.68</td>\n",
       "      <td>6.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9884</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.73</td>\n",
       "      <td>15.26</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9885</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  Intercept  ListingPrice  ShippingPrice  SellerFeedbackRating  \\\n",
       "0            0        1.0         94.00           0.00                     0   \n",
       "1            1        1.0        107.35           0.00                    95   \n",
       "2            0        1.0        100.46           6.99                    98   \n",
       "3            0        1.0         99.24          11.67                    95   \n",
       "4            0        1.0        109.48           8.99                    94   \n",
       "5            0        1.0        116.70           6.98                    67   \n",
       "6            0        1.0        124.69           0.00                   100   \n",
       "7            0        1.0        120.08           9.98                    96   \n",
       "8            0        1.0        125.73           5.00                    91   \n",
       "9            0        1.0        121.27           9.98                    96   \n",
       "10           0        1.0        133.12           0.00                    96   \n",
       "11           0        1.0        123.77          12.95                    96   \n",
       "12           0        1.0        139.58           0.00                    94   \n",
       "13           0        1.0        136.71           5.54                   100   \n",
       "14           0        1.0        131.25          14.99                    94   \n",
       "15           0        1.0        140.26           7.00                    96   \n",
       "16           0        1.0        145.93           1.34                   100   \n",
       "17           0        1.0        150.27           0.00                   100   \n",
       "18           0        1.0        150.79           0.00                   100   \n",
       "19           0        1.0         78.64          10.99                    98   \n",
       "20           1        1.0         89.64           0.00                    96   \n",
       "21           0        1.0         90.86           0.00                     0   \n",
       "22           0        1.0         81.49           9.98                    96   \n",
       "23           0        1.0         82.56           9.98                    96   \n",
       "24           0        1.0         74.07          21.69                    93   \n",
       "25           0        1.0         85.75          11.31                    95   \n",
       "26           0        1.0         94.14           5.00                    91   \n",
       "27           0        1.0         97.45           5.00                    91   \n",
       "28           0        1.0        102.71          13.19                    88   \n",
       "29           0        1.0        109.13           7.00                    96   \n",
       "...        ...        ...           ...            ...                   ...   \n",
       "9856         0        1.0         60.84          13.24                   100   \n",
       "9857         0        1.0         67.72           9.95                    96   \n",
       "9858         0        1.0         75.99           5.00                    91   \n",
       "9859         0        1.0         61.87          21.25                    93   \n",
       "9860         0        1.0         88.00           6.89                   100   \n",
       "9861         0        1.0         92.72           7.50                    91   \n",
       "9862         0        1.0         96.77          11.84                    88   \n",
       "9863         0        1.0        110.68           6.00                    96   \n",
       "9864         0        1.0        105.73          15.26                     0   \n",
       "9865         0        1.0        134.25           0.00                    98   \n",
       "9866         0        1.0        110.57          44.65                    96   \n",
       "9867         0        1.0         56.07          11.22                    95   \n",
       "9868         0        1.0         59.98           7.99                    98   \n",
       "9869         0        1.0         58.99           8.99                    84   \n",
       "9870         1        1.0         68.62           0.00                     0   \n",
       "9871         0        1.0         68.71           0.00                    96   \n",
       "9872         0        1.0         59.19           9.98                    96   \n",
       "9873         0        1.0         70.06           0.00                    94   \n",
       "9874         0        1.0         70.31           0.00                   100   \n",
       "9875         0        1.0         60.62           9.98                    96   \n",
       "9876         0        1.0         60.84          13.24                   100   \n",
       "9877         0        1.0         67.72           9.95                    96   \n",
       "9878         0        1.0         75.99           5.00                    91   \n",
       "9879         0        1.0         61.87          21.25                    93   \n",
       "9880         0        1.0         88.00           6.89                   100   \n",
       "9881         0        1.0         92.72           7.50                    91   \n",
       "9882         0        1.0         96.77          11.84                    88   \n",
       "9883         0        1.0        110.68           6.00                    96   \n",
       "9884         0        1.0        105.73          15.26                     0   \n",
       "9885         0        1.0        134.25           0.00                    98   \n",
       "\n",
       "      ShippingTime_minHours  ShippingTime_maxHours  \n",
       "0                       672                   1008  \n",
       "1                        48                     72  \n",
       "2                        24                     48  \n",
       "3                        24                     48  \n",
       "4                        24                     48  \n",
       "5                        24                     48  \n",
       "6                        24                     48  \n",
       "7                        96                    120  \n",
       "8                        24                     48  \n",
       "9                        96                    120  \n",
       "10                       96                    120  \n",
       "11                       24                     48  \n",
       "12                       24                     48  \n",
       "13                       24                     48  \n",
       "14                       24                     48  \n",
       "15                       24                     48  \n",
       "16                       96                    120  \n",
       "17                       72                     96  \n",
       "18                       72                     96  \n",
       "19                       24                     48  \n",
       "20                       96                    120  \n",
       "21                      672                   1008  \n",
       "22                       96                    120  \n",
       "23                       96                    120  \n",
       "24                       24                     48  \n",
       "25                       24                     48  \n",
       "26                       24                     48  \n",
       "27                       24                     48  \n",
       "28                       96                    120  \n",
       "29                       24                     48  \n",
       "...                     ...                    ...  \n",
       "9856                     24                     48  \n",
       "9857                     24                     48  \n",
       "9858                     24                     48  \n",
       "9859                     24                     48  \n",
       "9860                     24                     48  \n",
       "9861                     72                     96  \n",
       "9862                     96                    120  \n",
       "9863                     24                     48  \n",
       "9864                     24                     48  \n",
       "9865                     24                     48  \n",
       "9866                     96                    120  \n",
       "9867                     24                     48  \n",
       "9868                     48                     72  \n",
       "9869                     24                     48  \n",
       "9870                      0                      0  \n",
       "9871                     96                    120  \n",
       "9872                     96                    120  \n",
       "9873                     24                     48  \n",
       "9874                     24                     48  \n",
       "9875                     96                    120  \n",
       "9876                     24                     48  \n",
       "9877                     24                     48  \n",
       "9878                     24                     48  \n",
       "9879                     24                     48  \n",
       "9880                     24                     48  \n",
       "9881                     72                     96  \n",
       "9882                     96                    120  \n",
       "9883                     24                     48  \n",
       "9884                     24                     48  \n",
       "9885                     24                     48  \n",
       "\n",
       "[9886 rows x 7 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introduce the df with subset of promising features\n",
    "df_retrain = df[['IsWinner', 'Intercept' , 'ListingPrice', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']]\n",
    "df_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9522</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>471.91</td>\n",
       "      <td>10.60</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>332.96</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>100</td>\n",
       "      <td>264</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.42</td>\n",
       "      <td>12.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7572</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>444.53</td>\n",
       "      <td>20.26</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.26</td>\n",
       "      <td>27.23</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.76</td>\n",
       "      <td>12.60</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.34</td>\n",
       "      <td>7.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.34</td>\n",
       "      <td>17.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.40</td>\n",
       "      <td>13.41</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.94</td>\n",
       "      <td>12.88</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.33</td>\n",
       "      <td>14.99</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>12.95</td>\n",
       "      <td>97</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.91</td>\n",
       "      <td>10.51</td>\n",
       "      <td>92</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>848.58</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.32</td>\n",
       "      <td>21.94</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9377</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.47</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.04</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.98</td>\n",
       "      <td>9.19</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.85</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>579.94</td>\n",
       "      <td>34.80</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233.29</td>\n",
       "      <td>65.11</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.19</td>\n",
       "      <td>14.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.52</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.94</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.62</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.48</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.20</td>\n",
       "      <td>5.17</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>5.63</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>295.19</td>\n",
       "      <td>6.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.06</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.84</td>\n",
       "      <td>21.69</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286.18</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>301.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.77</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.52</td>\n",
       "      <td>14.99</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>363.79</td>\n",
       "      <td>14.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>452.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.13</td>\n",
       "      <td>11.01</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>398.98</td>\n",
       "      <td>41.12</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>351.89</td>\n",
       "      <td>122.42</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>391.95</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>333.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245.98</td>\n",
       "      <td>48.81</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.90</td>\n",
       "      <td>7.50</td>\n",
       "      <td>91</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9886 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  Intercept  ListingPrice  ShippingPrice  SellerFeedbackRating  \\\n",
       "9522         0        1.0        471.91          10.60                    50   \n",
       "9829         0        1.0        332.96           9.98                    96   \n",
       "9237         0        1.0         55.15           0.00                   100   \n",
       "298          0        1.0        211.00          45.00                   100   \n",
       "4256         0        1.0        176.47           0.00                    98   \n",
       "2402         0        1.0          9.62           5.54                     0   \n",
       "4745         0        1.0        129.84           0.00                   100   \n",
       "3757         0        1.0        117.42          12.95                    96   \n",
       "7572         0        1.0        444.53          20.26                   100   \n",
       "8560         0        1.0        265.26          27.23                    93   \n",
       "4340         1        1.0         67.99           0.00                     0   \n",
       "6323         0        1.0         68.76          12.60                    96   \n",
       "1618         0        1.0         56.34           7.00                    96   \n",
       "1035         0        1.0        116.12           0.00                    95   \n",
       "9131         0        1.0        234.34          17.95                    96   \n",
       "3600         0        1.0         64.40          13.41                   100   \n",
       "2495         0        1.0          8.46           5.00                    91   \n",
       "7207         0        1.0         53.94          12.88                    98   \n",
       "5050         0        1.0        260.33          14.99                    95   \n",
       "2250         0        1.0         13.94          12.95                    97   \n",
       "3738         0        1.0        176.85           0.00                    91   \n",
       "8929         0        1.0        128.91          10.51                    92   \n",
       "7822         0        1.0        848.58           5.00                    91   \n",
       "4057         0        1.0        109.32          21.94                    93   \n",
       "9377         0        1.0         69.43           0.00                    75   \n",
       "9545         1        1.0         26.66           0.00                     0   \n",
       "1239         0        1.0         73.47           9.95                    96   \n",
       "3938         0        1.0         85.04           5.00                    91   \n",
       "1417         0        1.0         15.98           9.19                    97   \n",
       "5395         0        1.0         36.85           9.98                    96   \n",
       "...        ...        ...           ...            ...                   ...   \n",
       "9480         0        1.0        116.68           0.00                    96   \n",
       "3427         0        1.0        579.94          34.80                    96   \n",
       "5856         0        1.0        233.29          65.11                    82   \n",
       "4383         0        1.0        247.19          14.99                    98   \n",
       "388          0        1.0         98.52           9.98                    96   \n",
       "5394         0        1.0         40.94           5.00                    91   \n",
       "2331         0        1.0         83.62           9.95                    96   \n",
       "2415         0        1.0         41.48           5.54                     0   \n",
       "8199         1        1.0         70.20           5.17                    95   \n",
       "5996         0        1.0         11.90           5.63                   100   \n",
       "6330         0        1.0        295.19           6.99                    98   \n",
       "9209         0        1.0         76.64           0.00                    98   \n",
       "3958         0        1.0         59.06           5.00                    91   \n",
       "5724         0        1.0        116.84          21.69                    93   \n",
       "1828         0        1.0        286.18           5.00                    91   \n",
       "8051         0        1.0        301.71           0.00                    96   \n",
       "8540         0        1.0         72.77           5.00                    91   \n",
       "8612         1        1.0         57.98           0.00                     0   \n",
       "7755         0        1.0         57.52          14.99                    95   \n",
       "5280         0        1.0        363.79          14.99                    98   \n",
       "9776         0        1.0         93.10           0.00                    96   \n",
       "9590         0        1.0        452.40           0.00                    91   \n",
       "9549         0        1.0         22.13          11.01                    95   \n",
       "3436         0        1.0        398.98          41.12                   100   \n",
       "1452         0        1.0        116.13           0.00                    95   \n",
       "2772         0        1.0        351.89         122.42                    88   \n",
       "7519         0        1.0        391.95           9.98                    96   \n",
       "2757         0        1.0        333.21           0.00                     0   \n",
       "9716         0        1.0        245.98          48.81                   100   \n",
       "6820         0        1.0        365.90           7.50                    91   \n",
       "\n",
       "      ShippingTime_minHours  ShippingTime_maxHours  \n",
       "9522                     24                     48  \n",
       "9829                     96                    120  \n",
       "9237                     24                     48  \n",
       "298                     264                    360  \n",
       "4256                     24                     48  \n",
       "2402                     24                     48  \n",
       "4745                     24                     48  \n",
       "3757                     24                     48  \n",
       "7572                     24                     48  \n",
       "8560                     24                     48  \n",
       "4340                      0                      0  \n",
       "6323                     96                    120  \n",
       "1618                     96                    120  \n",
       "1035                     24                     48  \n",
       "9131                     24                     48  \n",
       "3600                     24                     48  \n",
       "2495                     24                     48  \n",
       "7207                     24                     48  \n",
       "5050                     24                     48  \n",
       "2250                     24                     48  \n",
       "3738                     24                     48  \n",
       "8929                     72                     96  \n",
       "7822                     24                     48  \n",
       "4057                     24                     48  \n",
       "9377                    144                    240  \n",
       "9545                      0                      0  \n",
       "1239                     24                     48  \n",
       "3938                     24                     48  \n",
       "1417                    144                    240  \n",
       "5395                     96                    120  \n",
       "...                     ...                    ...  \n",
       "9480                     24                     48  \n",
       "3427                     96                    120  \n",
       "5856                     24                     48  \n",
       "4383                     24                     48  \n",
       "388                      96                    120  \n",
       "5394                     24                     48  \n",
       "2331                     24                     48  \n",
       "2415                     24                     48  \n",
       "8199                     96                    120  \n",
       "5996                     24                     48  \n",
       "6330                     24                     48  \n",
       "9209                     24                     48  \n",
       "3958                     24                     48  \n",
       "5724                     24                     48  \n",
       "1828                     24                     48  \n",
       "8051                     24                     48  \n",
       "8540                     24                     48  \n",
       "8612                      0                      0  \n",
       "7755                     24                     48  \n",
       "5280                     24                     48  \n",
       "9776                     96                    120  \n",
       "9590                     24                     48  \n",
       "9549                     24                     48  \n",
       "3436                     24                     48  \n",
       "1452                     24                     48  \n",
       "2772                     96                    120  \n",
       "7519                     96                    120  \n",
       "2757                    672                   1008  \n",
       "9716                    144                    240  \n",
       "6820                     72                     96  \n",
       "\n",
       "[9886 rows x 7 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly, shuffle the rows of the df before spliting to ensure randomness\n",
    "# Note, as this code shuffles the rows, it is likely that the returned Training and Test models will differ slightly\n",
    "# on Demonstrators/lecturers computer as it will return a new shuffle when executed, and these results may differ or vary slightly\n",
    "# than to what is described in the evaluation and comments section\n",
    "df_retrain = df_retrain.sample(frac=1)\n",
    "df_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9522</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>471.91</td>\n",
       "      <td>10.60</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>332.96</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>100</td>\n",
       "      <td>264</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4256</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2402</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.62</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3757</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.42</td>\n",
       "      <td>12.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7572</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>444.53</td>\n",
       "      <td>20.26</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.26</td>\n",
       "      <td>27.23</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4340</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6323</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.76</td>\n",
       "      <td>12.60</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.34</td>\n",
       "      <td>7.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.34</td>\n",
       "      <td>17.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.40</td>\n",
       "      <td>13.41</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.46</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.94</td>\n",
       "      <td>12.88</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.33</td>\n",
       "      <td>14.99</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.94</td>\n",
       "      <td>12.95</td>\n",
       "      <td>97</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8929</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.91</td>\n",
       "      <td>10.51</td>\n",
       "      <td>92</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7822</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>848.58</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.32</td>\n",
       "      <td>21.94</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9377</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.47</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.04</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.98</td>\n",
       "      <td>9.19</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.85</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.66</td>\n",
       "      <td>14.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.80</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>554.62</td>\n",
       "      <td>192.84</td>\n",
       "      <td>94</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9535</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.39</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.18</td>\n",
       "      <td>7.04</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>396.61</td>\n",
       "      <td>62.20</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>378.13</td>\n",
       "      <td>51.76</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.01</td>\n",
       "      <td>11.66</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8859</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.09</td>\n",
       "      <td>13.20</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8193</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>197.10</td>\n",
       "      <td>8.90</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.86</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9375</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7741</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>369.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.04</td>\n",
       "      <td>12.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246.75</td>\n",
       "      <td>61.07</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>584.01</td>\n",
       "      <td>10.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.80</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.51</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5075</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7873</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.08</td>\n",
       "      <td>20.05</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>215.66</td>\n",
       "      <td>30.52</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>308.93</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.93</td>\n",
       "      <td>7.45</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9243</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.58</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9585</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>384.56</td>\n",
       "      <td>13.38</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4792</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.90</td>\n",
       "      <td>9.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6920 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  Intercept  ListingPrice  ShippingPrice  SellerFeedbackRating  \\\n",
       "9522         0        1.0        471.91          10.60                    50   \n",
       "9829         0        1.0        332.96           9.98                    96   \n",
       "9237         0        1.0         55.15           0.00                   100   \n",
       "298          0        1.0        211.00          45.00                   100   \n",
       "4256         0        1.0        176.47           0.00                    98   \n",
       "2402         0        1.0          9.62           5.54                     0   \n",
       "4745         0        1.0        129.84           0.00                   100   \n",
       "3757         0        1.0        117.42          12.95                    96   \n",
       "7572         0        1.0        444.53          20.26                   100   \n",
       "8560         0        1.0        265.26          27.23                    93   \n",
       "4340         1        1.0         67.99           0.00                     0   \n",
       "6323         0        1.0         68.76          12.60                    96   \n",
       "1618         0        1.0         56.34           7.00                    96   \n",
       "1035         0        1.0        116.12           0.00                    95   \n",
       "9131         0        1.0        234.34          17.95                    96   \n",
       "3600         0        1.0         64.40          13.41                   100   \n",
       "2495         0        1.0          8.46           5.00                    91   \n",
       "7207         0        1.0         53.94          12.88                    98   \n",
       "5050         0        1.0        260.33          14.99                    95   \n",
       "2250         0        1.0         13.94          12.95                    97   \n",
       "3738         0        1.0        176.85           0.00                    91   \n",
       "8929         0        1.0        128.91          10.51                    92   \n",
       "7822         0        1.0        848.58           5.00                    91   \n",
       "4057         0        1.0        109.32          21.94                    93   \n",
       "9377         0        1.0         69.43           0.00                    75   \n",
       "9545         1        1.0         26.66           0.00                     0   \n",
       "1239         0        1.0         73.47           9.95                    96   \n",
       "3938         0        1.0         85.04           5.00                    91   \n",
       "1417         0        1.0         15.98           9.19                    97   \n",
       "5395         0        1.0         36.85           9.98                    96   \n",
       "...        ...        ...           ...            ...                   ...   \n",
       "926          0        1.0         40.66          14.99                    98   \n",
       "2300         0        1.0         86.80           5.00                    91   \n",
       "2506         0        1.0         88.25           0.00                    98   \n",
       "7104         0        1.0        554.62         192.84                    94   \n",
       "9535         0        1.0         33.39           5.00                    91   \n",
       "863          0        1.0         94.18           7.04                    50   \n",
       "8681         0        1.0        396.61          62.20                    82   \n",
       "7987         0        1.0        378.13          51.76                    97   \n",
       "2601         0        1.0         26.01          11.66                    98   \n",
       "8859         0        1.0         79.09          13.20                    96   \n",
       "8193         0        1.0         64.30           0.00                    95   \n",
       "3249         0        1.0        197.10           8.90                    95   \n",
       "4301         0        1.0         52.86           5.00                    91   \n",
       "9375         0        1.0         65.72           0.00                    98   \n",
       "7741         0        1.0        369.57           0.00                   100   \n",
       "7481         0        1.0        105.04          12.95                    96   \n",
       "1100         0        1.0        246.75          61.07                    88   \n",
       "4647         0        1.0        584.01          10.00                   100   \n",
       "4459         0        1.0        123.80           9.98                    96   \n",
       "7615         0        1.0         63.06           0.00                   100   \n",
       "4010         0        1.0        158.51           5.00                    91   \n",
       "5075         0        1.0         62.00           7.00                    96   \n",
       "7873         0        1.0         42.08          20.05                    93   \n",
       "4563         0        1.0        215.66          30.52                    93   \n",
       "5474         0        1.0        265.38           0.00                    96   \n",
       "5782         0        1.0        308.93           5.00                    91   \n",
       "398          0        1.0         45.93           7.45                    96   \n",
       "9243         0        1.0         54.58           9.95                    96   \n",
       "9585         1        1.0        384.56          13.38                    95   \n",
       "4792         0        1.0         35.90           9.00                    96   \n",
       "\n",
       "      ShippingTime_minHours  ShippingTime_maxHours  \n",
       "9522                     24                     48  \n",
       "9829                     96                    120  \n",
       "9237                     24                     48  \n",
       "298                     264                    360  \n",
       "4256                     24                     48  \n",
       "2402                     24                     48  \n",
       "4745                     24                     48  \n",
       "3757                     24                     48  \n",
       "7572                     24                     48  \n",
       "8560                     24                     48  \n",
       "4340                      0                      0  \n",
       "6323                     96                    120  \n",
       "1618                     96                    120  \n",
       "1035                     24                     48  \n",
       "9131                     24                     48  \n",
       "3600                     24                     48  \n",
       "2495                     24                     48  \n",
       "7207                     24                     48  \n",
       "5050                     24                     48  \n",
       "2250                     24                     48  \n",
       "3738                     24                     48  \n",
       "8929                     72                     96  \n",
       "7822                     24                     48  \n",
       "4057                     24                     48  \n",
       "9377                    144                    240  \n",
       "9545                      0                      0  \n",
       "1239                     24                     48  \n",
       "3938                     24                     48  \n",
       "1417                    144                    240  \n",
       "5395                     96                    120  \n",
       "...                     ...                    ...  \n",
       "926                      24                     48  \n",
       "2300                     24                     48  \n",
       "2506                     24                     48  \n",
       "7104                     24                     48  \n",
       "9535                     24                     48  \n",
       "863                      24                     48  \n",
       "8681                     24                     48  \n",
       "7987                    144                    240  \n",
       "2601                     24                     48  \n",
       "8859                     24                     48  \n",
       "8193                     24                     48  \n",
       "3249                     96                    120  \n",
       "4301                     24                     48  \n",
       "9375                     24                     48  \n",
       "7741                     96                    120  \n",
       "7481                     24                     48  \n",
       "1100                     96                    120  \n",
       "4647                     24                     48  \n",
       "4459                     96                    120  \n",
       "7615                     24                     48  \n",
       "4010                     24                     48  \n",
       "5075                     24                     48  \n",
       "7873                     24                     48  \n",
       "4563                     24                     48  \n",
       "5474                     24                     48  \n",
       "5782                     24                     48  \n",
       "398                      24                     48  \n",
       "9243                     24                     48  \n",
       "9585                     24                     48  \n",
       "4792                     24                     48  \n",
       "\n",
       "[6920 rows x 7 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataframe takes 70% of the entire 9886 rows as the training model for the 4 promising Continuous features\n",
    "# 70% of 9886 as training\n",
    "df_train70 = df_retrain[:6920]\n",
    "df_train70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsWinner</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>ListingPrice</th>\n",
       "      <th>ShippingPrice</th>\n",
       "      <th>SellerFeedbackRating</th>\n",
       "      <th>ShippingTime_minHours</th>\n",
       "      <th>ShippingTime_maxHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.19</td>\n",
       "      <td>11.35</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.88</td>\n",
       "      <td>14.99</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>834.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.69</td>\n",
       "      <td>12.82</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.58</td>\n",
       "      <td>10.28</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.52</td>\n",
       "      <td>11.66</td>\n",
       "      <td>98</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>584.03</td>\n",
       "      <td>14.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.20</td>\n",
       "      <td>11.07</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>295.01</td>\n",
       "      <td>54.47</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.77</td>\n",
       "      <td>6.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>268.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.23</td>\n",
       "      <td>48.90</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>729.67</td>\n",
       "      <td>34.97</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>192.48</td>\n",
       "      <td>21.25</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>84</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.48</td>\n",
       "      <td>11.75</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.71</td>\n",
       "      <td>13.19</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.46</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190.80</td>\n",
       "      <td>16.22</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>656.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>760.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>249.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.29</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9531</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.99</td>\n",
       "      <td>8.99</td>\n",
       "      <td>84</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>122.74</td>\n",
       "      <td>17.37</td>\n",
       "      <td>98</td>\n",
       "      <td>48</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.86</td>\n",
       "      <td>12.73</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>579.94</td>\n",
       "      <td>34.80</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233.29</td>\n",
       "      <td>65.11</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.19</td>\n",
       "      <td>14.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.52</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.94</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.62</td>\n",
       "      <td>9.95</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.48</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.20</td>\n",
       "      <td>5.17</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>5.63</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>295.19</td>\n",
       "      <td>6.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.06</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.84</td>\n",
       "      <td>21.69</td>\n",
       "      <td>93</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>286.18</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>301.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.77</td>\n",
       "      <td>5.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.52</td>\n",
       "      <td>14.99</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>363.79</td>\n",
       "      <td>14.99</td>\n",
       "      <td>98</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>452.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.13</td>\n",
       "      <td>11.01</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>398.98</td>\n",
       "      <td>41.12</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>351.89</td>\n",
       "      <td>122.42</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>391.95</td>\n",
       "      <td>9.98</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>333.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>672</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245.98</td>\n",
       "      <td>48.81</td>\n",
       "      <td>100</td>\n",
       "      <td>144</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.90</td>\n",
       "      <td>7.50</td>\n",
       "      <td>91</td>\n",
       "      <td>72</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2966 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IsWinner  Intercept  ListingPrice  ShippingPrice  SellerFeedbackRating  \\\n",
       "4876         0        1.0         28.19          11.35                    95   \n",
       "9447         0        1.0        130.88          14.99                    95   \n",
       "6630         0        1.0         65.22           0.00                    99   \n",
       "3093         0        1.0        834.38           0.00                    96   \n",
       "1332         0        1.0        168.69          12.82                    95   \n",
       "830          0        1.0         36.58          10.28                    95   \n",
       "626          0        1.0         43.52          11.66                    98   \n",
       "4672         0        1.0        584.03          14.99                    98   \n",
       "3912         0        1.0         59.20          11.07                    95   \n",
       "9717         0        1.0        295.01          54.47                    82   \n",
       "5675         0        1.0         48.77           6.00                    96   \n",
       "591          0        1.0        268.00           0.00                    91   \n",
       "1532         0        1.0        101.23          48.90                   100   \n",
       "3451         0        1.0        729.67          34.97                    50   \n",
       "5321         0        1.0        192.48          21.25                   100   \n",
       "3338         0        1.0         32.99           8.99                    84   \n",
       "7403         0        1.0         38.48          11.75                    95   \n",
       "6563         0        1.0        102.71          13.19                    88   \n",
       "4101         0        1.0         51.46           9.95                    96   \n",
       "1085         0        1.0        190.80          16.22                   100   \n",
       "2121         0        1.0        656.25           0.00                    91   \n",
       "2261         0        1.0         34.42           0.00                    91   \n",
       "732          0        1.0        760.05           0.00                    91   \n",
       "6371         0        1.0        249.80           0.00                   100   \n",
       "6082         0        1.0        107.87           0.00                    96   \n",
       "312          0        1.0        162.29           5.00                    91   \n",
       "9531         0        1.0         24.99           8.99                    84   \n",
       "2297         0        1.0        130.32           0.00                    98   \n",
       "1484         0        1.0        122.74          17.37                    98   \n",
       "5904         0        1.0         93.86          12.73                    95   \n",
       "...        ...        ...           ...            ...                   ...   \n",
       "9480         0        1.0        116.68           0.00                    96   \n",
       "3427         0        1.0        579.94          34.80                    96   \n",
       "5856         0        1.0        233.29          65.11                    82   \n",
       "4383         0        1.0        247.19          14.99                    98   \n",
       "388          0        1.0         98.52           9.98                    96   \n",
       "5394         0        1.0         40.94           5.00                    91   \n",
       "2331         0        1.0         83.62           9.95                    96   \n",
       "2415         0        1.0         41.48           5.54                     0   \n",
       "8199         1        1.0         70.20           5.17                    95   \n",
       "5996         0        1.0         11.90           5.63                   100   \n",
       "6330         0        1.0        295.19           6.99                    98   \n",
       "9209         0        1.0         76.64           0.00                    98   \n",
       "3958         0        1.0         59.06           5.00                    91   \n",
       "5724         0        1.0        116.84          21.69                    93   \n",
       "1828         0        1.0        286.18           5.00                    91   \n",
       "8051         0        1.0        301.71           0.00                    96   \n",
       "8540         0        1.0         72.77           5.00                    91   \n",
       "8612         1        1.0         57.98           0.00                     0   \n",
       "7755         0        1.0         57.52          14.99                    95   \n",
       "5280         0        1.0        363.79          14.99                    98   \n",
       "9776         0        1.0         93.10           0.00                    96   \n",
       "9590         0        1.0        452.40           0.00                    91   \n",
       "9549         0        1.0         22.13          11.01                    95   \n",
       "3436         0        1.0        398.98          41.12                   100   \n",
       "1452         0        1.0        116.13           0.00                    95   \n",
       "2772         0        1.0        351.89         122.42                    88   \n",
       "7519         0        1.0        391.95           9.98                    96   \n",
       "2757         0        1.0        333.21           0.00                     0   \n",
       "9716         0        1.0        245.98          48.81                   100   \n",
       "6820         0        1.0        365.90           7.50                    91   \n",
       "\n",
       "      ShippingTime_minHours  ShippingTime_maxHours  \n",
       "4876                     24                     48  \n",
       "9447                     24                     48  \n",
       "6630                     24                     48  \n",
       "3093                     96                    120  \n",
       "1332                     24                     48  \n",
       "830                      24                     48  \n",
       "626                      48                     72  \n",
       "4672                     24                     48  \n",
       "3912                     24                     48  \n",
       "9717                     24                     48  \n",
       "5675                     24                     48  \n",
       "591                      24                     48  \n",
       "1532                    144                    240  \n",
       "3451                     24                     48  \n",
       "5321                    144                    240  \n",
       "3338                     24                     48  \n",
       "7403                     24                     48  \n",
       "6563                     96                    120  \n",
       "4101                     24                     48  \n",
       "1085                     24                     48  \n",
       "2121                     24                     48  \n",
       "2261                     24                     48  \n",
       "732                      24                     48  \n",
       "6371                     24                     48  \n",
       "6082                     96                    120  \n",
       "312                      24                     48  \n",
       "9531                     24                     48  \n",
       "2297                     24                     48  \n",
       "1484                     48                     72  \n",
       "5904                     24                     48  \n",
       "...                     ...                    ...  \n",
       "9480                     24                     48  \n",
       "3427                     96                    120  \n",
       "5856                     24                     48  \n",
       "4383                     24                     48  \n",
       "388                      96                    120  \n",
       "5394                     24                     48  \n",
       "2331                     24                     48  \n",
       "2415                     24                     48  \n",
       "8199                     96                    120  \n",
       "5996                     24                     48  \n",
       "6330                     24                     48  \n",
       "9209                     24                     48  \n",
       "3958                     24                     48  \n",
       "5724                     24                     48  \n",
       "1828                     24                     48  \n",
       "8051                     24                     48  \n",
       "8540                     24                     48  \n",
       "8612                      0                      0  \n",
       "7755                     24                     48  \n",
       "5280                     24                     48  \n",
       "9776                     96                    120  \n",
       "9590                     24                     48  \n",
       "9549                     24                     48  \n",
       "3436                     24                     48  \n",
       "1452                     24                     48  \n",
       "2772                     96                    120  \n",
       "7519                     96                    120  \n",
       "2757                    672                   1008  \n",
       "9716                    144                    240  \n",
       "6820                     72                     96  \n",
       "\n",
       "[2966 rows x 7 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly, shuffle the rows of the df before spliting to ensure randomness\n",
    "# This dataframe takes 70% of the entire 9886 rows as the training model for the 4 promising Continuous features\n",
    "# 30% of 9886 as test set\n",
    "df_test30 = df_retrain[6920:]\n",
    "df_test30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> (5.1) Train all models from the previous exercises using the new training set and evaluate their quality on the new test set.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u><i>Train Linear Regression with 70% Training Model</i></u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept                0.536233\n",
      "ShippingPrice           -0.000364\n",
      "SellerFeedbackRating    -0.004781\n",
      "ShippingTime_minHours    0.002842\n",
      "ShippingTime_maxHours   -0.002375\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the linear regression model.\n",
    "# In this section, we train a simple linear regression with all descriptive features.\n",
    "# For training the model we call the method fit() on the given data stored in our df dataframe.\n",
    "lm10 = sm.ols(formula=\"IsWinner ~  ShippingPrice + SellerFeedbackRating + ShippingTime_minHours + ShippingTime_maxHours\", data=df_train70).fit()\n",
    "# Print the model weights/parameters\n",
    "# This gives different weights for the model than doing the weights separately\n",
    "print(lm10.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (5.1) Evaluate their quality on the new test set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4876    0.032126\n",
       "9447    0.030800\n",
       "6630    0.017138\n",
       "3093    0.065101\n",
       "1332    0.031590\n",
       "830     0.032516\n",
       "626     0.028877\n",
       "4672    0.016457\n",
       "3912    0.032228\n",
       "9717    0.078565\n",
       "5675    0.029294\n",
       "591     0.055384\n",
       "1532   -0.120438\n",
       "3451    0.238655\n",
       "5321   -0.110364\n",
       "3338    0.085574\n",
       "7403    0.031980\n",
       "6563    0.098541\n",
       "4101    0.027855\n",
       "1085    0.006448\n",
       "2121    0.055384\n",
       "2261    0.055384\n",
       "732     0.055384\n",
       "6371    0.012357\n",
       "6082    0.065101\n",
       "312     0.053563\n",
       "9531    0.085574\n",
       "2297    0.021919\n",
       "1484    0.026797\n",
       "5904    0.031623\n",
       "          ...   \n",
       "9480    0.031480\n",
       "3427    0.052421\n",
       "5856    0.074689\n",
       "4383    0.016457\n",
       "388     0.061465\n",
       "5394    0.053563\n",
       "2331    0.027855\n",
       "2415    0.488417\n",
       "8199    0.067998\n",
       "5996    0.010306\n",
       "6330    0.019372\n",
       "9209    0.021919\n",
       "3958    0.053563\n",
       "5724    0.037920\n",
       "1828    0.053563\n",
       "8051    0.031480\n",
       "8540    0.053563\n",
       "8612    0.536233\n",
       "7755    0.030800\n",
       "5280    0.016457\n",
       "9776    0.065101\n",
       "9590    0.055384\n",
       "9549    0.032250\n",
       "3436   -0.002625\n",
       "1452    0.036261\n",
       "2772    0.058743\n",
       "7519    0.061465\n",
       "2757    0.051964\n",
       "9716   -0.120405\n",
       "6820    0.075065\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicts the if seller IsWinner given the subset of Continuous Feature values from 30% test set\n",
    "lm10.predict(df_test30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   R-squared:                       0.189\n",
      "Model:                            OLS   Adj. R-squared:                  0.188\n",
      "Method:                 Least Squares   F-statistic:                     402.2\n",
      "Date:                Tue, 18 Apr 2017   Prob (F-statistic):          5.36e-312\n",
      "Time:                        08:59:28   Log-Likelihood:                 990.42\n",
      "No. Observations:                6920   AIC:                            -1971.\n",
      "Df Residuals:                    6915   BIC:                            -1937.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 0.5362      0.012     42.990      0.000       0.512       0.561\n",
      "ShippingPrice            -0.0004   9.56e-05     -3.809      0.000      -0.001      -0.000\n",
      "SellerFeedbackRating     -0.0048      0.000    -37.609      0.000      -0.005      -0.005\n",
      "ShippingTime_minHours     0.0028      0.000     11.530      0.000       0.002       0.003\n",
      "ShippingTime_maxHours    -0.0024      0.000    -13.907      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                     4840.191   Durbin-Watson:                   1.959\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            62022.918\n",
      "Skew:                           3.323   Prob(JB):                         0.00\n",
      "Kurtosis:                      16.074   Cond. No.                         876.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(lm10.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u><i>Train Logistic Regression with 70% Training Model</i></u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.165563\n",
      "         Iterations 10\n",
      "Intercept                1.072781\n",
      "ShippingPrice           -0.036391\n",
      "SellerFeedbackRating    -0.027306\n",
      "ShippingTime_minHours    0.103112\n",
      "ShippingTime_maxHours   -0.088696\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# The formula specifies the target feature and the descriptive features used for training the \n",
    "# logistic regression model.\n",
    "# A multiple logistic regression is calucated for subset of promising Continuous Features together.\n",
    "\n",
    "# For training the model we call the method fit() on the given data stored in our dataframe.\n",
    "logreg8 = sm.logit(formula=\"IsWinner ~  ShippingPrice + SellerFeedbackRating + ShippingTime_minHours + ShippingTime_maxHours\", data=df_train70).fit()\n",
    "# Print the model weights/parameters\n",
    "\n",
    "print(logreg8.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (5.1) Evaluate their quality on the new test set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4876    2.481184e-02\n",
       "9447    2.303765e-02\n",
       "6630    2.871372e-02\n",
       "3093    7.911685e-02\n",
       "1332    2.407985e-02\n",
       "830     2.535824e-02\n",
       "626     3.201189e-02\n",
       "4672    2.161479e-02\n",
       "3912    2.495370e-02\n",
       "9717    1.353085e-02\n",
       "5675    2.708468e-02\n",
       "591     3.398169e-02\n",
       "1532    6.506304e-06\n",
       "3451    3.967966e-02\n",
       "5321    1.159000e-05\n",
       "3338    3.283301e-02\n",
       "7403    2.461054e-02\n",
       "6563    7.202777e-02\n",
       "4101    2.499392e-02\n",
       "1085    2.019970e-02\n",
       "2121    3.398169e-02\n",
       "2261    3.398169e-02\n",
       "732     3.398169e-02\n",
       "6371    2.811370e-02\n",
       "6082    7.911685e-02\n",
       "312     3.071615e-02\n",
       "9531    3.283301e-02\n",
       "2297    2.932616e-02\n",
       "1484    2.851636e-02\n",
       "5904    2.412405e-02\n",
       "            ...     \n",
       "9480    3.058927e-02\n",
       "3427    3.988371e-02\n",
       "5856    1.086440e-02\n",
       "4383    2.161479e-02\n",
       "388     6.520413e-02\n",
       "5394    3.071615e-02\n",
       "2331    2.499392e-02\n",
       "2415    1.846583e-01\n",
       "8199    7.305854e-02\n",
       "5996    2.507363e-02\n",
       "6330    2.544473e-02\n",
       "9209    2.932616e-02\n",
       "3958    3.071615e-02\n",
       "5724    2.096416e-02\n",
       "1828    3.071615e-02\n",
       "8051    3.058927e-02\n",
       "8540    3.071615e-02\n",
       "8612    7.879672e-01\n",
       "7755    2.303765e-02\n",
       "5280    2.161479e-02\n",
       "9776    7.911685e-02\n",
       "9590    3.398169e-02\n",
       "9549    2.498421e-02\n",
       "3436    1.210889e-02\n",
       "1452    3.124042e-02\n",
       "2772    7.869615e-03\n",
       "7519    6.520413e-02\n",
       "2757    1.960779e-14\n",
       "9716    6.518543e-06\n",
       "6820    5.539811e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of IsWinner given 9886 rows of ListingPrice\n",
    "predictions_test = logreg7.predict(df_test30)\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               IsWinner   No. Observations:                 6920\n",
      "Model:                          Logit   Df Residuals:                     6915\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 18 Apr 2017   Pseudo R-squ.:                  0.2477\n",
      "Time:                        08:59:44   Log-Likelihood:                -1145.7\n",
      "converged:                       True   LL-Null:                       -1522.9\n",
      "                                        LLR p-value:                5.722e-162\n",
      "=========================================================================================\n",
      "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept                 1.0728      0.177      6.066      0.000       0.726       1.419\n",
      "ShippingPrice            -0.0364      0.008     -4.749      0.000      -0.051      -0.021\n",
      "SellerFeedbackRating     -0.0273      0.002    -11.776      0.000      -0.032      -0.023\n",
      "ShippingTime_minHours     0.1031      0.012      8.277      0.000       0.079       0.128\n",
      "ShippingTime_maxHours    -0.0887      0.012     -7.554      0.000      -0.112      -0.066\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logreg8.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h4><u><i>Train Logistic Regression with 70% Training Model: With Scikit Learn</i></u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      "       Intercept  ShippingPrice  SellerFeedbackRating  ShippingTime_minHours  \\\n",
      "9522        1.0          10.60                    50                     24   \n",
      "9829        1.0           9.98                    96                     96   \n",
      "9237        1.0           0.00                   100                     24   \n",
      "298         1.0          45.00                   100                    264   \n",
      "4256        1.0           0.00                    98                     24   \n",
      "2402        1.0           5.54                     0                     24   \n",
      "4745        1.0           0.00                   100                     24   \n",
      "3757        1.0          12.95                    96                     24   \n",
      "7572        1.0          20.26                   100                     24   \n",
      "8560        1.0          27.23                    93                     24   \n",
      "4340        1.0           0.00                     0                      0   \n",
      "6323        1.0          12.60                    96                     96   \n",
      "1618        1.0           7.00                    96                     96   \n",
      "1035        1.0           0.00                    95                     24   \n",
      "9131        1.0          17.95                    96                     24   \n",
      "3600        1.0          13.41                   100                     24   \n",
      "2495        1.0           5.00                    91                     24   \n",
      "7207        1.0          12.88                    98                     24   \n",
      "5050        1.0          14.99                    95                     24   \n",
      "2250        1.0          12.95                    97                     24   \n",
      "3738        1.0           0.00                    91                     24   \n",
      "8929        1.0          10.51                    92                     72   \n",
      "7822        1.0           5.00                    91                     24   \n",
      "4057        1.0          21.94                    93                     24   \n",
      "9377        1.0           0.00                    75                    144   \n",
      "9545        1.0           0.00                     0                      0   \n",
      "1239        1.0           9.95                    96                     24   \n",
      "3938        1.0           5.00                    91                     24   \n",
      "1417        1.0           9.19                    97                    144   \n",
      "5395        1.0           9.98                    96                     96   \n",
      "...         ...            ...                   ...                    ...   \n",
      "926         1.0          14.99                    98                     24   \n",
      "2300        1.0           5.00                    91                     24   \n",
      "2506        1.0           0.00                    98                     24   \n",
      "7104        1.0         192.84                    94                     24   \n",
      "9535        1.0           5.00                    91                     24   \n",
      "863         1.0           7.04                    50                     24   \n",
      "8681        1.0          62.20                    82                     24   \n",
      "7987        1.0          51.76                    97                    144   \n",
      "2601        1.0          11.66                    98                     24   \n",
      "8859        1.0          13.20                    96                     24   \n",
      "8193        1.0           0.00                    95                     24   \n",
      "3249        1.0           8.90                    95                     96   \n",
      "4301        1.0           5.00                    91                     24   \n",
      "9375        1.0           0.00                    98                     24   \n",
      "7741        1.0           0.00                   100                     96   \n",
      "7481        1.0          12.95                    96                     24   \n",
      "1100        1.0          61.07                    88                     96   \n",
      "4647        1.0          10.00                   100                     24   \n",
      "4459        1.0           9.98                    96                     96   \n",
      "7615        1.0           0.00                   100                     24   \n",
      "4010        1.0           5.00                    91                     24   \n",
      "5075        1.0           7.00                    96                     24   \n",
      "7873        1.0          20.05                    93                     24   \n",
      "4563        1.0          30.52                    93                     24   \n",
      "5474        1.0           0.00                    96                     24   \n",
      "5782        1.0           5.00                    91                     24   \n",
      "398         1.0           7.45                    96                     24   \n",
      "9243        1.0           9.95                    96                     24   \n",
      "9585        1.0          13.38                    95                     24   \n",
      "4792        1.0           9.00                    96                     24   \n",
      "\n",
      "      ShippingTime_maxHours  \n",
      "9522                     48  \n",
      "9829                    120  \n",
      "9237                     48  \n",
      "298                     360  \n",
      "4256                     48  \n",
      "2402                     48  \n",
      "4745                     48  \n",
      "3757                     48  \n",
      "7572                     48  \n",
      "8560                     48  \n",
      "4340                      0  \n",
      "6323                    120  \n",
      "1618                    120  \n",
      "1035                     48  \n",
      "9131                     48  \n",
      "3600                     48  \n",
      "2495                     48  \n",
      "7207                     48  \n",
      "5050                     48  \n",
      "2250                     48  \n",
      "3738                     48  \n",
      "8929                     96  \n",
      "7822                     48  \n",
      "4057                     48  \n",
      "9377                    240  \n",
      "9545                      0  \n",
      "1239                     48  \n",
      "3938                     48  \n",
      "1417                    240  \n",
      "5395                    120  \n",
      "...                     ...  \n",
      "926                      48  \n",
      "2300                     48  \n",
      "2506                     48  \n",
      "7104                     48  \n",
      "9535                     48  \n",
      "863                      48  \n",
      "8681                     48  \n",
      "7987                    240  \n",
      "2601                     48  \n",
      "8859                     48  \n",
      "8193                     48  \n",
      "3249                    120  \n",
      "4301                     48  \n",
      "9375                     48  \n",
      "7741                    120  \n",
      "7481                     48  \n",
      "1100                    120  \n",
      "4647                     48  \n",
      "4459                    120  \n",
      "7615                     48  \n",
      "4010                     48  \n",
      "5075                     48  \n",
      "7873                     48  \n",
      "4563                     48  \n",
      "5474                     48  \n",
      "5782                     48  \n",
      "398                      48  \n",
      "9243                     48  \n",
      "9585                     48  \n",
      "4792                     48  \n",
      "\n",
      "[6920 rows x 5 columns]\n",
      "\n",
      "Target feature:\n",
      " 9522    0\n",
      "9829    0\n",
      "9237    0\n",
      "298     0\n",
      "4256    0\n",
      "2402    0\n",
      "4745    0\n",
      "3757    0\n",
      "7572    0\n",
      "8560    0\n",
      "4340    1\n",
      "6323    0\n",
      "1618    0\n",
      "1035    0\n",
      "9131    0\n",
      "3600    0\n",
      "2495    0\n",
      "7207    0\n",
      "5050    0\n",
      "2250    0\n",
      "3738    0\n",
      "8929    0\n",
      "7822    0\n",
      "4057    0\n",
      "9377    0\n",
      "9545    1\n",
      "1239    0\n",
      "3938    0\n",
      "1417    0\n",
      "5395    0\n",
      "       ..\n",
      "926     0\n",
      "2300    0\n",
      "2506    0\n",
      "7104    0\n",
      "9535    0\n",
      "863     0\n",
      "8681    0\n",
      "7987    0\n",
      "2601    0\n",
      "8859    0\n",
      "8193    0\n",
      "3249    0\n",
      "4301    0\n",
      "9375    0\n",
      "7741    0\n",
      "7481    0\n",
      "1100    0\n",
      "4647    0\n",
      "4459    0\n",
      "7615    0\n",
      "4010    0\n",
      "5075    0\n",
      "7873    0\n",
      "4563    0\n",
      "5474    0\n",
      "5782    0\n",
      "398     0\n",
      "9243    0\n",
      "9585    1\n",
      "4792    0\n",
      "Name: IsWinner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare the descriptive features   \n",
    "X_trainlog = df_train70[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']]\n",
    "y_trainlog = df_train70.IsWinner\n",
    "X_testlog = df_test30[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']]\n",
    "y_testlog = df_test30.IsWinner\n",
    "print(\"Descriptive features:\\n\", X_trainlog)\n",
    "print(\"\\nTarget feature:\\n\", y_trainlog)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a model using logistic regression from scikit-learn.\n",
    "# Use only the descriptive feature Size.\n",
    "logreg_retrain = LogisticRegression().fit(X_trainlog[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']], y_trainlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients: \n",
      " [[ 0.52801435 -0.03638309 -0.02728912  0.10245768 -0.08804823]]\n"
     ]
    }
   ],
   "source": [
    "# Examine the estimated logistic regression coefficients.\n",
    "print(\"Coeficients: \\n\", logreg_retrain.coef_)\n",
    "#pd.DataFrame(zip(X[['Size']], np.transpose(logreg.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> (5.1) Evaluate their quality on the new test set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.76263456e-01,   2.37365443e-02],\n",
       "       [  9.79146330e-01,   2.08536704e-02],\n",
       "       [  9.68106043e-01,   3.18939575e-02],\n",
       "       ..., \n",
       "       [  9.99999993e-01,   6.54198571e-09],\n",
       "       [  9.99945997e-01,   5.40033073e-05],\n",
       "       [  9.41355755e-01,   5.86442449e-02]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for all examples. \n",
    "# The output is a pair for each example, \n",
    "# The first component is the probability of the negative class (class 0).\n",
    "# The second component is the probability of the positive class (class 1).\n",
    "logreg_retrain.predict_proba(X_testlog[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicted class labels for all examples, \n",
    "# using the trained model, on in-sample data (same sample used for training and test)\n",
    "predictions = logreg_retrain.predict(X_testlog[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']])\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "4876            0               0\n",
       "9447            0               0\n",
       "6630            0               0\n",
       "3093            0               0\n",
       "1332            0               0\n",
       "830             0               0\n",
       "626             0               0\n",
       "4672            0               0\n",
       "3912            0               0\n",
       "9717            0               0\n",
       "5675            0               0\n",
       "591             0               0\n",
       "1532            0               0\n",
       "3451            0               0\n",
       "5321            0               0\n",
       "3338            0               0\n",
       "7403            0               0\n",
       "6563            0               0\n",
       "4101            0               0\n",
       "1085            0               0\n",
       "2121            0               0\n",
       "2261            0               0\n",
       "732             0               0\n",
       "6371            0               0\n",
       "6082            0               0\n",
       "312             0               0\n",
       "9531            0               0\n",
       "2297            0               0\n",
       "1484            0               0\n",
       "5904            0               0\n",
       "...           ...             ...\n",
       "9480            0               0\n",
       "3427            0               0\n",
       "5856            0               0\n",
       "4383            0               0\n",
       "388             0               0\n",
       "5394            0               0\n",
       "2331            0               0\n",
       "2415            0               0\n",
       "8199            1               0\n",
       "5996            0               0\n",
       "6330            0               0\n",
       "9209            0               0\n",
       "3958            0               0\n",
       "5724            0               0\n",
       "1828            0               0\n",
       "8051            0               0\n",
       "8540            0               0\n",
       "8612            1               1\n",
       "7755            0               0\n",
       "5280            0               0\n",
       "9776            0               0\n",
       "9590            0               0\n",
       "9549            0               0\n",
       "3436            0               0\n",
       "1452            0               0\n",
       "2772            0               0\n",
       "7519            0               0\n",
       "2757            0               0\n",
       "9716            0               0\n",
       "6820            0               0\n",
       "\n",
       "[2966 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_true_vs_predicted_test = pd.DataFrame({'ActualClass': df_test30.IsWinner, 'PredictedClass': predictions})\n",
    "df_true_vs_predicted_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642616318273769"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the accuracy on the training set. \n",
    "# For this we use the predicted class labels,\n",
    "# and compare them to the true class labels.\n",
    "# The accuracy is the ratio of correct predictions to total examples.\n",
    "# Total accuracy is 0.96 or 96% accuracy\n",
    "logreg_retrain.score(X_testlog[['Intercept', 'ShippingPrice', 'SellerFeedbackRating', 'ShippingTime_minHours', 'ShippingTime_maxHours']], y_testlog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u><i>Train Random Forest with 70% Training Model</i></u></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive features:\n",
      "       ListingPrice  ShippingPrice  ShippingTime_minHours  \\\n",
      "9522        471.91          10.60                     24   \n",
      "9829        332.96           9.98                     96   \n",
      "9237         55.15           0.00                     24   \n",
      "298         211.00          45.00                    264   \n",
      "4256        176.47           0.00                     24   \n",
      "2402          9.62           5.54                     24   \n",
      "4745        129.84           0.00                     24   \n",
      "3757        117.42          12.95                     24   \n",
      "7572        444.53          20.26                     24   \n",
      "8560        265.26          27.23                     24   \n",
      "4340         67.99           0.00                      0   \n",
      "6323         68.76          12.60                     96   \n",
      "1618         56.34           7.00                     96   \n",
      "1035        116.12           0.00                     24   \n",
      "9131        234.34          17.95                     24   \n",
      "3600         64.40          13.41                     24   \n",
      "2495          8.46           5.00                     24   \n",
      "7207         53.94          12.88                     24   \n",
      "5050        260.33          14.99                     24   \n",
      "2250         13.94          12.95                     24   \n",
      "3738        176.85           0.00                     24   \n",
      "8929        128.91          10.51                     72   \n",
      "7822        848.58           5.00                     24   \n",
      "4057        109.32          21.94                     24   \n",
      "9377         69.43           0.00                    144   \n",
      "9545         26.66           0.00                      0   \n",
      "1239         73.47           9.95                     24   \n",
      "3938         85.04           5.00                     24   \n",
      "1417         15.98           9.19                    144   \n",
      "5395         36.85           9.98                     96   \n",
      "...            ...            ...                    ...   \n",
      "926          40.66          14.99                     24   \n",
      "2300         86.80           5.00                     24   \n",
      "2506         88.25           0.00                     24   \n",
      "7104        554.62         192.84                     24   \n",
      "9535         33.39           5.00                     24   \n",
      "863          94.18           7.04                     24   \n",
      "8681        396.61          62.20                     24   \n",
      "7987        378.13          51.76                    144   \n",
      "2601         26.01          11.66                     24   \n",
      "8859         79.09          13.20                     24   \n",
      "8193         64.30           0.00                     24   \n",
      "3249        197.10           8.90                     96   \n",
      "4301         52.86           5.00                     24   \n",
      "9375         65.72           0.00                     24   \n",
      "7741        369.57           0.00                     96   \n",
      "7481        105.04          12.95                     24   \n",
      "1100        246.75          61.07                     96   \n",
      "4647        584.01          10.00                     24   \n",
      "4459        123.80           9.98                     96   \n",
      "7615         63.06           0.00                     24   \n",
      "4010        158.51           5.00                     24   \n",
      "5075         62.00           7.00                     24   \n",
      "7873         42.08          20.05                     24   \n",
      "4563        215.66          30.52                     24   \n",
      "5474        265.38           0.00                     24   \n",
      "5782        308.93           5.00                     24   \n",
      "398          45.93           7.45                     24   \n",
      "9243         54.58           9.95                     24   \n",
      "9585        384.56          13.38                     24   \n",
      "4792         35.90           9.00                     24   \n",
      "\n",
      "      ShippingTime_maxHours  \n",
      "9522                     48  \n",
      "9829                    120  \n",
      "9237                     48  \n",
      "298                     360  \n",
      "4256                     48  \n",
      "2402                     48  \n",
      "4745                     48  \n",
      "3757                     48  \n",
      "7572                     48  \n",
      "8560                     48  \n",
      "4340                      0  \n",
      "6323                    120  \n",
      "1618                    120  \n",
      "1035                     48  \n",
      "9131                     48  \n",
      "3600                     48  \n",
      "2495                     48  \n",
      "7207                     48  \n",
      "5050                     48  \n",
      "2250                     48  \n",
      "3738                     48  \n",
      "8929                     96  \n",
      "7822                     48  \n",
      "4057                     48  \n",
      "9377                    240  \n",
      "9545                      0  \n",
      "1239                     48  \n",
      "3938                     48  \n",
      "1417                    240  \n",
      "5395                    120  \n",
      "...                     ...  \n",
      "926                      48  \n",
      "2300                     48  \n",
      "2506                     48  \n",
      "7104                     48  \n",
      "9535                     48  \n",
      "863                      48  \n",
      "8681                     48  \n",
      "7987                    240  \n",
      "2601                     48  \n",
      "8859                     48  \n",
      "8193                     48  \n",
      "3249                    120  \n",
      "4301                     48  \n",
      "9375                     48  \n",
      "7741                    120  \n",
      "7481                     48  \n",
      "1100                    120  \n",
      "4647                     48  \n",
      "4459                    120  \n",
      "7615                     48  \n",
      "4010                     48  \n",
      "5075                     48  \n",
      "7873                     48  \n",
      "4563                     48  \n",
      "5474                     48  \n",
      "5782                     48  \n",
      "398                      48  \n",
      "9243                     48  \n",
      "9585                     48  \n",
      "4792                     48  \n",
      "\n",
      "[6920 rows x 4 columns]\n",
      "\n",
      "Target feature:\n",
      " 9522    0\n",
      "9829    0\n",
      "9237    0\n",
      "298     0\n",
      "4256    0\n",
      "2402    0\n",
      "4745    0\n",
      "3757    0\n",
      "7572    0\n",
      "8560    0\n",
      "4340    1\n",
      "6323    0\n",
      "1618    0\n",
      "1035    0\n",
      "9131    0\n",
      "3600    0\n",
      "2495    0\n",
      "7207    0\n",
      "5050    0\n",
      "2250    0\n",
      "3738    0\n",
      "8929    0\n",
      "7822    0\n",
      "4057    0\n",
      "9377    0\n",
      "9545    1\n",
      "1239    0\n",
      "3938    0\n",
      "1417    0\n",
      "5395    0\n",
      "       ..\n",
      "926     0\n",
      "2300    0\n",
      "2506    0\n",
      "7104    0\n",
      "9535    0\n",
      "863     0\n",
      "8681    0\n",
      "7987    0\n",
      "2601    0\n",
      "8859    0\n",
      "8193    0\n",
      "3249    0\n",
      "4301    0\n",
      "9375    0\n",
      "7741    0\n",
      "7481    0\n",
      "1100    0\n",
      "4647    0\n",
      "4459    0\n",
      "7615    0\n",
      "4010    0\n",
      "5075    0\n",
      "7873    0\n",
      "4563    0\n",
      "5474    0\n",
      "5782    0\n",
      "398     0\n",
      "9243    0\n",
      "9585    1\n",
      "4792    0\n",
      "Name: IsWinner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train1 = df_train70[['ListingPrice', 'ShippingPrice', 'ShippingTime_minHours', 'ShippingTime_maxHours']]\n",
    "y_train1 = df_train70.IsWinner\n",
    "X_test1 = df_test30[['ListingPrice', 'ShippingPrice', 'ShippingTime_minHours', 'ShippingTime_maxHours']]\n",
    "y_test1 = df_test30.IsWinner\n",
    "print(\"Descriptive features:\\n\", X_train1)\n",
    "print(\"\\nTarget feature:\\n\", y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=True, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.  ],\n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 0.93,  0.07],\n",
       "       ..., \n",
       "       [ 0.37,  0.63],\n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 0.94,  0.06]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted probabilities for all examples. \n",
    "# The output is a pair for each example, \n",
    "# The first component is the probability of the negative class (class 0).\n",
    "# The second component is the probability of the positive class (class 1).\n",
    "rfc.predict_proba(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualClass</th>\n",
       "      <th>PredictedClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9531</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ActualClass  PredictedClass\n",
       "4876            0               0\n",
       "9447            0               0\n",
       "6630            0               0\n",
       "3093            0               0\n",
       "1332            0               0\n",
       "830             0               0\n",
       "626             0               0\n",
       "4672            0               0\n",
       "3912            0               0\n",
       "9717            0               0\n",
       "5675            0               0\n",
       "591             0               0\n",
       "1532            0               0\n",
       "3451            0               0\n",
       "5321            0               0\n",
       "3338            0               0\n",
       "7403            0               0\n",
       "6563            0               0\n",
       "4101            0               0\n",
       "1085            0               0\n",
       "2121            0               0\n",
       "2261            0               0\n",
       "732             0               0\n",
       "6371            0               0\n",
       "6082            0               0\n",
       "312             0               0\n",
       "9531            0               0\n",
       "2297            0               0\n",
       "1484            0               0\n",
       "5904            0               0\n",
       "...           ...             ...\n",
       "9480            0               0\n",
       "3427            0               0\n",
       "5856            0               0\n",
       "4383            0               0\n",
       "388             0               0\n",
       "5394            0               0\n",
       "2331            0               0\n",
       "2415            0               0\n",
       "8199            1               0\n",
       "5996            0               0\n",
       "6330            0               0\n",
       "9209            0               0\n",
       "3958            0               0\n",
       "5724            0               0\n",
       "1828            0               0\n",
       "8051            0               0\n",
       "8540            0               0\n",
       "8612            1               1\n",
       "7755            0               0\n",
       "5280            0               0\n",
       "9776            0               0\n",
       "9590            0               0\n",
       "9549            0               0\n",
       "3436            0               0\n",
       "1452            0               0\n",
       "2772            0               0\n",
       "7519            0               0\n",
       "2757            0               1\n",
       "9716            0               0\n",
       "6820            0               0\n",
       "\n",
       "[2966 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted class labels for all examples, \n",
    "# using the trained model, on in-sample data (same sample used for training and test)\n",
    "rfc_predictions = rfc.predict(X_test1)\n",
    "df_true_vs_rfc_predicted = pd.DataFrame({'ActualClass': y_test1, 'PredictedClass': rfc_predictions})\n",
    "df_true_vs_rfc_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> (5.1) Evaluate their quality on the new test set.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.969318948078\n",
      "\n",
      "Confusion matrix: \n",
      " [[2781   36]\n",
      " [  55   94]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      2817\n",
      "          1       0.72      0.63      0.67       149\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test1, rfc_predictions))\n",
    "print(\"\\nConfusion matrix: \\n\", metrics.confusion_matrix(y_test1, rfc_predictions))\n",
    "print(\"\\nClassification report:\\n \", metrics.classification_report(y_test1, rfc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> (5.1) Print classification evaluation metrics for all models on the test set (e.g., Accuracy, Confusion matrix, Precision, Recall, F1).</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4><i>Linear Regression</i></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Value IsWinner</th>\n",
       "      <th>Prediction IsWinner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>0</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6630</th>\n",
       "      <td>0</td>\n",
       "      <td>0.017138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0</td>\n",
       "      <td>0.065101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0</td>\n",
       "      <td>0.028877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>0</td>\n",
       "      <td>0.078565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>0</td>\n",
       "      <td>0.029294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.120438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>0</td>\n",
       "      <td>0.238655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.110364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>0</td>\n",
       "      <td>0.085574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>0</td>\n",
       "      <td>0.098541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>0</td>\n",
       "      <td>0.012357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>0</td>\n",
       "      <td>0.065101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9531</th>\n",
       "      <td>0</td>\n",
       "      <td>0.085574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9480</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>0</td>\n",
       "      <td>0.052421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>0</td>\n",
       "      <td>0.074689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>0</td>\n",
       "      <td>0.488417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>1</td>\n",
       "      <td>0.067998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9209</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8540</th>\n",
       "      <td>0</td>\n",
       "      <td>0.053563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>1</td>\n",
       "      <td>0.536233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>0</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9776</th>\n",
       "      <td>0</td>\n",
       "      <td>0.065101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3436</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>0</td>\n",
       "      <td>0.036261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>0</td>\n",
       "      <td>0.051964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9716</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.120405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6820</th>\n",
       "      <td>0</td>\n",
       "      <td>0.075065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2966 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual Value IsWinner  Prediction IsWinner\n",
       "4876                      0             0.032126\n",
       "9447                      0             0.030800\n",
       "6630                      0             0.017138\n",
       "3093                      0             0.065101\n",
       "1332                      0             0.031590\n",
       "830                       0             0.032516\n",
       "626                       0             0.028877\n",
       "4672                      0             0.016457\n",
       "3912                      0             0.032228\n",
       "9717                      0             0.078565\n",
       "5675                      0             0.029294\n",
       "591                       0             0.055384\n",
       "1532                      0            -0.120438\n",
       "3451                      0             0.238655\n",
       "5321                      0            -0.110364\n",
       "3338                      0             0.085574\n",
       "7403                      0             0.031980\n",
       "6563                      0             0.098541\n",
       "4101                      0             0.027855\n",
       "1085                      0             0.006448\n",
       "2121                      0             0.055384\n",
       "2261                      0             0.055384\n",
       "732                       0             0.055384\n",
       "6371                      0             0.012357\n",
       "6082                      0             0.065101\n",
       "312                       0             0.053563\n",
       "9531                      0             0.085574\n",
       "2297                      0             0.021919\n",
       "1484                      0             0.026797\n",
       "5904                      0             0.031623\n",
       "...                     ...                  ...\n",
       "9480                      0             0.031480\n",
       "3427                      0             0.052421\n",
       "5856                      0             0.074689\n",
       "4383                      0             0.016457\n",
       "388                       0             0.061465\n",
       "5394                      0             0.053563\n",
       "2331                      0             0.027855\n",
       "2415                      0             0.488417\n",
       "8199                      1             0.067998\n",
       "5996                      0             0.010306\n",
       "6330                      0             0.019372\n",
       "9209                      0             0.021919\n",
       "3958                      0             0.053563\n",
       "5724                      0             0.037920\n",
       "1828                      0             0.053563\n",
       "8051                      0             0.031480\n",
       "8540                      0             0.053563\n",
       "8612                      1             0.536233\n",
       "7755                      0             0.030800\n",
       "5280                      0             0.016457\n",
       "9776                      0             0.065101\n",
       "9590                      0             0.055384\n",
       "9549                      0             0.032250\n",
       "3436                      0            -0.002625\n",
       "1452                      0             0.036261\n",
       "2772                      0             0.058743\n",
       "7519                      0             0.061465\n",
       "2757                      0             0.051964\n",
       "9716                      0            -0.120405\n",
       "6820                      0             0.075065\n",
       "\n",
       "[2966 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df_test = pd.DataFrame({'Actual Value IsWinner': df_test30.IsWinner, 'Prediction IsWinner': lm10.predict(df_test30)})\n",
    "predict_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual - Predicted:\n",
      " 4876   -0.032126\n",
      "9447   -0.030800\n",
      "6630   -0.017138\n",
      "3093   -0.065101\n",
      "1332   -0.031590\n",
      "830    -0.032516\n",
      "626    -0.028877\n",
      "4672   -0.016457\n",
      "3912   -0.032228\n",
      "9717   -0.078565\n",
      "5675   -0.029294\n",
      "591    -0.055384\n",
      "1532    0.120438\n",
      "3451   -0.238655\n",
      "5321    0.110364\n",
      "3338   -0.085574\n",
      "7403   -0.031980\n",
      "6563   -0.098541\n",
      "4101   -0.027855\n",
      "1085   -0.006448\n",
      "2121   -0.055384\n",
      "2261   -0.055384\n",
      "732    -0.055384\n",
      "6371   -0.012357\n",
      "6082   -0.065101\n",
      "312    -0.053563\n",
      "9531   -0.085574\n",
      "2297   -0.021919\n",
      "1484   -0.026797\n",
      "5904   -0.031623\n",
      "          ...   \n",
      "9480   -0.031480\n",
      "3427   -0.052421\n",
      "5856   -0.074689\n",
      "4383   -0.016457\n",
      "388    -0.061465\n",
      "5394   -0.053563\n",
      "2331   -0.027855\n",
      "2415   -0.488417\n",
      "8199    0.932002\n",
      "5996   -0.010306\n",
      "6330   -0.019372\n",
      "9209   -0.021919\n",
      "3958   -0.053563\n",
      "5724   -0.037920\n",
      "1828   -0.053563\n",
      "8051   -0.031480\n",
      "8540   -0.053563\n",
      "8612    0.463767\n",
      "7755   -0.030800\n",
      "5280   -0.016457\n",
      "9776   -0.065101\n",
      "9590   -0.055384\n",
      "9549   -0.032250\n",
      "3436    0.002625\n",
      "1452   -0.036261\n",
      "2772   -0.058743\n",
      "7519   -0.061465\n",
      "2757   -0.051964\n",
      "9716    0.120405\n",
      "6820   -0.075065\n",
      "dtype: float64\n",
      "\n",
      "(Actual - Predicted) squared:\n",
      " 4876    0.001032\n",
      "9447    0.000949\n",
      "6630    0.000294\n",
      "3093    0.004238\n",
      "1332    0.000998\n",
      "830     0.001057\n",
      "626     0.000834\n",
      "4672    0.000271\n",
      "3912    0.001039\n",
      "9717    0.006172\n",
      "5675    0.000858\n",
      "591     0.003067\n",
      "1532    0.014505\n",
      "3451    0.056956\n",
      "5321    0.012180\n",
      "3338    0.007323\n",
      "7403    0.001023\n",
      "6563    0.009710\n",
      "4101    0.000776\n",
      "1085    0.000042\n",
      "2121    0.003067\n",
      "2261    0.003067\n",
      "732     0.003067\n",
      "6371    0.000153\n",
      "6082    0.004238\n",
      "312     0.002869\n",
      "9531    0.007323\n",
      "2297    0.000480\n",
      "1484    0.000718\n",
      "5904    0.001000\n",
      "          ...   \n",
      "9480    0.000991\n",
      "3427    0.002748\n",
      "5856    0.005578\n",
      "4383    0.000271\n",
      "388     0.003778\n",
      "5394    0.002869\n",
      "2331    0.000776\n",
      "2415    0.238551\n",
      "8199    0.868628\n",
      "5996    0.000106\n",
      "6330    0.000375\n",
      "9209    0.000480\n",
      "3958    0.002869\n",
      "5724    0.001438\n",
      "1828    0.002869\n",
      "8051    0.000991\n",
      "8540    0.002869\n",
      "8612    0.215080\n",
      "7755    0.000949\n",
      "5280    0.000271\n",
      "9776    0.004238\n",
      "9590    0.003067\n",
      "9549    0.001040\n",
      "3436    0.000007\n",
      "1452    0.001315\n",
      "2772    0.003451\n",
      "7519    0.003778\n",
      "2757    0.002700\n",
      "9716    0.014497\n",
      "6820    0.005635\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Pair the actual and the predicted values\n",
    "print(\"Actual - Predicted:\\n\", (df_test30.IsWinner - lm10.predict(df_test30)))\n",
    "print(\"\\n(Actual - Predicted) squared:\\n\", (df_test30.IsWinner - lm10.predict(df_test30))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Squared Error:\n",
      " 0.0394863795888\n"
     ]
    }
   ],
   "source": [
    "# Print the Mean Squared Error of the model on the training set\n",
    "mse = ((df_test30.IsWinner - lm10.predict(df_test30))** 2).mean()\n",
    "print(\"\\nMean Squared Error:\\n\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Actual - Predicted|:\n",
      " 4876    0.032126\n",
      "9447    0.030800\n",
      "6630    0.017138\n",
      "3093    0.065101\n",
      "1332    0.031590\n",
      "830     0.032516\n",
      "626     0.028877\n",
      "4672    0.016457\n",
      "3912    0.032228\n",
      "9717    0.078565\n",
      "5675    0.029294\n",
      "591     0.055384\n",
      "1532    0.120438\n",
      "3451    0.238655\n",
      "5321    0.110364\n",
      "3338    0.085574\n",
      "7403    0.031980\n",
      "6563    0.098541\n",
      "4101    0.027855\n",
      "1085    0.006448\n",
      "2121    0.055384\n",
      "2261    0.055384\n",
      "732     0.055384\n",
      "6371    0.012357\n",
      "6082    0.065101\n",
      "312     0.053563\n",
      "9531    0.085574\n",
      "2297    0.021919\n",
      "1484    0.026797\n",
      "5904    0.031623\n",
      "          ...   \n",
      "9480    0.031480\n",
      "3427    0.052421\n",
      "5856    0.074689\n",
      "4383    0.016457\n",
      "388     0.061465\n",
      "5394    0.053563\n",
      "2331    0.027855\n",
      "2415    0.488417\n",
      "8199    0.932002\n",
      "5996    0.010306\n",
      "6330    0.019372\n",
      "9209    0.021919\n",
      "3958    0.053563\n",
      "5724    0.037920\n",
      "1828    0.053563\n",
      "8051    0.031480\n",
      "8540    0.053563\n",
      "8612    0.463767\n",
      "7755    0.030800\n",
      "5280    0.016457\n",
      "9776    0.065101\n",
      "9590    0.055384\n",
      "9549    0.032250\n",
      "3436    0.002625\n",
      "1452    0.036261\n",
      "2772    0.058743\n",
      "7519    0.061465\n",
      "2757    0.051964\n",
      "9716    0.120405\n",
      "6820    0.075065\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"|Actual - Predicted|:\\n\", abs(df_test30.IsWinner - lm10.predict(df_test30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Absolute Error:\n",
      " 0.094520480993\n"
     ]
    }
   ],
   "source": [
    "# Print the Mean Absolute Error of the model on the test set\n",
    "mae = abs(df_test30.IsWinner - lm10.predict(df_test30)).mean()\n",
    "print(\"\\nMean Absolute Error:\\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><i>Logistic Regression</i></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.964261631827\n",
      "\n",
      "Confusion matrix: \n",
      " [[2801   16]\n",
      " [  90   59]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98      2817\n",
      "          1       0.79      0.40      0.53       149\n",
      "\n",
      "avg / total       0.96      0.96      0.96      2966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_testlog, predictions))\n",
    "print(\"\\nConfusion matrix: \\n\", metrics.confusion_matrix(y_testlog, predictions))\n",
    "print(\"\\nClassification report:\\n \", metrics.classification_report(y_testlog, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><i>Random Forest</i></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.969318948078\n",
      "\n",
      "Confusion matrix: \n",
      " [[2781   36]\n",
      " [  55   94]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.98      2817\n",
      "          1       0.72      0.63      0.67       149\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", metrics.accuracy_score(y_test1, rfc_predictions))\n",
    "print(\"\\nConfusion matrix: \\n\", metrics.confusion_matrix(y_test1, rfc_predictions))\n",
    "print(\"\\nClassification report:\\n \", metrics.classification_report(y_test1, rfc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3> (5.1) Discuss how does evaluation on the test set compare to evaluation using the full data for training and also for testing.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>When discussing the evaluation on training and and test set, it is first important to establish what is the function of each set. A training set is a set that is used to discover predictive correlations given a certain amount of data. Once established, the test is used to test the strength of this relationship, and in a way to see if the set or model is a good predictive model.</p>\n",
    "\n",
    "<p><u>Linear Regression:</u></p>\n",
    "<p>Firstly, with regard to Linear Regression: Much of the evaluation of Linear Regression considering all promisingly Continuous Features, where the full data was taken for traning and testing set, has been discussed in the previous sections by means of prediction summaries through stats models. These results stated that although all selected features had p-vales within the required threshold of 0.05, the model had an exceedingly low R-squared value of 0.185. This is significantly higher once all Continuous Features are included in a multiple Linear Regression, however the R-squared value did not change even on the retrained model</p>\n",
    "\n",
    "<p>Similarly, with regard to Linear Regression where there is a 70/30 split in training and test set, similar there are some evaluations to take note of. Firstly, when testing the 70% trained model on the 30% test model, all p-values are below the 0.05 threshold, and the R-squared value increases slightly to 0.191. While this is far from the ideal of 1 within the 0 to 1 scale, it demonstrates that the model can predict strongly given a training model, even if the training model does not have an ideal level of variance to be begin with. Other metrics from the evaluation suggests that there is a low error rate. When testing the training set on the testing set, there is a Mean Squared Error (MSE) of 0.04, and a Mean Absolute Error (MAE) of 0.093. This evaluation shows that given the training model, there is a very small margin of error when predicting.</p>\n",
    "\n",
    "<p><u>Logistic Regression:</u></p>\n",
    "<p>Secondly, with regard to Logistic Regression: There were two models applied for accurate evalution; The stats model and Sckit learn model. Firstly, in discussing the evaluation of the full data as training and test, all p-values were below the recommended threshold mentioned above. ListingPrice was high at 0.023 but still below the threshold of 0.05. In considering the Pseduo R-squared value, it was 0.2545, which is an increase on the Linear Model. Scikit learn was used to produce a Confusion Matrix and further evaluation metrics. In this instance, it was found that the model had 0.96 accuracy. This is represented by the matrix, where 9326 rows were true positives, and 211 true negatives. With regard to the falses, 336 were false positives, while 13 were false negatives. With regard to the 70/30 train test model, it managed to predict with a Pseudo R-squared value of 0.25, predicting the same value as the entire dataset value. Similar accuracy can be noted with regard to the confusion matrix. True positives of 2805 and true negatives of 56 show that the test model is very accurate at reaching the same level of prediction as the training model. There were a number of false positives, 94, and false negatives, 11, which is expected as the model is far from perfect. However the model is evaluated to have a 0.95 accuracy which makes it equal in predicting to the training model.</p>\n",
    "\n",
    "<p><u>Random Forests:</u></p>\n",
    "<p>Finally, in terms of Random Forest: Taking again the full dataset model, the evaluation statistics are provided by scikit learn. They highlight from the model that there are 9320 true positives, 518 true negatives, 29 false positives, and 19 false negatives. It also recorded an accuracy of 0.99. With regard to the 70/30 training test sets, there were similar accurate predictions. Of the 30% test set, 2782 were true postives, 97 were true negatives, 53 were false positives and 34 were false negatives. There was a lower accuracy of 0.97, but this is still a very accurate prediction level.</p>\n",
    "\n",
    "<p><u>Conclusion:</u></p>\n",
    "<p>While the data above suggests that there is high accuracy from the full training model, where all rows are training and testing, the important thing to remember is that all of this data is seen. There this limits the predicatability of this model. While it may state that from a trained dataset it is 0.96 accurate in predicting, what is predicting is data that it has already seen in training, which questions the models actual predicting capabilities given an unseen set. This is good for some descriptive models, however it is limited in that it can only describe data that it was trained with.</p>\n",
    "\n",
    "<p>Taking the 70/30 training/test model, this differs in that it takes only 70% of the rows as training data, and tests this predicting power on the remaining 30%. In terms of results, the model, if accurate, can only be as good as it's trained model, in so far as, if the R-squared values were low in the trained model, they should be low in the test model too if accurate. Our data shows that this is the case, with p-values and R-squared values from the Linear and Logistic models being accurately predicted. In terms of the confusion matrices, there may be higher false positives and negatives in proprotion to the full dataset model, however the data shows that it is accurate in predicting the true positives and negatives, but to a lower standard than the full dataset. </p>\n",
    "\n",
    "<p>It can therefore be concluded that when creating a descriptive model, using the entire dataset is a good model. However, with regard to the question at hand, in order to best predict a target feature, a predictive model is required, and for this model to be accurate it must be tested on unseen, unobserved data. It must not be specialised aiming, for a generalising model which avoids these methods referred to as Overfitting.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3><u>(5.2) Summarize and try to improve your results so far</u>:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>(5.2.1) Which model performs best and is it more accurate than a simple (but useless) model that always predicts IsWinner=0? Justify your answers.</h3>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>There is a bit of crossover between this solution and the solution to the question above, as the above discussion is of key importance when deciding which model performs best. Taking this information into consideration, it is evident that al the models seem accurate at predicting. However, Random Forest appears to perform the best as a predictive model, with fewer errors on this evaluated test. This is due to the following reasons:</p>\n",
    "<p>Firstly, we must consider many methods of evaluation to decide on a model. When analysing the R-squared numbers from both the regression models, they were both quite low in the scale of 0 to 1. This indicates a low amount of variance, or simply that the model explains none of its variability. However, it should be noted that a low R-squared is not always bad and a high R-squared is not always good. However, by analysing some of the provided graphs and coefficients, it is not always the case that the graphs accurately represent the ideal prediction. The p-values, which are used to either accept or reject the null hypothesis, are accurate and fall below the threshold of 0.05 in all cases after retraining.</p>\n",
    "\n",
    "<p>There are also many factors which highlight why Random Forest is a good model for prediction. Taking the Confusion Matrix for both Logistic Regression, it is clear that Random Forest has a higher level of accuracy. When refering to the set that took the full dataset as Training and testing, Random Forest and Logistic Regression had a similar amount of true positives, 9230 and 9236 respectively. What should be focused on instead, is the error margin of the models. Random Forest has much less False predictions at 29 and 19, comparing it with the 336 and 13 positive and negatives from Logistic Regression. Although this model only explains a descriptive, seen model, these figures can be seen on the predictive 70/30 split models, where the error signifcantly lower for Random Forest.</p>\n",
    "\n",
    "<p>Focusing on the positives, the precision for predicting the Target Feature is high, with an average accuracy of 0.97. While the Logistic regression models has similar accuracy and precision in predicting the classification of the Target Feature, it is its flaws and higher amount of errors, which therefore make Random Forest the perferred model</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>(5.2.2) Discuss your understanding of the problem and predictive modeling results so far. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>The problem of this assignment was to focus on building and evaluating prediction models for particular problems and datasets. Sections focused on Data Understanding, Predictive Modelling, and ultimately evaluting the established Predictive Models. The inital steps in Data Understanding allowed for testing to establish correlations between features. It focused on the filtering features which had rows of signifcant and usuable values,and discarding those that did not. It is clear that this section is an iterative process, whereby one model is tested, and if the results are not as expected, then the model should be retrained. While this retraining may not make the model 100% accurate in predicting, it should improve the model, and this is the case as when retraining. Similarly, initally these models trained with Single feature regressions to demonstrate that using multiple features in regressions resulted in an increase in the R-squared number, and the removal of some features resulted in the lower of out of range p values.</p>\n",
    "<p>With regard to the Predictive Modelling process, the problem allowed for the applying of different approaches by means of three different models to datasets that were trained and tested with the full dataset, and trained and tested with split rows where some where unseen, to the margin od 70%/30%. This highlighted the difference between descriptive and predictive models, and how some metrics that appear accurate may not be true. It also allowed for the application of different statistical tools, such as statsmodels and sckitlearn, where each tool took the same data but was able to present different metrics and analysis which would further the understand and objectivity of each of the predicative models.</p>\n",
    "<p>With regards to the results so far, all three models appear to show capability in predicting the Target Feature. Where they differ is in accuracy, with regard specifically to false predictions rather than amount of true predictions each model has. If the model is making large amounts of false predictions then this is an issue that, in essence, discredits a lot of the true predictions. The ideal model will make not just large amounts of true predictions, but small amounts of false ones, to prove that it has not just learnt from the training set. It will show true predictive capabilites when given unseen test data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>(5.2.2) Can you find any tricks to improve the best model so far (e.g., using feature significance, feature re-scaling, creating new features, combining models, or other knowledge)?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>There are some factors to keep in mind when trying to improve a Predictive Model:</p>\n",
    "<p>Firstly, it is of key importance to always make sure that the data used to evaluate the model is not the same as the data used to train the model. On this point, rather than just spliting the data 70/30, spliting the data 50:20:30, or 40:20:40, is a good idea for improving predictability. The 20 value could represent a validation set</p>\n",
    "<p>Similarly, using methods of Cross-Validation would be useful for improve the integrity of the model. It would dispel any doubts that a single train and test split was a one-off. Taking the average erros of multiple spilts of test data would improve this integrity</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
